{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project 6: Analyzing Stock Sentiment from Twits\n",
    "## Instructions\n",
    "Each problem consists of a function to implement and instructions on how to implement the function.  The parts of the function that need to be implemented are marked with a `# TODO` comment.\n",
    "\n",
    "## Packages\n",
    "When you implement the functions, you'll only need to you use the packages you've used in the classroom, like [Pandas](https://pandas.pydata.org/) and [Numpy](http://www.numpy.org/). These packages will be imported for you. We recommend you don't add any import statements, otherwise the grader might not be able to run your code.\n",
    "\n",
    "### Load Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import nltk\n",
    "import os\n",
    "import random\n",
    "import re\n",
    "import torch\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from torch import nn, optim\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "When deciding the value of a company, it's important to follow the news. For example, a product recall or natural disaster in a company's product chain. You want to be able to turn this information into a signal. Currently, the best tool for the job is a Neural Network. \n",
    "\n",
    "For this project, you'll use posts from the social media site [StockTwits](https://en.wikipedia.org/wiki/StockTwits). The community on StockTwits is full of investors, traders, and entrepreneurs. Each message posted is called a Twit. This is similar to Twitter's version of a post, called a Tweet. You'll build a model around these twits that generate a sentiment score.\n",
    "\n",
    "We've collected a bunch of twits, then hand labeled the sentiment of each. To capture the degree of sentiment, we'll use a five-point scale: very negative, negative, neutral, positive, very positive. Each twit is labeled -2 to 2 in steps of 1, from very negative to very positive respectively. You'll build a sentiment analysis model that will learn to assign sentiment to twits on its own, using this labeled data.\n",
    "\n",
    "The first thing we should to do, is load the data.\n",
    "\n",
    "## Import Twits \n",
    "### Load Twits Data \n",
    "This JSON file contains a list of objects for each twit in the `'data'` field:\n",
    "\n",
    "```\n",
    "{'data':\n",
    "  {'message_body': 'Neutral twit body text here',\n",
    "   'sentiment': 0},\n",
    "  {'message_body': 'Happy twit body text here',\n",
    "   'sentiment': 1},\n",
    "   ...\n",
    "}\n",
    "```\n",
    "\n",
    "The fields represent the following:\n",
    "\n",
    "* `'message_body'`: The text of the twit.\n",
    "* `'sentiment'`: Sentiment score for the twit, ranges from -2 to 2 in steps of 1, with 0 being neutral.\n",
    "\n",
    "\n",
    "To see what the data look like by printing the first 10 twits from the list. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'message_body': '$FITB great buy at 26.00...ill wait', 'sentiment': 2, 'timestamp': '2018-07-01T00:00:09Z'}, {'message_body': '@StockTwits $MSFT', 'sentiment': 1, 'timestamp': '2018-07-01T00:00:42Z'}, {'message_body': '#STAAnalystAlert for $TDG : Jefferies Maintains with a rating of Hold setting target price at USD 350.00. Our own verdict is Buy  http://www.stocktargetadvisor.com/toprating', 'sentiment': 2, 'timestamp': '2018-07-01T00:01:24Z'}, {'message_body': '$AMD I heard thereâ€™s a guy who knows someone who thinks somebody knows something - on StockTwits.', 'sentiment': 1, 'timestamp': '2018-07-01T00:01:47Z'}, {'message_body': '$AMD reveal yourself!', 'sentiment': 0, 'timestamp': '2018-07-01T00:02:13Z'}, {'message_body': '$AAPL Why the drop? I warren Buffet taking out his position?', 'sentiment': 1, 'timestamp': '2018-07-01T00:03:10Z'}, {'message_body': '$BA bears have 1 reason on 06-29 to pay more attention https://dividendbot.com?s=BA', 'sentiment': -2, 'timestamp': '2018-07-01T00:04:09Z'}, {'message_body': '$BAC ok good we&#39;re not dropping in price over the weekend, lol', 'sentiment': 1, 'timestamp': '2018-07-01T00:04:17Z'}, {'message_body': '$AMAT - Daily Chart, we need to get back to above 50.', 'sentiment': 2, 'timestamp': '2018-07-01T00:08:01Z'}, {'message_body': '$GME 3% drop per week after spike... if no news in 3 months, back to 12s... if BO, then bingo... what is the odds?', 'sentiment': -2, 'timestamp': '2018-07-01T00:09:03Z'}]\n"
     ]
    }
   ],
   "source": [
    "with open(os.path.join('..', '..', 'data', 'project_6_stocktwits', 'twits.json'), 'r') as f:\n",
    "    twits = json.load(f)\n",
    "\n",
    "print(twits['data'][:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Length of Data\n",
    "Now let's look at the number of twits in dataset. Print the number of twits below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1548010\n"
     ]
    }
   ],
   "source": [
    "\"\"\"print out the number of twits\"\"\"\n",
    "\n",
    "# TODO Implement \n",
    "print(len(twits['data']))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split Message Body and Sentiment Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "messages = [twit['message_body'] for twit in twits['data']]\n",
    "# Since the sentiment scores are discrete, we'll scale the sentiments to 0 to 4 for use in our network\n",
    "sentiments = [twit['sentiment'] + 2 for twit in twits['data']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing the Data\n",
    "With our data in hand we need to preprocess our text. These twits are collected by filtering on ticker symbols where these are denoted with a leader $ symbol in the twit itself. For example,\n",
    "\n",
    "`{'message_body': 'RT @google Our annual look at the year in Google blogging (and beyond) http://t.co/sptHOAh8 $GOOG',\n",
    " 'sentiment': 0}`\n",
    "\n",
    "The ticker symbols don't provide information on the sentiment, and they are in every twit, so we should remove them. This twit also has the `@google` username, again not providing sentiment information, so we should also remove it. We also see a URL `http://t.co/sptHOAh8`. Let's remove these too.\n",
    "\n",
    "The easiest way to remove specific words or phrases is with regex using the `re` module. You can sub out specific patterns with a space:\n",
    "\n",
    "```python\n",
    "re.sub(pattern, ' ', text)\n",
    "```\n",
    "This will substitute a space with anywhere the pattern matches in the text. Later when we tokenize the text, we'll split appropriately on those spaces."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pre-Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "nltk.download('wordnet')\n",
    "\n",
    "\n",
    "def preprocess(message):\n",
    "    \"\"\"\n",
    "    This function takes a string as input, then performs these operations: \n",
    "        - lowercase\n",
    "        - remove URLs\n",
    "        - remove ticker symbols \n",
    "        - removes punctuation\n",
    "        - tokenize by splitting the string on whitespace \n",
    "        - removes any single character tokens\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "        message : The text message to be preprocessed.\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "        tokens: The preprocessed text into tokens.\n",
    "    \"\"\" \n",
    "    #TODO: Implement \n",
    "    \n",
    "    # Lowercase the twit message\n",
    "    text = message.lower()\n",
    "    \n",
    "    # Replace URLs with a space in the message\n",
    "    # Since URL only resides in the end of sentence we can just find them starting from http/https\n",
    "    text = re.sub(r\"(http|https)+.+\",\" \",text)\n",
    "    \n",
    "    # Replace ticker symbols with a space. The ticker symbols are any stock symbol that starts with $.\n",
    "    text = re.sub(r\"\\$[a-zA-Z]{1,5}\",\" \",text) \n",
    "    \n",
    "    # Replace StockTwits usernames with a space. The usernames are any word that starts with @.\n",
    "    text = re.sub(r\"\\@[a-zA-Z]{1,20}\",\" \",text)\n",
    "\n",
    "    # Replace everything not a letter with a space\n",
    "    # \\W may include numbers\n",
    "    text = re.sub(r\"[^a-zA-Z]\",\" \",text)\n",
    "    \n",
    "    # Tokenize by splitting the string on whitespace into a list of words\n",
    "    tokens = text.split()\n",
    "\n",
    "    # Lemmatize words using the WordNetLemmatizer. You can ignore any word that is not longer than one character.\n",
    "    wnl = nltk.stem.WordNetLemmatizer()\n",
    "    tokens = [wnl.lemmatize(t) for t in tokens if len(t)>1]\n",
    "\n",
    "    \n",
    "    assert type(tokens) == list, 'Tokens should be list'\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">Note: You must ensure that after preprocessing the text should NOT include:\n",
    "- Numbers\n",
    "- URLs\n",
    "- Single character tokens\n",
    "- Ticker symbols (these should be removed even if they don't appear at the beginning)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocess All the Twits \n",
    "Now we can preprocess each of the twits in our dataset. Apply the function `preprocess` to all the twit messages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['great', 'buy', 'at', 'ill', 'wait'],\n",
       " [],\n",
       " ['staanalystalert',\n",
       "  'for',\n",
       "  'jefferies',\n",
       "  'maintains',\n",
       "  'with',\n",
       "  'rating',\n",
       "  'of',\n",
       "  'hold',\n",
       "  'setting',\n",
       "  'target',\n",
       "  'price',\n",
       "  'at',\n",
       "  'usd',\n",
       "  'our',\n",
       "  'own',\n",
       "  'verdict',\n",
       "  'is',\n",
       "  'buy'],\n",
       " ['heard',\n",
       "  'there',\n",
       "  'guy',\n",
       "  'who',\n",
       "  'know',\n",
       "  'someone',\n",
       "  'who',\n",
       "  'think',\n",
       "  'somebody',\n",
       "  'know',\n",
       "  'something',\n",
       "  'on',\n",
       "  'stocktwits'],\n",
       " ['reveal', 'yourself'],\n",
       " ['why',\n",
       "  'the',\n",
       "  'drop',\n",
       "  'warren',\n",
       "  'buffet',\n",
       "  'taking',\n",
       "  'out',\n",
       "  'his',\n",
       "  'position'],\n",
       " ['bear', 'have', 'reason', 'on', 'to', 'pay', 'more', 'attention'],\n",
       " ['ok',\n",
       "  'good',\n",
       "  'we',\n",
       "  're',\n",
       "  'not',\n",
       "  'dropping',\n",
       "  'in',\n",
       "  'price',\n",
       "  'over',\n",
       "  'the',\n",
       "  'weekend',\n",
       "  'lol'],\n",
       " ['daily', 'chart', 'we', 'need', 'to', 'get', 'back', 'to', 'above'],\n",
       " ['drop',\n",
       "  'per',\n",
       "  'week',\n",
       "  'after',\n",
       "  'spike',\n",
       "  'if',\n",
       "  'no',\n",
       "  'news',\n",
       "  'in',\n",
       "  'month',\n",
       "  'back',\n",
       "  'to',\n",
       "  'if',\n",
       "  'bo',\n",
       "  'then',\n",
       "  'bingo',\n",
       "  'what',\n",
       "  'is',\n",
       "  'the',\n",
       "  'odds'],\n",
       " ['strong', 'buy'],\n",
       " ['short', 'ratio', 'is', 'at', 'and', 'short', 'to', 'float', 'is'],\n",
       " ['price',\n",
       "  'squeezing',\n",
       "  'perfect',\n",
       "  'place',\n",
       "  'for',\n",
       "  'an',\n",
       "  'option',\n",
       "  'straddle',\n",
       "  'near',\n",
       "  'the',\n",
       "  'supporting',\n",
       "  'trend'],\n",
       " ['start',\n",
       "  'of',\n",
       "  'new',\n",
       "  'on',\n",
       "  'monday',\n",
       "  'expect',\n",
       "  'strong',\n",
       "  'buy',\n",
       "  'volume',\n",
       "  'across',\n",
       "  'key',\n",
       "  'company',\n",
       "  'of',\n",
       "  'various',\n",
       "  'sector'],\n",
       " ['breakout', 'strategy', 'current', 'portfolio'],\n",
       " ['bull', 'have', 'reason', 'on', 'to', 'pay', 'more', 'attention'],\n",
       " ['catalyst',\n",
       "  'continuing',\n",
       "  'this',\n",
       "  'new',\n",
       "  'uptrend',\n",
       "  'pill',\n",
       "  'pack',\n",
       "  'buy',\n",
       "  'out',\n",
       "  'amazon',\n",
       "  'prime',\n",
       "  'day',\n",
       "  'earnings',\n",
       "  'test',\n",
       "  'break',\n",
       "  'of',\n",
       "  'soon'],\n",
       " ['ha', 'moved', 'on', 'check', 'out', 'the', 'movement', 'and', 'peer', 'at'],\n",
       " ['staanalystalert',\n",
       "  'for',\n",
       "  'mkm',\n",
       "  'partner',\n",
       "  'set',\n",
       "  'price',\n",
       "  'target',\n",
       "  'with',\n",
       "  'rating',\n",
       "  'of',\n",
       "  'buy',\n",
       "  'setting',\n",
       "  'target',\n",
       "  'price',\n",
       "  'at',\n",
       "  'usd',\n",
       "  'our',\n",
       "  'own',\n",
       "  'verdict',\n",
       "  'is',\n",
       "  'buy'],\n",
       " ['think',\n",
       "  'it',\n",
       "  'is',\n",
       "  'too',\n",
       "  'early',\n",
       "  'to',\n",
       "  'tell',\n",
       "  'what',\n",
       "  'going',\n",
       "  'to',\n",
       "  'happen',\n",
       "  'monday',\n",
       "  'even',\n",
       "  'with',\n",
       "  'the',\n",
       "  'current',\n",
       "  'news',\n",
       "  'about',\n",
       "  'raisinf',\n",
       "  'output',\n",
       "  'there',\n",
       "  'is',\n",
       "  'still',\n",
       "  'so',\n",
       "  'many'],\n",
       " ['ha',\n",
       "  'current',\n",
       "  'ratio',\n",
       "  'of',\n",
       "  'so',\n",
       "  'it',\n",
       "  'is',\n",
       "  'financially',\n",
       "  'healthy',\n",
       "  'and',\n",
       "  'ha',\n",
       "  'no',\n",
       "  'problem',\n",
       "  'in',\n",
       "  'meeting',\n",
       "  'it',\n",
       "  'obligation'],\n",
       " ['bullish', 'stock', 'to', 'watch', 'setup', 'timeframes'],\n",
       " ['just', 'short', 'it'],\n",
       " ['high', 'alert', 'for', 'next', 'week', 'gt', 'breakdown'],\n",
       " ['the',\n",
       "  'current',\n",
       "  'ratio',\n",
       "  'of',\n",
       "  'is',\n",
       "  'much',\n",
       "  'better',\n",
       "  'than',\n",
       "  'the',\n",
       "  'industry',\n",
       "  'average',\n",
       "  'of'],\n",
       " ['miss', 'these', 'day'],\n",
       " ['if',\n",
       "  'break',\n",
       "  'and',\n",
       "  'confirms',\n",
       "  'next',\n",
       "  'week',\n",
       "  'you',\n",
       "  'will',\n",
       "  'see',\n",
       "  'violent',\n",
       "  'move',\n",
       "  'downward',\n",
       "  'to',\n",
       "  'my',\n",
       "  'buy',\n",
       "  'price'],\n",
       " ['bear', 'have', 'reason', 'on', 'to', 'pay', 'more', 'attention'],\n",
       " ['breakout',\n",
       "  'base',\n",
       "  'gap',\n",
       "  'and',\n",
       "  'day',\n",
       "  'ma',\n",
       "  'gap',\n",
       "  'gap',\n",
       "  'gap',\n",
       "  'and',\n",
       "  'day',\n",
       "  'ma'],\n",
       " ['cabot',\n",
       "  'weekly',\n",
       "  'video',\n",
       "  'quot',\n",
       "  'resilient',\n",
       "  'growth',\n",
       "  'stock',\n",
       "  'to',\n",
       "  'watch',\n",
       "  'quot'],\n",
       " ['when',\n",
       "  'wa',\n",
       "  'kid',\n",
       "  'my',\n",
       "  'froend',\n",
       "  'told',\n",
       "  'me',\n",
       "  'the',\n",
       "  'moon',\n",
       "  'wa',\n",
       "  'made',\n",
       "  'out',\n",
       "  'of',\n",
       "  'cheese'],\n",
       " ['short',\n",
       "  'volume',\n",
       "  'percent',\n",
       "  'for',\n",
       "  'wa',\n",
       "  'on',\n",
       "  'and',\n",
       "  'day',\n",
       "  'rank',\n",
       "  'wa',\n",
       "  'th',\n",
       "  'percentile'],\n",
       " ['thank',\n",
       "  'you',\n",
       "  'don',\n",
       "  'feel',\n",
       "  'the',\n",
       "  'need',\n",
       "  'to',\n",
       "  'tell',\n",
       "  'or',\n",
       "  'to',\n",
       "  'do',\n",
       "  'well',\n",
       "  'for',\n",
       "  'me',\n",
       "  'they',\n",
       "  'already',\n",
       "  'have'],\n",
       " ['during',\n",
       "  'the',\n",
       "  'youtube',\n",
       "  'interview',\n",
       "  'mitch',\n",
       "  'couldn',\n",
       "  'remember',\n",
       "  'single',\n",
       "  'movie',\n",
       "  'he',\n",
       "  'watched',\n",
       "  'all',\n",
       "  'year',\n",
       "  'except',\n",
       "  'star',\n",
       "  'war',\n",
       "  'black',\n",
       "  'panther',\n",
       "  'clothes'],\n",
       " ['staanalystalert',\n",
       "  'for',\n",
       "  'jefferies',\n",
       "  'downgrade',\n",
       "  'with',\n",
       "  'rating',\n",
       "  'of',\n",
       "  'hold',\n",
       "  'setting',\n",
       "  'target',\n",
       "  'price',\n",
       "  'at',\n",
       "  'usd',\n",
       "  'our',\n",
       "  'own',\n",
       "  'verdict',\n",
       "  'is',\n",
       "  'hold'],\n",
       " ['short', 'sale', 'volume', 'not', 'short', 'interest', 'for', 'on', 'is'],\n",
       " ['ha',\n",
       "  'better',\n",
       "  'return',\n",
       "  'on',\n",
       "  'equity',\n",
       "  'than',\n",
       "  'the',\n",
       "  'industry',\n",
       "  'average',\n",
       "  'of'],\n",
       " ['although',\n",
       "  'the',\n",
       "  'market',\n",
       "  'is',\n",
       "  'up',\n",
       "  'is',\n",
       "  'doing',\n",
       "  'even',\n",
       "  'better',\n",
       "  'it',\n",
       "  'ha',\n",
       "  'advanced',\n",
       "  'a',\n",
       "  'of',\n",
       "  'more',\n",
       "  'info',\n",
       "  'peer',\n",
       "  'at'],\n",
       " ['july',\n",
       "  'will',\n",
       "  'be',\n",
       "  'the',\n",
       "  'most',\n",
       "  'bullish',\n",
       "  'day',\n",
       "  'of',\n",
       "  'the',\n",
       "  'year',\n",
       "  'for',\n",
       "  'stock'],\n",
       " ['option',\n",
       "  'volume',\n",
       "  'wa',\n",
       "  'normal',\n",
       "  'on',\n",
       "  'friday',\n",
       "  'with',\n",
       "  'contract',\n",
       "  'call',\n",
       "  'volume',\n",
       "  'wa',\n",
       "  'and',\n",
       "  'put',\n",
       "  'volume',\n",
       "  'wa'],\n",
       " ['third', 'design', 'win', 'the', 'timing', 'match', 'it', 'probably', 'arm'],\n",
       " ['alcohol',\n",
       "  'stock',\n",
       "  'tobacco',\n",
       "  'stock',\n",
       "  'and',\n",
       "  'firearm',\n",
       "  'stock',\n",
       "  'to',\n",
       "  'buy'],\n",
       " ['president',\n",
       "  'trump',\n",
       "  'tweet',\n",
       "  'just',\n",
       "  'spoke',\n",
       "  'to',\n",
       "  'king',\n",
       "  'salman',\n",
       "  'of',\n",
       "  'saudi',\n",
       "  'arabia',\n",
       "  'and',\n",
       "  'explained',\n",
       "  'to',\n",
       "  'him',\n",
       "  'that',\n",
       "  'because',\n",
       "  'of',\n",
       "  'the',\n",
       "  'turmoil',\n",
       "  'amp'],\n",
       " ['today', 'insight', 'on'],\n",
       " ['intc',\n",
       "  'mama',\n",
       "  'said',\n",
       "  'get',\n",
       "  'ice',\n",
       "  'cream',\n",
       "  'if',\n",
       "  'finish',\n",
       "  'my',\n",
       "  'due',\n",
       "  'dil'],\n",
       " ['just',\n",
       "  'noticed',\n",
       "  'they',\n",
       "  'have',\n",
       "  'the',\n",
       "  'last',\n",
       "  'jedi',\n",
       "  'on',\n",
       "  'stream',\n",
       "  'love',\n",
       "  'this',\n",
       "  'stock'],\n",
       " ['here', 'you', 'go', 'will', 'just', 'leave', 'this', 'here'],\n",
       " ['good',\n",
       "  'view',\n",
       "  'daily',\n",
       "  'still',\n",
       "  'look',\n",
       "  'good',\n",
       "  'ema',\n",
       "  'held',\n",
       "  'above',\n",
       "  'ema',\n",
       "  'and',\n",
       "  'stochastics',\n",
       "  'turning',\n",
       "  'healthy',\n",
       "  'a',\n",
       "  'spy',\n",
       "  'qqq',\n",
       "  'opposite'],\n",
       " ['with',\n",
       "  'forward',\n",
       "  'pe',\n",
       "  'of',\n",
       "  'the',\n",
       "  'valuation',\n",
       "  'of',\n",
       "  'can',\n",
       "  'be',\n",
       "  'described',\n",
       "  'a',\n",
       "  'cheap'],\n",
       " ['saber',\n",
       "  'capital',\n",
       "  'presentation',\n",
       "  'common',\n",
       "  'denominator',\n",
       "  'of',\n",
       "  'tencent',\n",
       "  'facebook',\n",
       "  'and',\n",
       "  'google'],\n",
       " ['how', 'expect', 'the', 'earnings'],\n",
       " ['is',\n",
       "  'one',\n",
       "  'of',\n",
       "  'the',\n",
       "  'better',\n",
       "  'performing',\n",
       "  'stock',\n",
       "  'in',\n",
       "  'the',\n",
       "  'crude',\n",
       "  'petroleum',\n",
       "  'and',\n",
       "  'natural',\n",
       "  'gas',\n",
       "  'industry'],\n",
       " ['pu',\n",
       "  'it',\n",
       "  'simply',\n",
       "  'havent',\n",
       "  'lost',\n",
       "  'on',\n",
       "  'any',\n",
       "  'brown',\n",
       "  'guy',\n",
       "  'run',\n",
       "  'tech',\n",
       "  'company',\n",
       "  'mf',\n",
       "  'are',\n",
       "  'well',\n",
       "  'educated',\n",
       "  'know',\n",
       "  'their',\n",
       "  'shit',\n",
       "  'more',\n",
       "  'more',\n",
       "  'every',\n",
       "  'year'],\n",
       " ['former',\n",
       "  'president',\n",
       "  'of',\n",
       "  'global',\n",
       "  'manufacturing',\n",
       "  'at',\n",
       "  'pfizer',\n",
       "  'is',\n",
       "  'an',\n",
       "  'independent',\n",
       "  'director',\n",
       "  'at',\n",
       "  'nat',\n",
       "  'ricciardi'],\n",
       " ['may', 'be', 'the', 'safest', 'stock', 'own'],\n",
       " ['special',\n",
       "  'limited',\n",
       "  'offer',\n",
       "  'june',\n",
       "  'th',\n",
       "  'june',\n",
       "  'th',\n",
       "  'tradenet',\n",
       "  'is',\n",
       "  'offering',\n",
       "  'discount',\n",
       "  'on',\n",
       "  'intro',\n",
       "  'program'],\n",
       " ['below', 'buy', 'put', 'on', 'financials'],\n",
       " ['great',\n",
       "  'summary',\n",
       "  'of',\n",
       "  'jeff',\n",
       "  'gundlach',\n",
       "  'sohn',\n",
       "  'presentation',\n",
       "  'long',\n",
       "  'thesis',\n",
       "  'for',\n",
       "  'energy',\n",
       "  'stock'],\n",
       " ['low',\n",
       "  'peg',\n",
       "  'ratio',\n",
       "  'which',\n",
       "  'compensates',\n",
       "  'the',\n",
       "  'pe',\n",
       "  'for',\n",
       "  'growth',\n",
       "  'indicates',\n",
       "  'rather',\n",
       "  'cheap',\n",
       "  'valuation'],\n",
       " ['great',\n",
       "  'summary',\n",
       "  'of',\n",
       "  'jeff',\n",
       "  'gundlach',\n",
       "  'sohn',\n",
       "  'pres',\n",
       "  'long',\n",
       "  'thesis',\n",
       "  'for',\n",
       "  'energy',\n",
       "  'equity'],\n",
       " ['coming'],\n",
       " ['seems', 'is', 'the', 'support', 'next', 'if', 'under', 'is', 'likely'],\n",
       " ['ha', 'moved', 'on', 'check', 'out', 'the', 'movement', 'and', 'peer', 'at'],\n",
       " ['bullshit',\n",
       "  'worthless',\n",
       "  'mean',\n",
       "  'fucking',\n",
       "  'nothing',\n",
       "  'this',\n",
       "  'is',\n",
       "  'macau',\n",
       "  'not',\n",
       "  'fucking',\n",
       "  'usa'],\n",
       " ['take',\n",
       "  'this',\n",
       "  'let',\n",
       "  'me',\n",
       "  'know',\n",
       "  'where',\n",
       "  'are',\n",
       "  'we',\n",
       "  'right',\n",
       "  'now',\n",
       "  'lol'],\n",
       " ['the',\n",
       "  'chart',\n",
       "  'look',\n",
       "  'so',\n",
       "  'ugly',\n",
       "  'without',\n",
       "  'clear',\n",
       "  'support',\n",
       "  'level',\n",
       "  'short',\n",
       "  'term',\n",
       "  'bearish',\n",
       "  'll',\n",
       "  'buy',\n",
       "  'when',\n",
       "  'this',\n",
       "  'is',\n",
       "  'at'],\n",
       " ['great',\n",
       "  'summary',\n",
       "  'of',\n",
       "  'jeff',\n",
       "  'gundlach',\n",
       "  'sohn',\n",
       "  'presentation',\n",
       "  'long',\n",
       "  'thesis',\n",
       "  'for',\n",
       "  'energy',\n",
       "  'stock'],\n",
       " ['previously',\n",
       "  'there',\n",
       "  'wa',\n",
       "  'mo',\n",
       "  'run',\n",
       "  'up',\n",
       "  'followed',\n",
       "  'by',\n",
       "  'drop',\n",
       "  'we',\n",
       "  'are',\n",
       "  'at',\n",
       "  'the',\n",
       "  'end',\n",
       "  'of',\n",
       "  'month',\n",
       "  'of',\n",
       "  'another',\n",
       "  'runup',\n",
       "  'and',\n",
       "  'have',\n",
       "  'dropped',\n",
       "  'about'],\n",
       " ['smart', 'money', 'betting', 'on', 'call', 'deal', 'update'],\n",
       " ['although',\n",
       "  'the',\n",
       "  'technical',\n",
       "  'rating',\n",
       "  'is',\n",
       "  'bad',\n",
       "  'doe',\n",
       "  'present',\n",
       "  'nice',\n",
       "  'setup',\n",
       "  'opportunity'],\n",
       " ['will',\n",
       "  'completely',\n",
       "  'scale',\n",
       "  'out',\n",
       "  'in',\n",
       "  'time',\n",
       "  'to',\n",
       "  'gobble',\n",
       "  'up',\n",
       "  'my',\n",
       "  'next',\n",
       "  'long',\n",
       "  'play',\n",
       "  'aka',\n",
       "  'my',\n",
       "  'favorite',\n",
       "  'gt'],\n",
       " ['short', 'sale', 'volume', 'not', 'short', 'interest', 'for', 'is'],\n",
       " ['them', 'are', 'iddy', 'bitty', 'kiddy', 'hand'],\n",
       " ['short',\n",
       "  'interest',\n",
       "  'ratio',\n",
       "  'of',\n",
       "  'is',\n",
       "  'at',\n",
       "  'and',\n",
       "  'short',\n",
       "  'to',\n",
       "  'float',\n",
       "  'is'],\n",
       " ['then',\n",
       "  'awesome',\n",
       "  'it',\n",
       "  'is',\n",
       "  'now',\n",
       "  'be',\n",
       "  'concerned',\n",
       "  'if',\n",
       "  'not',\n",
       "  'over',\n",
       "  'by',\n",
       "  'eow',\n",
       "  'might',\n",
       "  'get',\n",
       "  'under',\n",
       "  'next',\n",
       "  'wk',\n",
       "  'or',\n",
       "  'soon'],\n",
       " ['throwback'],\n",
       " ['staanalystalert',\n",
       "  'for',\n",
       "  'u',\n",
       "  'capital',\n",
       "  'advisor',\n",
       "  'upgrade',\n",
       "  'with',\n",
       "  'rating',\n",
       "  'of',\n",
       "  'hold',\n",
       "  'our',\n",
       "  'own',\n",
       "  'verdict',\n",
       "  'is',\n",
       "  'buy'],\n",
       " ['lol',\n",
       "  'all',\n",
       "  'these',\n",
       "  'shorties',\n",
       "  'are',\n",
       "  'dreaming',\n",
       "  'of',\n",
       "  'great',\n",
       "  'depression',\n",
       "  'or',\n",
       "  'somethin',\n",
       "  'loll'],\n",
       " ['just',\n",
       "  'updated',\n",
       "  'hormel',\n",
       "  'food',\n",
       "  'dividend',\n",
       "  'king',\n",
       "  'stock',\n",
       "  'analysis',\n",
       "  'dividend',\n",
       "  'king',\n",
       "  'consumer',\n",
       "  'defensive'],\n",
       " ['today', 'insight', 'on'],\n",
       " ['just',\n",
       "  'updated',\n",
       "  'intel',\n",
       "  'valuation',\n",
       "  'profitability',\n",
       "  'and',\n",
       "  'dividend',\n",
       "  'safety',\n",
       "  'score',\n",
       "  'analysis',\n",
       "  'dividend',\n",
       "  'technology'],\n",
       " ['today', 'insight', 'on'],\n",
       " ['the',\n",
       "  'long',\n",
       "  'and',\n",
       "  'short',\n",
       "  'term',\n",
       "  'trend',\n",
       "  'are',\n",
       "  'both',\n",
       "  'positive',\n",
       "  'this',\n",
       "  'is',\n",
       "  'looking',\n",
       "  'good'],\n",
       " ['they', 'so', 'mad', 'at', 'me', 'still'],\n",
       " ['back', 'to', 'by', 'july'],\n",
       " ['report', 'and', 'block', 'this', 'person', 'spam'],\n",
       " ['should', 'open', 'at', 'on', 'monday'],\n",
       " ['my',\n",
       "  'projection',\n",
       "  'for',\n",
       "  'if',\n",
       "  'thats',\n",
       "  'true',\n",
       "  'under',\n",
       "  'is',\n",
       "  'next',\n",
       "  'week',\n",
       "  'thats',\n",
       "  'why',\n",
       "  'prefer',\n",
       "  'to',\n",
       "  'buy',\n",
       "  'from',\n",
       "  'support',\n",
       "  'level'],\n",
       " ['what', 'turd'],\n",
       " ['percent', 'short', 'volume', 'for', 'wa', 'on'],\n",
       " ['wal',\n",
       "  'mart',\n",
       "  'dividend',\n",
       "  'aristocrat',\n",
       "  'dividend',\n",
       "  'aristocrat',\n",
       "  'consumer',\n",
       "  'defensive',\n",
       "  'valueinvesting',\n",
       "  'dvb',\n",
       "  'aaamp'],\n",
       " ['looking',\n",
       "  'for',\n",
       "  'marriage',\n",
       "  'have',\n",
       "  'in',\n",
       "  'my',\n",
       "  'bank',\n",
       "  'account',\n",
       "  'with',\n",
       "  'in',\n",
       "  'stock',\n",
       "  'dm'],\n",
       " ['short', 'ratio', 'is', 'at', 'and', 'short', 'to', 'float', 'is'],\n",
       " ['to',\n",
       "  'that',\n",
       "  'bear',\n",
       "  'that',\n",
       "  'won',\n",
       "  'stop',\n",
       "  'posting',\n",
       "  'holding',\n",
       "  'big',\n",
       "  'short',\n",
       "  'position',\n",
       "  'over',\n",
       "  'weekend',\n",
       "  'calm',\n",
       "  'down',\n",
       "  'and',\n",
       "  'good',\n",
       "  'luck',\n",
       "  'lol'],\n",
       " ['the',\n",
       "  'chase',\n",
       "  'continues',\n",
       "  'hopefully',\n",
       "  'they',\n",
       "  'catch',\n",
       "  'him',\n",
       "  'before',\n",
       "  'lisa',\n",
       "  'announces',\n",
       "  'the',\n",
       "  'rd',\n",
       "  'win'],\n",
       " ['the',\n",
       "  'price',\n",
       "  'earnings',\n",
       "  'ratio',\n",
       "  'is',\n",
       "  'which',\n",
       "  'indicates',\n",
       "  'rather',\n",
       "  'cheap',\n",
       "  'valuation',\n",
       "  'of'],\n",
       " ['permamently',\n",
       "  'turned',\n",
       "  'me',\n",
       "  'off',\n",
       "  'of',\n",
       "  'option',\n",
       "  'trading',\n",
       "  'and',\n",
       "  'maybe',\n",
       "  'stock',\n",
       "  'altogether',\n",
       "  'manipulation',\n",
       "  'by',\n",
       "  'very',\n",
       "  'rich',\n",
       "  'to',\n",
       "  'make',\n",
       "  'me',\n",
       "  'very',\n",
       "  'poor',\n",
       "  'fuk',\n",
       "  'it'],\n",
       " ['is',\n",
       "  'down',\n",
       "  'almost',\n",
       "  'pct',\n",
       "  'from',\n",
       "  'it',\n",
       "  'week',\n",
       "  'high',\n",
       "  'it',\n",
       "  'about',\n",
       "  'time',\n",
       "  'for',\n",
       "  'buyback',\n",
       "  'got',\n",
       "  'more',\n",
       "  'share',\n",
       "  'in',\n",
       "  'my',\n",
       "  'account',\n",
       "  'though',\n",
       "  'from',\n",
       "  'drip'],\n",
       " ['option',\n",
       "  'volume',\n",
       "  'wa',\n",
       "  'normal',\n",
       "  'on',\n",
       "  'friday',\n",
       "  'with',\n",
       "  'contract',\n",
       "  'call',\n",
       "  'volume',\n",
       "  'wa',\n",
       "  'and',\n",
       "  'put',\n",
       "  'volume',\n",
       "  'wa'],\n",
       " [],\n",
       " ['dumped',\n",
       "  'call',\n",
       "  'friday',\n",
       "  'at',\n",
       "  'open',\n",
       "  'that',\n",
       "  'wa',\n",
       "  'obv',\n",
       "  'but',\n",
       "  'jeez',\n",
       "  'bit',\n",
       "  'over',\n",
       "  'done',\n",
       "  'here'],\n",
       " ['bounce',\n",
       "  'off',\n",
       "  'support',\n",
       "  'heikin',\n",
       "  'ashi',\n",
       "  'weekly',\n",
       "  'candle',\n",
       "  'look',\n",
       "  'good',\n",
       "  'a',\n",
       "  'well',\n",
       "  'will',\n",
       "  'be',\n",
       "  'looking',\n",
       "  'for',\n",
       "  'confirmation'],\n",
       " ['liking', 'this'],\n",
       " ['look',\n",
       "  'for',\n",
       "  'wife',\n",
       "  'got',\n",
       "  'about',\n",
       "  'tree',\n",
       "  'fiddy',\n",
       "  'in',\n",
       "  'stock',\n",
       "  'and',\n",
       "  'it',\n",
       "  'sure',\n",
       "  'my',\n",
       "  'piggy',\n",
       "  'bank',\n",
       "  'ha',\n",
       "  'got',\n",
       "  'lot',\n",
       "  'of',\n",
       "  'coin',\n",
       "  'may',\n",
       "  'spend',\n",
       "  'on',\n",
       "  'candy',\n",
       "  'no',\n",
       "  'dm',\n",
       "  'though'],\n",
       " ['short',\n",
       "  'interest',\n",
       "  'ratio',\n",
       "  'is',\n",
       "  'on',\n",
       "  'and',\n",
       "  'short',\n",
       "  'to',\n",
       "  'float',\n",
       "  'is'],\n",
       " ['just',\n",
       "  'updated',\n",
       "  'microsoft',\n",
       "  'valuation',\n",
       "  'profitability',\n",
       "  'and',\n",
       "  'dividend',\n",
       "  'safety',\n",
       "  'score',\n",
       "  'analysis',\n",
       "  'dividend',\n",
       "  'technology'],\n",
       " ['bearish', 'investor', 'aren', 'happy', 'today', 'for', 'a', 'of'],\n",
       " ['staanalystalert',\n",
       "  'for',\n",
       "  'royal',\n",
       "  'bank',\n",
       "  'of',\n",
       "  'canada',\n",
       "  'reiterates',\n",
       "  'with',\n",
       "  'rating',\n",
       "  'of',\n",
       "  'outperform',\n",
       "  'our',\n",
       "  'own',\n",
       "  'verdict',\n",
       "  'is',\n",
       "  'buy'],\n",
       " ['staanalystalert',\n",
       "  'for',\n",
       "  'loop',\n",
       "  'capital',\n",
       "  'raise',\n",
       "  'target',\n",
       "  'with',\n",
       "  'rating',\n",
       "  'of',\n",
       "  'buy',\n",
       "  'setting',\n",
       "  'target',\n",
       "  'price',\n",
       "  'at',\n",
       "  'usd',\n",
       "  'our',\n",
       "  'own',\n",
       "  'verdict',\n",
       "  'is',\n",
       "  'buy'],\n",
       " ['kid', 'never', 'been', 'wrong', 'he', 'miracle'],\n",
       " ['what', 'is', 'period', 'bollinger', 'band', 'mean'],\n",
       " ['you',\n",
       "  'dare',\n",
       "  'say',\n",
       "  'didn',\n",
       "  'know',\n",
       "  'you',\n",
       "  'are',\n",
       "  'a',\n",
       "  'guilty',\n",
       "  'a',\n",
       "  'fudge'],\n",
       " ['today', 'insight', 'on'],\n",
       " ['hardly',\n",
       "  'ever',\n",
       "  'an',\n",
       "  'informative',\n",
       "  'comment',\n",
       "  'here',\n",
       "  'and',\n",
       "  'the',\n",
       "  'page',\n",
       "  'is',\n",
       "  'broken',\n",
       "  'giving',\n",
       "  'endless',\n",
       "  'buffering',\n",
       "  'icon',\n",
       "  'give',\n",
       "  'up',\n",
       "  'stocktwits'],\n",
       " ['viral',\n",
       "  'walk',\n",
       "  'away',\n",
       "  'video',\n",
       "  'highlight',\n",
       "  'growing',\n",
       "  'movement',\n",
       "  'of',\n",
       "  'democrat',\n",
       "  'leaving',\n",
       "  'the',\n",
       "  'party',\n",
       "  'the',\n",
       "  'epoch',\n",
       "  'time'],\n",
       " ['staanalystalert',\n",
       "  'for',\n",
       "  'robert',\n",
       "  'baird',\n",
       "  'downgrade',\n",
       "  'with',\n",
       "  'rating',\n",
       "  'of',\n",
       "  'neutral',\n",
       "  'setting',\n",
       "  'target',\n",
       "  'price',\n",
       "  'at',\n",
       "  'usd',\n",
       "  'our',\n",
       "  'own',\n",
       "  'verdict',\n",
       "  'is',\n",
       "  'buy'],\n",
       " ['too', 'much', 'weed', 'and', 'other', 'drug', 'guess'],\n",
       " ['with',\n",
       "  'forward',\n",
       "  'pe',\n",
       "  'of',\n",
       "  'the',\n",
       "  'valuation',\n",
       "  'of',\n",
       "  'can',\n",
       "  'be',\n",
       "  'described',\n",
       "  'a',\n",
       "  'very',\n",
       "  'reasonable'],\n",
       " ['the',\n",
       "  'reason',\n",
       "  'nike',\n",
       "  'is',\n",
       "  'winning',\n",
       "  'is',\n",
       "  'because',\n",
       "  'of',\n",
       "  'their',\n",
       "  'click',\n",
       "  'booking',\n",
       "  'app',\n",
       "  'it',\n",
       "  'better',\n",
       "  'than',\n",
       "  'native',\n",
       "  'seamless',\n",
       "  'lovalized',\n",
       "  'transactable',\n",
       "  'ap'],\n",
       " ['vitiello', 'tapped', 'a', 'acting', 'ice', 'director', 'via'],\n",
       " ['will',\n",
       "  'reach',\n",
       "  'over',\n",
       "  'this',\n",
       "  'year',\n",
       "  'iconic',\n",
       "  'brand',\n",
       "  'global',\n",
       "  'technology',\n",
       "  'and',\n",
       "  'built',\n",
       "  'for',\n",
       "  'mobile',\n",
       "  'winning',\n",
       "  'strategy',\n",
       "  'amp',\n",
       "  'show',\n",
       "  'in',\n",
       "  'earnings'],\n",
       " ['by', 'monday', 'morning'],\n",
       " ['this', 'is', 'heading', 'to', 'ath', 'soon', 'maybe', 'next', 'week'],\n",
       " ['staanalystalert',\n",
       "  'for',\n",
       "  'jefferies',\n",
       "  'downgrade',\n",
       "  'with',\n",
       "  'rating',\n",
       "  'of',\n",
       "  'hold',\n",
       "  'setting',\n",
       "  'target',\n",
       "  'price',\n",
       "  'at',\n",
       "  'usd',\n",
       "  'our',\n",
       "  'own',\n",
       "  'verdict',\n",
       "  'is',\n",
       "  'buy'],\n",
       " ['staanalystalert',\n",
       "  'for',\n",
       "  'baird',\n",
       "  'downgrade',\n",
       "  'with',\n",
       "  'rating',\n",
       "  'of',\n",
       "  'neutral',\n",
       "  'our',\n",
       "  'own',\n",
       "  'verdict',\n",
       "  'is',\n",
       "  'buy'],\n",
       " ['there',\n",
       "  'have',\n",
       "  'been',\n",
       "  'acquisition',\n",
       "  'for',\n",
       "  'total',\n",
       "  'of',\n",
       "  'share',\n",
       "  'over',\n",
       "  'the',\n",
       "  'past',\n",
       "  'week',\n",
       "  'for'],\n",
       " ['happy', 'trading', 'guy', 'looking', 'to', 'exit', 'today'],\n",
       " ['buy', 'zone'],\n",
       " [],\n",
       " ['fantastic',\n",
       "  'read',\n",
       "  'oil',\n",
       "  'market',\n",
       "  'continues',\n",
       "  'to',\n",
       "  'tighten',\n",
       "  'bbl',\n",
       "  'is',\n",
       "  'getting',\n",
       "  'closer'],\n",
       " ['one', 'of', 'the', 'greatest', 'buy'],\n",
       " ['looking',\n",
       "  'at',\n",
       "  'the',\n",
       "  'yearly',\n",
       "  'performance',\n",
       "  'did',\n",
       "  'better',\n",
       "  'than',\n",
       "  'of',\n",
       "  'all',\n",
       "  'other',\n",
       "  'stock'],\n",
       " ['at',\n",
       "  'amp',\n",
       "  'dividend',\n",
       "  'aristocrat',\n",
       "  'dividend',\n",
       "  'aristocrat',\n",
       "  'champion',\n",
       "  'cashflow',\n",
       "  'highyield',\n",
       "  'telecommunication',\n",
       "  'dividend'],\n",
       " ['that',\n",
       "  'pretty',\n",
       "  'risky',\n",
       "  'gamble',\n",
       "  'no',\n",
       "  'the',\n",
       "  'stock',\n",
       "  'can',\n",
       "  'either',\n",
       "  'plummet',\n",
       "  'or',\n",
       "  'rally'],\n",
       " ['the',\n",
       "  'short',\n",
       "  'sale',\n",
       "  'volume',\n",
       "  'not',\n",
       "  'short',\n",
       "  'interest',\n",
       "  'for',\n",
       "  'on',\n",
       "  'is'],\n",
       " ['stronger'],\n",
       " ['apple',\n",
       "  'valuation',\n",
       "  'profitability',\n",
       "  'and',\n",
       "  'dividend',\n",
       "  'safety',\n",
       "  'score',\n",
       "  'analysis',\n",
       "  'dividend',\n",
       "  'technology',\n",
       "  'dividend'],\n",
       " ['not', 'talking', 'about', 'wa', 'referring', 'to', 'intelsat'],\n",
       " ['will',\n",
       "  'punish',\n",
       "  'seller',\n",
       "  'who',\n",
       "  'don',\n",
       "  'move',\n",
       "  'stock',\n",
       "  'from',\n",
       "  'it',\n",
       "  'warehouse',\n",
       "  'common',\n",
       "  'sense',\n",
       "  'old',\n",
       "  'gather',\n",
       "  'dust',\n",
       "  'new',\n",
       "  'gather',\n",
       "  'money'],\n",
       " ['pc',\n",
       "  'gamers',\n",
       "  'crypto',\n",
       "  'miner',\n",
       "  'and',\n",
       "  'other',\n",
       "  'gpu',\n",
       "  'enthusiast',\n",
       "  'have',\n",
       "  'been',\n",
       "  'waiting',\n",
       "  'over',\n",
       "  'two',\n",
       "  'year',\n",
       "  'for',\n",
       "  'the',\n",
       "  'company',\n",
       "  'next',\n",
       "  'big'],\n",
       " ['ha',\n",
       "  'only',\n",
       "  'medium',\n",
       "  'technical',\n",
       "  'rating',\n",
       "  'but',\n",
       "  'it',\n",
       "  'doe',\n",
       "  'show',\n",
       "  'decent',\n",
       "  'setup',\n",
       "  'pattern'],\n",
       " ['today', 'insight', 'on'],\n",
       " ['what', 'will', 'be', 'more', 'in', 'five', 'year', 'baba', 'or', 'apple'],\n",
       " ['next', 'week', 'ahhhhhhhhhhhhhhhhhhhhh'],\n",
       " ['short', 'sale', 'volume', 'not', 'short', 'interest', 'for', 'is'],\n",
       " ['raytheon',\n",
       "  'valuation',\n",
       "  'profitability',\n",
       "  'and',\n",
       "  'dividend',\n",
       "  'safety',\n",
       "  'score',\n",
       "  'analysis',\n",
       "  'dividend',\n",
       "  'industrials',\n",
       "  'military'],\n",
       " ['why', 'we', 'trending'],\n",
       " ['we',\n",
       "  'will',\n",
       "  'get',\n",
       "  'riiiiiiiiiich',\n",
       "  'sooooon',\n",
       "  'buuuuls',\n",
       "  'looooove',\n",
       "  'you',\n",
       "  'all',\n",
       "  'and',\n",
       "  'fucking',\n",
       "  'drunk'],\n",
       " ['if',\n",
       "  'this',\n",
       "  'doesn',\n",
       "  'get',\n",
       "  'through',\n",
       "  'it',\n",
       "  'going',\n",
       "  'to',\n",
       "  'make',\n",
       "  'new',\n",
       "  'low',\n",
       "  'when',\n",
       "  'it',\n",
       "  'pay',\n",
       "  'the',\n",
       "  'dividend'],\n",
       " ['gapping', 'up', 'monday'],\n",
       " ['short', 'ratio', 'of', 'is', 'at', 'and', 'short', 'to', 'float', 'is'],\n",
       " ['staanalystalert',\n",
       "  'for',\n",
       "  'jefferies',\n",
       "  'maintains',\n",
       "  'with',\n",
       "  'rating',\n",
       "  'of',\n",
       "  'hold',\n",
       "  'setting',\n",
       "  'target',\n",
       "  'price',\n",
       "  'at',\n",
       "  'usd',\n",
       "  'our',\n",
       "  'own',\n",
       "  'verdict',\n",
       "  'is',\n",
       "  'buy'],\n",
       " ['should',\n",
       "  'by',\n",
       "  'warbey',\n",
       "  'parker',\n",
       "  'for',\n",
       "  'in',\n",
       "  'prep',\n",
       "  'for',\n",
       "  'apple',\n",
       "  'glass',\n",
       "  'a',\n",
       "  'seen',\n",
       "  'with',\n",
       "  'watch',\n",
       "  'apple',\n",
       "  'focus',\n",
       "  'on',\n",
       "  'fashion',\n",
       "  'and',\n",
       "  'tech',\n",
       "  'wrt',\n",
       "  'wearable'],\n",
       " ['look',\n",
       "  'like',\n",
       "  'sbux',\n",
       "  'is',\n",
       "  'paying',\n",
       "  'full',\n",
       "  'sex',\n",
       "  'change',\n",
       "  'for',\n",
       "  'employee',\n",
       "  'now',\n",
       "  'that',\n",
       "  'll',\n",
       "  'hit',\n",
       "  'the',\n",
       "  'bottom',\n",
       "  'line'],\n",
       " ['weekly',\n",
       "  'recap',\n",
       "  'price',\n",
       "  'moved',\n",
       "  'since',\n",
       "  'post',\n",
       "  'expect',\n",
       "  'run',\n",
       "  'up',\n",
       "  'to',\n",
       "  'other',\n",
       "  'trade',\n",
       "  'included',\n",
       "  'hsy',\n",
       "  'uri',\n",
       "  'sonc',\n",
       "  'dri',\n",
       "  'kmx',\n",
       "  'wynn',\n",
       "  'akam'],\n",
       " ['enterprise',\n",
       "  'value',\n",
       "  'v',\n",
       "  'market',\n",
       "  'cap',\n",
       "  'difference',\n",
       "  'of',\n",
       "  'actual',\n",
       "  'asset',\n",
       "  'v',\n",
       "  'market',\n",
       "  'value',\n",
       "  'too',\n",
       "  'big',\n",
       "  'spread',\n",
       "  'way',\n",
       "  'undervalued'],\n",
       " ['million', 'share', 'added', 'on', 'june', 'dont', 'wait'],\n",
       " ['who',\n",
       "  'think',\n",
       "  'amazon',\n",
       "  'will',\n",
       "  'become',\n",
       "  'such',\n",
       "  'monopoly',\n",
       "  'dipping',\n",
       "  'into',\n",
       "  'everything',\n",
       "  'that',\n",
       "  'an',\n",
       "  'amazon',\n",
       "  'airline',\n",
       "  'is',\n",
       "  'possibility',\n",
       "  'do'],\n",
       " ['don',\n",
       "  'miss',\n",
       "  'the',\n",
       "  'breakout',\n",
       "  'on',\n",
       "  'buy',\n",
       "  'stop',\n",
       "  'stop',\n",
       "  'loss',\n",
       "  'is',\n",
       "  'suggested',\n",
       "  'by',\n",
       "  'the',\n",
       "  'chartmill',\n",
       "  'analyzer'],\n",
       " ['short', 'sale', 'volume', 'not', 'short', 'interest', 'for', 'on', 'is'],\n",
       " ['weekly',\n",
       "  'recap',\n",
       "  'price',\n",
       "  'ha',\n",
       "  'moved',\n",
       "  'since',\n",
       "  'post',\n",
       "  'support',\n",
       "  'resistance',\n",
       "  'other',\n",
       "  'trade',\n",
       "  'included',\n",
       "  'uri',\n",
       "  'sonc',\n",
       "  'dri',\n",
       "  'kmx',\n",
       "  'wynn',\n",
       "  'akam',\n",
       "  'len'],\n",
       " ['weekly',\n",
       "  'recap',\n",
       "  'price',\n",
       "  'ha',\n",
       "  'moved',\n",
       "  'since',\n",
       "  'post',\n",
       "  'reversal',\n",
       "  'in',\n",
       "  'progress',\n",
       "  'other',\n",
       "  'trade',\n",
       "  'included',\n",
       "  'sonc',\n",
       "  'dri',\n",
       "  'kmx',\n",
       "  'wynn',\n",
       "  'akam',\n",
       "  'len',\n",
       "  'hsy'],\n",
       " ['ve',\n",
       "  'recently',\n",
       "  'closed',\n",
       "  'my',\n",
       "  'position',\n",
       "  'in',\n",
       "  'for',\n",
       "  'now',\n",
       "  'is',\n",
       "  'probably',\n",
       "  'next',\n",
       "  'on',\n",
       "  'the',\n",
       "  'list',\n",
       "  'bought',\n",
       "  'both',\n",
       "  'in',\n",
       "  'the',\n",
       "  'same',\n",
       "  'week'],\n",
       " ['nat',\n",
       "  'ricciardi',\n",
       "  'is',\n",
       "  'director',\n",
       "  'used',\n",
       "  'to',\n",
       "  'be',\n",
       "  'president',\n",
       "  'of',\n",
       "  'global',\n",
       "  'manufacturing'],\n",
       " ['according',\n",
       "  'to',\n",
       "  'data',\n",
       "  'reported',\n",
       "  'to',\n",
       "  'finra',\n",
       "  'short',\n",
       "  'volume',\n",
       "  'percent',\n",
       "  'for',\n",
       "  'clocked',\n",
       "  'in',\n",
       "  'at',\n",
       "  'on'],\n",
       " ['saudi',\n",
       "  'official',\n",
       "  'came',\n",
       "  'out',\n",
       "  'saying',\n",
       "  'they',\n",
       "  'didn',\n",
       "  'agree',\n",
       "  'to',\n",
       "  'this'],\n",
       " ['weekly',\n",
       "  'recap',\n",
       "  'price',\n",
       "  'moved',\n",
       "  'since',\n",
       "  'post',\n",
       "  'uptrend',\n",
       "  'to',\n",
       "  'resume',\n",
       "  'other',\n",
       "  'trade',\n",
       "  'included',\n",
       "  'kmx',\n",
       "  'wynn',\n",
       "  'akam',\n",
       "  'len',\n",
       "  'hsy',\n",
       "  'uri',\n",
       "  'sonc'],\n",
       " ['the',\n",
       "  'one',\n",
       "  'on',\n",
       "  'the',\n",
       "  'right',\n",
       "  'cover',\n",
       "  'the',\n",
       "  'penis',\n",
       "  'or',\n",
       "  'the',\n",
       "  'putang',\n",
       "  'the',\n",
       "  'front',\n",
       "  'leg',\n",
       "  'would',\n",
       "  'be',\n",
       "  'arm'],\n",
       " [],\n",
       " ['some', 'of', 'the', 'stock', 'am', 'watching', 'now'],\n",
       " ['short', 'ratio', 'of', 'is', 'at', 'and', 'short', 'to', 'float', 'is'],\n",
       " ['weekly',\n",
       "  'recap',\n",
       "  'price',\n",
       "  'moved',\n",
       "  'since',\n",
       "  'post',\n",
       "  'next',\n",
       "  'stop',\n",
       "  'other',\n",
       "  'trade',\n",
       "  'included',\n",
       "  'wynn',\n",
       "  'akam',\n",
       "  'len',\n",
       "  'hsy',\n",
       "  'uri',\n",
       "  'sonc',\n",
       "  'dri'],\n",
       " ['wonder',\n",
       "  'how',\n",
       "  'much',\n",
       "  'this',\n",
       "  'will',\n",
       "  'be',\n",
       "  'valued',\n",
       "  'at',\n",
       "  'in',\n",
       "  'year',\n",
       "  'we',\n",
       "  'are',\n",
       "  'not',\n",
       "  'even',\n",
       "  'in',\n",
       "  'the',\n",
       "  'th',\n",
       "  'inning'],\n",
       " ['ha',\n",
       "  'bad',\n",
       "  'technical',\n",
       "  'rating',\n",
       "  'but',\n",
       "  'it',\n",
       "  'doe',\n",
       "  'show',\n",
       "  'decent',\n",
       "  'setup',\n",
       "  'pattern'],\n",
       " ['is',\n",
       "  'going',\n",
       "  'to',\n",
       "  'make',\n",
       "  'big',\n",
       "  'move',\n",
       "  'higher',\n",
       "  'also',\n",
       "  'watching',\n",
       "  'apple',\n",
       "  'think',\n",
       "  'they',\n",
       "  'shorted',\n",
       "  'the',\n",
       "  'put',\n",
       "  'spread',\n",
       "  'for',\n",
       "  'july'],\n",
       " ['weekly',\n",
       "  'recap',\n",
       "  'price',\n",
       "  'moved',\n",
       "  'since',\n",
       "  'post',\n",
       "  'expect',\n",
       "  'consolidation',\n",
       "  'other',\n",
       "  'trade',\n",
       "  'included',\n",
       "  'akam',\n",
       "  'len',\n",
       "  'hsy',\n",
       "  'uri',\n",
       "  'sonc',\n",
       "  'dri',\n",
       "  'kmx'],\n",
       " ['it',\n",
       "  'good',\n",
       "  'that',\n",
       "  'even',\n",
       "  'bull',\n",
       "  'are',\n",
       "  'cautious',\n",
       "  'stunned',\n",
       "  'bearish',\n",
       "  'deeply',\n",
       "  'disappointed',\n",
       "  'too',\n",
       "  'bad',\n",
       "  'continues',\n",
       "  'it',\n",
       "  'old',\n",
       "  'way',\n",
       "  'hopefully',\n",
       "  'we',\n",
       "  'are',\n",
       "  'close'],\n",
       " ['weekly',\n",
       "  'recap',\n",
       "  'price',\n",
       "  'moved',\n",
       "  'since',\n",
       "  'post',\n",
       "  'support',\n",
       "  'other',\n",
       "  'trade',\n",
       "  'included',\n",
       "  'len',\n",
       "  'hsy',\n",
       "  'uri',\n",
       "  'sonc',\n",
       "  'dri',\n",
       "  'kmx',\n",
       "  'wynn'],\n",
       " ['ending', 'june', 'killed', 'it', 'best', 'month', 'since', 'february'],\n",
       " ['funny',\n",
       "  'how',\n",
       "  'long',\n",
       "  'the',\n",
       "  'same',\n",
       "  'thing',\n",
       "  'ha',\n",
       "  'been',\n",
       "  'going',\n",
       "  'on',\n",
       "  'with',\n",
       "  'this',\n",
       "  'about',\n",
       "  'year',\n",
       "  'of',\n",
       "  'this',\n",
       "  'similar',\n",
       "  'story',\n",
       "  'different',\n",
       "  'day'],\n",
       " ['bearish',\n",
       "  'crab',\n",
       "  'well',\n",
       "  'measured',\n",
       "  'bearish',\n",
       "  'crab',\n",
       "  'with',\n",
       "  'bearish',\n",
       "  'divergence',\n",
       "  'you',\n",
       "  'can',\n",
       "  'really',\n",
       "  'see',\n",
       "  'the',\n",
       "  'momentum',\n",
       "  'starting',\n",
       "  'to',\n",
       "  'shi'],\n",
       " ['staanalystalert',\n",
       "  'for',\n",
       "  'jefferies',\n",
       "  'maintains',\n",
       "  'with',\n",
       "  'rating',\n",
       "  'of',\n",
       "  'buy',\n",
       "  'setting',\n",
       "  'target',\n",
       "  'price',\n",
       "  'at',\n",
       "  'usd',\n",
       "  'our',\n",
       "  'own',\n",
       "  'verdict',\n",
       "  'is',\n",
       "  'buy'],\n",
       " ['google', 'venture', 'company'],\n",
       " ['tariff',\n",
       "  'increase',\n",
       "  'profit',\n",
       "  'how',\n",
       "  'can',\n",
       "  'it',\n",
       "  'be',\n",
       "  'bad',\n",
       "  'recession',\n",
       "  'if',\n",
       "  'it',\n",
       "  'come',\n",
       "  'is',\n",
       "  'year',\n",
       "  'down',\n",
       "  'the',\n",
       "  'line',\n",
       "  'keep',\n",
       "  'buying',\n",
       "  'short',\n",
       "  'pure',\n",
       "  'bull'],\n",
       " ['beanscreen', 'for'],\n",
       " ['the',\n",
       "  'min',\n",
       "  'chart',\n",
       "  'from',\n",
       "  'friday',\n",
       "  'indicating',\n",
       "  'some',\n",
       "  'nice',\n",
       "  'accumulation',\n",
       "  'at',\n",
       "  'eod',\n",
       "  'could',\n",
       "  'be',\n",
       "  'nice',\n",
       "  'pop',\n",
       "  'monday'],\n",
       " ['short', 'sale', 'volume', 'not', 'short', 'interest', 'for', 'at', 'is'],\n",
       " ['weekly',\n",
       "  'recap',\n",
       "  'price',\n",
       "  'moved',\n",
       "  'since',\n",
       "  'post',\n",
       "  'heavy',\n",
       "  'resistance',\n",
       "  'at',\n",
       "  'other',\n",
       "  'trade',\n",
       "  'included',\n",
       "  'apog',\n",
       "  'acn',\n",
       "  'camp',\n",
       "  'gi',\n",
       "  'payx',\n",
       "  'fdx',\n",
       "  'goo'],\n",
       " ['can', 'we', 'squeeze', 'the', 'short'],\n",
       " ['weekly',\n",
       "  'recap',\n",
       "  'price',\n",
       "  'moved',\n",
       "  'since',\n",
       "  'post',\n",
       "  'pullback',\n",
       "  'to',\n",
       "  'before',\n",
       "  'more',\n",
       "  'upside',\n",
       "  'other',\n",
       "  'trade',\n",
       "  'included',\n",
       "  'camp',\n",
       "  'gi',\n",
       "  'payx',\n",
       "  'fdx',\n",
       "  'goo',\n",
       "  'nvda',\n",
       "  'apog'],\n",
       " ['still', 'holding', 'call', 'for', 'next', 'week'],\n",
       " ['is', 'safe', 'but', 'their', 'buyback', 'yield', 'is', 'div', 'yield'],\n",
       " ['adding',\n",
       "  'at',\n",
       "  'gladly',\n",
       "  'let',\n",
       "  'irrationality',\n",
       "  'reign',\n",
       "  'a',\n",
       "  'long',\n",
       "  'a',\n",
       "  'possible',\n",
       "  'excess',\n",
       "  'gain',\n",
       "  'are',\n",
       "  'welcome',\n",
       "  'gl'],\n",
       " ['looking',\n",
       "  'at',\n",
       "  'friday',\n",
       "  'data',\n",
       "  'seeing',\n",
       "  'different',\n",
       "  'story',\n",
       "  'on',\n",
       "  'the',\n",
       "  'chart',\n",
       "  'take',\n",
       "  'look',\n",
       "  'and',\n",
       "  'tell',\n",
       "  'me',\n",
       "  'what',\n",
       "  'you',\n",
       "  'think'],\n",
       " ['the',\n",
       "  'short',\n",
       "  'probably',\n",
       "  'aren',\n",
       "  'jumping',\n",
       "  'for',\n",
       "  'joy',\n",
       "  'today',\n",
       "  'in',\n",
       "  'at',\n",
       "  'least',\n",
       "  'for',\n",
       "  'given',\n",
       "  'the',\n",
       "  'price',\n",
       "  'action'],\n",
       " ['bouncing',\n",
       "  'off',\n",
       "  'support',\n",
       "  'need',\n",
       "  'continuation',\n",
       "  'next',\n",
       "  'week',\n",
       "  'make',\n",
       "  'me',\n",
       "  'feel',\n",
       "  'more',\n",
       "  'hopeful',\n",
       "  'for'],\n",
       " ['data',\n",
       "  'science',\n",
       "  'officially',\n",
       "  'became',\n",
       "  'major',\n",
       "  'in',\n",
       "  'university',\n",
       "  'this',\n",
       "  'year',\n",
       "  'to',\n",
       "  'support',\n",
       "  'ai',\n",
       "  'industry',\n",
       "  'these',\n",
       "  'are',\n",
       "  'no',\n",
       "  'brainers',\n",
       "  'in',\n",
       "  'the',\n",
       "  'data',\n",
       "  'era'],\n",
       " ['short', 'ratio', 'of', 'is', 'at', 'and', 'short', 'to', 'float', 'is'],\n",
       " [],\n",
       " ['weekly',\n",
       "  'recap',\n",
       "  'price',\n",
       "  'moved',\n",
       "  'since',\n",
       "  'post',\n",
       "  'support',\n",
       "  'at',\n",
       "  'other',\n",
       "  'trade',\n",
       "  'included',\n",
       "  'payx',\n",
       "  'fdx',\n",
       "  'goo',\n",
       "  'nvda',\n",
       "  'apog',\n",
       "  'acn',\n",
       "  'camp'],\n",
       " ['short', 'sale', 'volume', 'not', 'short', 'interest', 'for', 'on', 'is'],\n",
       " [],\n",
       " ['ha',\n",
       "  'better',\n",
       "  'return',\n",
       "  'on',\n",
       "  'equity',\n",
       "  'than',\n",
       "  'the',\n",
       "  'industry',\n",
       "  'average',\n",
       "  'of'],\n",
       " ['second', 'not', 'minute'],\n",
       " ['weekly',\n",
       "  'recap',\n",
       "  'price',\n",
       "  'moved',\n",
       "  'since',\n",
       "  'post',\n",
       "  'rule',\n",
       "  'applies',\n",
       "  'here',\n",
       "  'other',\n",
       "  'trade',\n",
       "  'included',\n",
       "  'zbra',\n",
       "  'six',\n",
       "  'fc',\n",
       "  'gbx',\n",
       "  'fds',\n",
       "  'avav',\n",
       "  'baba'],\n",
       " ['trump',\n",
       "  'is',\n",
       "  'killing',\n",
       "  'the',\n",
       "  'tax',\n",
       "  'cut',\n",
       "  'with',\n",
       "  'oil',\n",
       "  'price',\n",
       "  'and',\n",
       "  'tariff',\n",
       "  'no',\n",
       "  'idea',\n",
       "  'what',\n",
       "  'he',\n",
       "  'doing',\n",
       "  'right',\n",
       "  'now'],\n",
       " ['haven',\n",
       "  'posted',\n",
       "  'on',\n",
       "  'stocktwits',\n",
       "  'in',\n",
       "  'while',\n",
       "  'these',\n",
       "  'weekly',\n",
       "  'chart',\n",
       "  'look',\n",
       "  'good'],\n",
       " ['today', 'insight', 'on'],\n",
       " ['omg', 'toy', 'story', 'land', 'look', 'amazing'],\n",
       " ['stock',\n",
       "  'have',\n",
       "  'contributed',\n",
       "  'of',\n",
       "  'ytd',\n",
       "  'return',\n",
       "  'what',\n",
       "  'do',\n",
       "  'you',\n",
       "  'own'],\n",
       " ['today', 'insight', 'on'],\n",
       " ['my', 'rd', 'most', 'popular', 'word'],\n",
       " ['trump',\n",
       "  'tweet',\n",
       "  'and',\n",
       "  'then',\n",
       "  'he',\n",
       "  'may',\n",
       "  'be',\n",
       "  'buyin',\n",
       "  'those',\n",
       "  'dip',\n",
       "  'haha',\n",
       "  'still',\n",
       "  'makin',\n",
       "  'it',\n",
       "  'rain',\n",
       "  'up',\n",
       "  'in',\n",
       "  'the',\n",
       "  'white',\n",
       "  'house'],\n",
       " ['ha',\n",
       "  'poor',\n",
       "  'technical',\n",
       "  'rating',\n",
       "  'and',\n",
       "  'the',\n",
       "  'quality',\n",
       "  'of',\n",
       "  'the',\n",
       "  'setup',\n",
       "  'is',\n",
       "  'also',\n",
       "  'not',\n",
       "  'perfect',\n",
       "  'at',\n",
       "  'the',\n",
       "  'moment'],\n",
       " ['doubt',\n",
       "  'it',\n",
       "  'go',\n",
       "  'down',\n",
       "  'monday',\n",
       "  'and',\n",
       "  'doubt',\n",
       "  'saudi',\n",
       "  'arabia',\n",
       "  'increase',\n",
       "  'production'],\n",
       " ['measured',\n",
       "  'over',\n",
       "  'the',\n",
       "  'past',\n",
       "  'year',\n",
       "  'show',\n",
       "  'very',\n",
       "  'strong',\n",
       "  'growth',\n",
       "  'in',\n",
       "  'eps'],\n",
       " ['constellation', 'brand'],\n",
       " ['the',\n",
       "  'short',\n",
       "  'probably',\n",
       "  'aren',\n",
       "  'jumping',\n",
       "  'for',\n",
       "  'joy',\n",
       "  'today',\n",
       "  'in',\n",
       "  'at',\n",
       "  'least',\n",
       "  'for',\n",
       "  'given',\n",
       "  'the',\n",
       "  'price',\n",
       "  'action'],\n",
       " ['here'],\n",
       " ['did', 'disney', 'just', 'clinch', 'the', 'deal', 'to', 'acquire', 'fox'],\n",
       " ['new', 'way', 'match', 'group', 'can', 'counter', 'facebook'],\n",
       " ['aggregate',\n",
       "  'short',\n",
       "  'volume',\n",
       "  'reported',\n",
       "  'to',\n",
       "  'finra',\n",
       "  'for',\n",
       "  'wa',\n",
       "  'on'],\n",
       " ['southwest',\n",
       "  'airline',\n",
       "  'is',\n",
       "  'adding',\n",
       "  'flight',\n",
       "  'in',\n",
       "  'dallas',\n",
       "  'a',\n",
       "  'delta',\n",
       "  'spat',\n",
       "  'continues'],\n",
       " ['what', 'california'],\n",
       " ['better', 'buy', 'netflix', 'inc', 'nflx', 'versus', 'facebook', 'fb'],\n",
       " ['one', 'thing', 'that', 'starbucks', 'is', 'doing', 'wrong'],\n",
       " [],\n",
       " ['using',\n",
       "  'iex',\n",
       "  'data',\n",
       "  'we',\n",
       "  'calculate',\n",
       "  'that',\n",
       "  'shorters',\n",
       "  'have',\n",
       "  'lost',\n",
       "  'in',\n",
       "  'on'],\n",
       " ['bull',\n",
       "  'list',\n",
       "  'after',\n",
       "  'their',\n",
       "  'emergence',\n",
       "  'from',\n",
       "  'bankruptcy',\n",
       "  'emergency'],\n",
       " ['zwj',\n",
       "  'investment',\n",
       "  'counsel',\n",
       "  'inc',\n",
       "  'lower',\n",
       "  'stake',\n",
       "  'in',\n",
       "  'unitedhealth',\n",
       "  'group',\n",
       "  'inc',\n",
       "  'unh'],\n",
       " ['list', 'of', 'tyzen', 'and', 'vega', 'laptop', 'a', 'of', 'june', 'th'],\n",
       " ['investing',\n",
       "  'in',\n",
       "  'the',\n",
       "  'company',\n",
       "  'like',\n",
       "  'an',\n",
       "  'annuity',\n",
       "  'or',\n",
       "  'yr',\n",
       "  'bond',\n",
       "  'continue',\n",
       "  'to',\n",
       "  'add',\n",
       "  'share',\n",
       "  'unsure',\n",
       "  'if',\n",
       "  'the',\n",
       "  'country',\n",
       "  'is',\n",
       "  'growing',\n",
       "  'amd',\n",
       "  'is'],\n",
       " ['list', 'of', 'ryzen', 'and', 'vega', 'laptop', 'a', 'of'],\n",
       " ['gettin', 'blasted'],\n",
       " ['weekly',\n",
       "  'recap',\n",
       "  'price',\n",
       "  'moved',\n",
       "  'since',\n",
       "  'post',\n",
       "  'strong',\n",
       "  'support',\n",
       "  'at',\n",
       "  'current',\n",
       "  'price',\n",
       "  'other',\n",
       "  'trade',\n",
       "  'included',\n",
       "  'cgnx',\n",
       "  'cx',\n",
       "  'aaoi',\n",
       "  'aa',\n",
       "  'amswa',\n",
       "  'yy',\n",
       "  'snx'],\n",
       " ['bearish',\n",
       "  'shark',\n",
       "  'bearish',\n",
       "  'shark',\n",
       "  'with',\n",
       "  'bearish',\n",
       "  'divergence',\n",
       "  'am',\n",
       "  'definitely',\n",
       "  'jumping',\n",
       "  'into',\n",
       "  'the',\n",
       "  'august',\n",
       "  'put',\n",
       "  'on',\n",
       "  'monday'],\n",
       " ['so',\n",
       "  'is',\n",
       "  'g',\n",
       "  'going',\n",
       "  'to',\n",
       "  'give',\n",
       "  'u',\n",
       "  'price',\n",
       "  'point',\n",
       "  'before',\n",
       "  'or',\n",
       "  'after',\n",
       "  'earnings'],\n",
       " ['the',\n",
       "  'short',\n",
       "  'sale',\n",
       "  'volume',\n",
       "  'not',\n",
       "  'short',\n",
       "  'interest',\n",
       "  'for',\n",
       "  'on',\n",
       "  'is'],\n",
       " ['huge', 'volume', 'at', 'closing', 'on', 'friday'],\n",
       " ['looking', 'for', 'scalp'],\n",
       " ['this',\n",
       "  'is',\n",
       "  'one',\n",
       "  'giant',\n",
       "  'fermenting',\n",
       "  'turd',\n",
       "  'of',\n",
       "  'stock',\n",
       "  'when',\n",
       "  'will',\n",
       "  'it',\n",
       "  'go',\n",
       "  'back',\n",
       "  'up',\n",
       "  'to'],\n",
       " ['buffet', 'and', 'are', 'buying', 'at', 'per', 'share'],\n",
       " ['in', 'put', 'from', 'last', 'week', 'target', 'zone', 'marked'],\n",
       " ['option',\n",
       "  'volume',\n",
       "  'wa',\n",
       "  'normal',\n",
       "  'on',\n",
       "  'friday',\n",
       "  'with',\n",
       "  'contract',\n",
       "  'call',\n",
       "  'volume',\n",
       "  'wa',\n",
       "  'and',\n",
       "  'put',\n",
       "  'volume',\n",
       "  'wa'],\n",
       " ['compared',\n",
       "  'to',\n",
       "  'an',\n",
       "  'average',\n",
       "  'industry',\n",
       "  'price',\n",
       "  'book',\n",
       "  'ratio',\n",
       "  'of',\n",
       "  'is',\n",
       "  'valued',\n",
       "  'rather',\n",
       "  'cheaply'],\n",
       " ['the',\n",
       "  'eps',\n",
       "  'ha',\n",
       "  'been',\n",
       "  'growing',\n",
       "  'by',\n",
       "  'on',\n",
       "  'average',\n",
       "  'over',\n",
       "  'the',\n",
       "  'past',\n",
       "  'year',\n",
       "  'this',\n",
       "  'is',\n",
       "  'quite',\n",
       "  'good'],\n",
       " ['mitch',\n",
       "  'did',\n",
       "  'great',\n",
       "  'job',\n",
       "  'of',\n",
       "  'getting',\n",
       "  'netflix',\n",
       "  'started',\n",
       "  'he',\n",
       "  'clearly',\n",
       "  'know',\n",
       "  'how',\n",
       "  'to',\n",
       "  'make',\n",
       "  'big',\n",
       "  'thing',\n",
       "  'happen',\n",
       "  'in',\n",
       "  'this',\n",
       "  'industry'],\n",
       " ['cup',\n",
       "  'and',\n",
       "  'holder',\n",
       "  'inverse',\n",
       "  'bearish',\n",
       "  'with',\n",
       "  'confidence',\n",
       "  'to',\n",
       "  'reach',\n",
       "  'target',\n",
       "  'price',\n",
       "  'usd'],\n",
       " ['with',\n",
       "  'debt',\n",
       "  'to',\n",
       "  'equity',\n",
       "  'ratio',\n",
       "  'of',\n",
       "  'is',\n",
       "  'doing',\n",
       "  'better',\n",
       "  'than',\n",
       "  'the',\n",
       "  'average',\n",
       "  'in',\n",
       "  'the',\n",
       "  'industry'],\n",
       " ['sell',\n",
       "  'in',\n",
       "  'may',\n",
       "  'amp',\n",
       "  'go',\n",
       "  'away',\n",
       "  'ha',\n",
       "  'been',\n",
       "  'pattern',\n",
       "  'for',\n",
       "  'year',\n",
       "  'interesting',\n",
       "  'to',\n",
       "  'see',\n",
       "  'so',\n",
       "  'much',\n",
       "  'trading',\n",
       "  'in',\n",
       "  'this',\n",
       "  'time',\n",
       "  'frame',\n",
       "  'bank',\n",
       "  'love',\n",
       "  'you',\n",
       "  'trader'],\n",
       " ['meanwhile', 'in', 'galaxy', 'far', 'far', 'away'],\n",
       " ['broadening',\n",
       "  'wedge',\n",
       "  'descending',\n",
       "  'bearish',\n",
       "  'with',\n",
       "  'confidence',\n",
       "  'to',\n",
       "  'reach',\n",
       "  'target',\n",
       "  'price',\n",
       "  'usd'],\n",
       " ['happy', 'trading', 'guy', 'looking', 'to', 'exit', 'today'],\n",
       " ['large', 'put', 'spread', 'in', 'open', 'interest', 'im', 'bearish'],\n",
       " [],\n",
       " ['pt'],\n",
       " ['three',\n",
       "  'falling',\n",
       "  'peak',\n",
       "  'bearish',\n",
       "  'with',\n",
       "  'confidence',\n",
       "  'to',\n",
       "  'reach',\n",
       "  'target',\n",
       "  'price',\n",
       "  'usd'],\n",
       " ['happy',\n",
       "  'fourth',\n",
       "  'everyone',\n",
       "  'have',\n",
       "  'coke',\n",
       "  'and',\n",
       "  'smile',\n",
       "  'thanks',\n",
       "  'for',\n",
       "  'the',\n",
       "  'dividend',\n",
       "  'and'],\n",
       " [],\n",
       " ['selling', 'will', 'prove', 'to', 'be', 'terrible', 'error'],\n",
       " ['the',\n",
       "  'end',\n",
       "  'of',\n",
       "  'the',\n",
       "  'article',\n",
       "  'just',\n",
       "  'posted',\n",
       "  'hint',\n",
       "  'at',\n",
       "  'possible',\n",
       "  'acquisition',\n",
       "  'of',\n",
       "  'sogou',\n",
       "  'finger',\n",
       "  'crossed'],\n",
       " ['triple',\n",
       "  'top',\n",
       "  'bearish',\n",
       "  'with',\n",
       "  'confidence',\n",
       "  'to',\n",
       "  'reach',\n",
       "  'target',\n",
       "  'price',\n",
       "  'usd'],\n",
       " ['short', 'sale', 'volume', 'not', 'short', 'interest', 'for', 'on', 'is'],\n",
       " ['bro',\n",
       "  'that',\n",
       "  'not',\n",
       "  'how',\n",
       "  'it',\n",
       "  'work',\n",
       "  'delete',\n",
       "  'the',\n",
       "  'blue',\n",
       "  'arrow',\n",
       "  'that',\n",
       "  'your',\n",
       "  'delusion'],\n",
       " ['let',\n",
       "  'me',\n",
       "  'guess',\n",
       "  'everyone',\n",
       "  'is',\n",
       "  'still',\n",
       "  'bullish',\n",
       "  'here',\n",
       "  'even',\n",
       "  'after',\n",
       "  'it',\n",
       "  'close',\n",
       "  'under',\n",
       "  'the',\n",
       "  'ma',\n",
       "  'on',\n",
       "  'the',\n",
       "  'daily',\n",
       "  'overbought',\n",
       "  'level',\n",
       "  'trend',\n",
       "  'is',\n",
       "  'changing'],\n",
       " ['cup',\n",
       "  'and',\n",
       "  'holder',\n",
       "  'bullish',\n",
       "  'with',\n",
       "  'confidence',\n",
       "  'to',\n",
       "  'reach',\n",
       "  'target',\n",
       "  'price',\n",
       "  'usd'],\n",
       " ['mr', 'hold', 'yo'],\n",
       " ['option',\n",
       "  'volume',\n",
       "  'wa',\n",
       "  'normal',\n",
       "  'on',\n",
       "  'friday',\n",
       "  'with',\n",
       "  'contract',\n",
       "  'call',\n",
       "  'volume',\n",
       "  'wa',\n",
       "  'and',\n",
       "  'put',\n",
       "  'volume',\n",
       "  'wa'],\n",
       " ['hi',\n",
       "  'everyone',\n",
       "  'going',\n",
       "  'to',\n",
       "  'bed',\n",
       "  'good',\n",
       "  'night',\n",
       "  'everyone',\n",
       "  'happy',\n",
       "  'money',\n",
       "  'monday',\n",
       "  'soon',\n",
       "  'be',\n",
       "  'prepared'],\n",
       " ['short', 'sale', 'volume', 'not', 'short', 'interest', 'for', 'is'],\n",
       " ['amazon',\n",
       "  'new',\n",
       "  'warehouse',\n",
       "  'policy',\n",
       "  'will',\n",
       "  'start',\n",
       "  'penalizing',\n",
       "  'seller',\n",
       "  'that',\n",
       "  'store',\n",
       "  'product',\n",
       "  'for',\n",
       "  'too',\n",
       "  'long'],\n",
       " ['just',\n",
       "  'fyi',\n",
       "  'trump',\n",
       "  'era',\n",
       "  'ramp',\n",
       "  'up',\n",
       "  'tech',\n",
       "  'worker',\n",
       "  'revolt',\n",
       "  'the',\n",
       "  'hill'],\n",
       " ['this',\n",
       "  'company',\n",
       "  'going',\n",
       "  'off',\n",
       "  'the',\n",
       "  'rail',\n",
       "  'the',\n",
       "  'people',\n",
       "  'that',\n",
       "  'work',\n",
       "  'there',\n",
       "  'and',\n",
       "  'the',\n",
       "  'store',\n",
       "  'manager',\n",
       "  'say',\n",
       "  'it',\n",
       "  'all',\n",
       "  'circuit',\n",
       "  'city',\n",
       "  'deux'],\n",
       " ['why',\n",
       "  'did',\n",
       "  'bank',\n",
       "  'fail',\n",
       "  'to',\n",
       "  'rally',\n",
       "  'despite',\n",
       "  'huge',\n",
       "  'bb',\n",
       "  'and',\n",
       "  'div',\n",
       "  'incr',\n",
       "  'me',\n",
       "  'thinking',\n",
       "  'mm',\n",
       "  'driving',\n",
       "  'down',\n",
       "  'price',\n",
       "  'to',\n",
       "  'get',\n",
       "  'in',\n",
       "  'on',\n",
       "  'the',\n",
       "  'cheap',\n",
       "  'prior',\n",
       "  'the',\n",
       "  'rally'],\n",
       " ['bear',\n",
       "  'using',\n",
       "  'all',\n",
       "  'argument',\n",
       "  'sound',\n",
       "  'like',\n",
       "  'short',\n",
       "  'position',\n",
       "  'are',\n",
       "  'becoming',\n",
       "  'loses',\n",
       "  'this',\n",
       "  'week'],\n",
       " ['gameranx', 'popular', 'youtube', 'gaming', 'channel'],\n",
       " ['facebook', 'the', 'cash', 'machine'],\n",
       " ['and',\n",
       "  'it',\n",
       "  'will',\n",
       "  'take',\n",
       "  'all',\n",
       "  'semi',\n",
       "  'up',\n",
       "  'more',\n",
       "  'week',\n",
       "  'and',\n",
       "  'then',\n",
       "  'uptrend',\n",
       "  'continues'],\n",
       " ['cheap',\n",
       "  'dividend',\n",
       "  'champion',\n",
       "  'with',\n",
       "  'low',\n",
       "  'forward',\n",
       "  'altria',\n",
       "  'aflac',\n",
       "  'eatonvance'],\n",
       " ['look',\n",
       "  'at',\n",
       "  'the',\n",
       "  'graph',\n",
       "  'tripple',\n",
       "  'bottom',\n",
       "  'reached',\n",
       "  'for',\n",
       "  'heading',\n",
       "  'to',\n",
       "  'and',\n",
       "  'to',\n",
       "  'in',\n",
       "  'to',\n",
       "  'week'],\n",
       " ['if',\n",
       "  'you',\n",
       "  'have',\n",
       "  'penis',\n",
       "  'and',\n",
       "  'want',\n",
       "  'vagina',\n",
       "  'like',\n",
       "  'alteration',\n",
       "  'go',\n",
       "  'get',\n",
       "  'job',\n",
       "  'at',\n",
       "  'sbux'],\n",
       " ['oled',\n",
       "  'panel',\n",
       "  'post',\n",
       "  'steady',\n",
       "  'growth',\n",
       "  'amid',\n",
       "  'weak',\n",
       "  'demand',\n",
       "  'in',\n",
       "  'display',\n",
       "  'market',\n",
       "  'data'],\n",
       " ['facebook', 'the', 'cash', 'machine'],\n",
       " [],\n",
       " ['option',\n",
       "  'volume',\n",
       "  'wa',\n",
       "  'normal',\n",
       "  'on',\n",
       "  'friday',\n",
       "  'with',\n",
       "  'contract',\n",
       "  'call',\n",
       "  'volume',\n",
       "  'wa',\n",
       "  'and',\n",
       "  'put',\n",
       "  'volume',\n",
       "  'wa'],\n",
       " ['microsoft',\n",
       "  'andromeda',\n",
       "  'leak',\n",
       "  'foldable',\n",
       "  'dual',\n",
       "  'screen',\n",
       "  'surface',\n",
       "  'device',\n",
       "  'that',\n",
       "  'fit',\n",
       "  'in',\n",
       "  'your',\n",
       "  'pocket'],\n",
       " ['the',\n",
       "  'short',\n",
       "  'sale',\n",
       "  'volume',\n",
       "  'not',\n",
       "  'short',\n",
       "  'interest',\n",
       "  'for',\n",
       "  'on',\n",
       "  'is'],\n",
       " ['ha',\n",
       "  'good',\n",
       "  'piotroski',\n",
       "  'score',\n",
       "  'of',\n",
       "  'this',\n",
       "  'indicates',\n",
       "  'good',\n",
       "  'health',\n",
       "  'and',\n",
       "  'profitability'],\n",
       " ['short',\n",
       "  'interest',\n",
       "  'ratio',\n",
       "  'of',\n",
       "  'is',\n",
       "  'at',\n",
       "  'and',\n",
       "  'short',\n",
       "  'to',\n",
       "  'float',\n",
       "  'is'],\n",
       " ['my',\n",
       "  'original',\n",
       "  'thesis',\n",
       "  'wa',\n",
       "  'predicated',\n",
       "  'on',\n",
       "  'amd',\n",
       "  'having',\n",
       "  'competitive',\n",
       "  'server',\n",
       "  'product',\n",
       "  'around',\n",
       "  'this',\n",
       "  'time',\n",
       "  'didn',\n",
       "  'think',\n",
       "  'intel',\n",
       "  'would',\n",
       "  'shit',\n",
       "  'the',\n",
       "  'bed'],\n",
       " ['bullish', 'bat', 'bullish', 'bat', 'with', 'bullish', 'divergence'],\n",
       " ['epyc',\n",
       "  'server',\n",
       "  'adoption',\n",
       "  'will',\n",
       "  'snow',\n",
       "  'ball',\n",
       "  'this',\n",
       "  'year',\n",
       "  'intel',\n",
       "  'security',\n",
       "  'flaw',\n",
       "  'nm',\n",
       "  'fail',\n",
       "  'fire',\n",
       "  'ceo',\n",
       "  'you',\n",
       "  'can',\n",
       "  'make',\n",
       "  'this',\n",
       "  'sh',\n",
       "  'up'],\n",
       " ['my',\n",
       "  'original',\n",
       "  'thesis',\n",
       "  'wa',\n",
       "  'predicated',\n",
       "  'on',\n",
       "  'amd',\n",
       "  'having',\n",
       "  'competitive',\n",
       "  'server',\n",
       "  'product',\n",
       "  'around',\n",
       "  'this',\n",
       "  'time',\n",
       "  'didn',\n",
       "  'think',\n",
       "  'intel',\n",
       "  'would',\n",
       "  'sh',\n",
       "  'the',\n",
       "  'bed'],\n",
       " ['think', 'will', 'buy', 'a', 'many', 'a', 'can', 'under'],\n",
       " ['new', 'way', 'match', 'group', 'can', 'counter', 'facebook'],\n",
       " ['wowza',\n",
       "  'for',\n",
       "  'if',\n",
       "  'started',\n",
       "  'one',\n",
       "  'month',\n",
       "  'ago',\n",
       "  'the',\n",
       "  'short',\n",
       "  'return',\n",
       "  'would',\n",
       "  'be',\n",
       "  'around',\n",
       "  'a',\n",
       "  'of',\n",
       "  'iex',\n",
       "  'data'],\n",
       " ['is',\n",
       "  'the',\n",
       "  'real',\n",
       "  'boom',\n",
       "  'in',\n",
       "  'the',\n",
       "  'social',\n",
       "  'medium',\n",
       "  'and',\n",
       "  'it',\n",
       "  'will',\n",
       "  'get',\n",
       "  'much',\n",
       "  'bigger',\n",
       "  'it',\n",
       "  'will',\n",
       "  'be',\n",
       "  'in',\n",
       "  'before',\n",
       "  'christmas'],\n",
       " ['the',\n",
       "  'current',\n",
       "  'ratio',\n",
       "  'of',\n",
       "  'is',\n",
       "  'much',\n",
       "  'better',\n",
       "  'than',\n",
       "  'the',\n",
       "  'industry',\n",
       "  'average',\n",
       "  'of'],\n",
       " ['celgene',\n",
       "  'investor',\n",
       "  'breathe',\n",
       "  'sigh',\n",
       "  'of',\n",
       "  'relief',\n",
       "  'after',\n",
       "  'acceleron',\n",
       "  'success'],\n",
       " ['bear',\n",
       "  'and',\n",
       "  'shorties',\n",
       "  'made',\n",
       "  'huge',\n",
       "  'mistake',\n",
       "  'and',\n",
       "  'they',\n",
       "  'don',\n",
       "  'have',\n",
       "  'the',\n",
       "  'money',\n",
       "  'to',\n",
       "  'buy',\n",
       "  'back',\n",
       "  'when',\n",
       "  'shorted',\n",
       "  'it',\n",
       "  'at',\n",
       "  'so',\n",
       "  'they',\n",
       "  'cry',\n",
       "  'out',\n",
       "  'here',\n",
       "  'everyday'],\n",
       " ['today', 'insight', 'on'],\n",
       " ['the',\n",
       "  'industry',\n",
       "  'average',\n",
       "  'roa',\n",
       "  'is',\n",
       "  'outperforms',\n",
       "  'of',\n",
       "  'it',\n",
       "  'industry',\n",
       "  'peer'],\n",
       " ['encourage',\n",
       "  'you',\n",
       "  'to',\n",
       "  'no',\n",
       "  'longer',\n",
       "  'be',\n",
       "  'sheep',\n",
       "  'end',\n",
       "  'your',\n",
       "  'racist',\n",
       "  'and',\n",
       "  'hateful',\n",
       "  'way',\n",
       "  'buy',\n",
       "  'amd',\n",
       "  'and',\n",
       "  'walk',\n",
       "  'away',\n",
       "  'from',\n",
       "  'the',\n",
       "  'democratic',\n",
       "  'party',\n",
       "  'walkaway'],\n",
       " ['it',\n",
       "  'happening',\n",
       "  'looking',\n",
       "  'to',\n",
       "  'ease',\n",
       "  'the',\n",
       "  'flattening',\n",
       "  'of',\n",
       "  'the',\n",
       "  'yc',\n",
       "  'starting',\n",
       "  'this',\n",
       "  'week',\n",
       "  'lot',\n",
       "  'of',\n",
       "  'trader',\n",
       "  'def',\n",
       "  'offside',\n",
       "  'now'],\n",
       " ['daily', 'or', 'weekly', 'chart', 'all', 'look', 'horrible'],\n",
       " ['if', 'spotify', 'add', 'more', 'video', 'content', 'look', 'out'],\n",
       " ['market',\n",
       "  'positioning',\n",
       "  'is',\n",
       "  'very',\n",
       "  'underweight',\n",
       "  'crowdthnk',\n",
       "  'algo',\n",
       "  'forecast',\n",
       "  'chance',\n",
       "  'moving',\n",
       "  'lower'],\n",
       " ['added',\n",
       "  'more',\n",
       "  'at',\n",
       "  'this',\n",
       "  'no',\n",
       "  'brainer',\n",
       "  'if',\n",
       "  'you',\n",
       "  're',\n",
       "  'long',\n",
       "  'there',\n",
       "  'is',\n",
       "  'no',\n",
       "  'peer',\n",
       "  'and',\n",
       "  'they',\n",
       "  'are',\n",
       "  'top',\n",
       "  'dog',\n",
       "  'amd',\n",
       "  'and',\n",
       "  'mu',\n",
       "  'notwithstanding'],\n",
       " ['bearish',\n",
       "  'bat',\n",
       "  'bearish',\n",
       "  'bat',\n",
       "  'with',\n",
       "  'some',\n",
       "  'serious',\n",
       "  'bearish',\n",
       "  'divergence',\n",
       "  'something',\n",
       "  'is',\n",
       "  'about',\n",
       "  'to',\n",
       "  'give'],\n",
       " ['ha',\n",
       "  'been',\n",
       "  'proposition',\n",
       "  'in',\n",
       "  'july',\n",
       "  'since',\n",
       "  'with',\n",
       "  'net',\n",
       "  'return',\n",
       "  'of'],\n",
       " ['in',\n",
       "  'term',\n",
       "  'of',\n",
       "  'negative',\n",
       "  'for',\n",
       "  'there',\n",
       "  'are',\n",
       "  'bearish',\n",
       "  'indicator',\n",
       "  'a',\n",
       "  'of'],\n",
       " ['quite', 'over', 'valued', 'in', 'my', 'opinion'],\n",
       " ['brexit',\n",
       "  'banker',\n",
       "  'risk',\n",
       "  'life',\n",
       "  'on',\n",
       "  'the',\n",
       "  'edge',\n",
       "  'a',\n",
       "  'luxembourg',\n",
       "  'fill',\n",
       "  'up',\n",
       "  'via'],\n",
       " ['market', 'history'],\n",
       " ['so', 'amd', 'is', 'using', 'liquid', 'inside', 'of', 'the', 'gpu'],\n",
       " ['curve',\n",
       "  'flattening',\n",
       "  'juggernaut',\n",
       "  'face',\n",
       "  'risk',\n",
       "  'from',\n",
       "  'fed',\n",
       "  'concern',\n",
       "  'on',\n",
       "  'trade',\n",
       "  'via'],\n",
       " ['a',\n",
       "  'it',\n",
       "  'pertains',\n",
       "  'to',\n",
       "  'if',\n",
       "  'started',\n",
       "  'day',\n",
       "  'ago',\n",
       "  'bearish',\n",
       "  'investor',\n",
       "  'would',\n",
       "  'have',\n",
       "  'lost',\n",
       "  'around',\n",
       "  'a',\n",
       "  'of',\n",
       "  'according',\n",
       "  'to',\n",
       "  'iex'],\n",
       " [],\n",
       " ['short', 'sale', 'volume', 'not', 'short', 'interest', 'for', 'on', 'is'],\n",
       " ['study',\n",
       "  'of',\n",
       "  'watchlist',\n",
       "  'trade',\n",
       "  'wisely',\n",
       "  'invest',\n",
       "  'wisely',\n",
       "  'read',\n",
       "  'the',\n",
       "  'wallstreet',\n",
       "  'runner'],\n",
       " ['waiting', 'for', 'the', 'pull', 'back', 'slow', 'steady', 'stock'],\n",
       " ['thought',\n",
       "  'friday',\n",
       "  'flush',\n",
       "  'wa',\n",
       "  'for',\n",
       "  'cheap',\n",
       "  'share',\n",
       "  'just',\n",
       "  'like',\n",
       "  'they',\n",
       "  'did',\n",
       "  'in',\n",
       "  'oil',\n",
       "  'before',\n",
       "  'the',\n",
       "  'opec',\n",
       "  'meeting'],\n",
       " ['jeson', 'china', 'attack'],\n",
       " ['short', 'sale', 'volume', 'not', 'short', 'interest', 'for', 'is'],\n",
       " ['is',\n",
       "  'rated',\n",
       "  'sell',\n",
       "  'since',\n",
       "  'june',\n",
       "  'and',\n",
       "  'is',\n",
       "  'below',\n",
       "  'it',\n",
       "  'median',\n",
       "  'level'],\n",
       " ['dont', 'trust', 'this', 'company'],\n",
       " ['today', 'insight', 'on'],\n",
       " ['the',\n",
       "  'anticipation',\n",
       "  'is',\n",
       "  'rising',\n",
       "  'which',\n",
       "  'analyst',\n",
       "  'is',\n",
       "  'right',\n",
       "  'june'],\n",
       " ['sorry',\n",
       "  'itsallaboutheoptions',\n",
       "  'stock',\n",
       "  'price',\n",
       "  'is',\n",
       "  'not',\n",
       "  'so',\n",
       "  'we',\n",
       "  'are',\n",
       "  'higher',\n",
       "  'than',\n",
       "  'you',\n",
       "  'predicted',\n",
       "  'not',\n",
       "  'lower'],\n",
       " ['warren', 'diggered', 'a', 'they', 'exited'],\n",
       " ['short', 'sale', 'volume', 'not', 'short', 'interest', 'for', 'at', 'is'],\n",
       " ['another', 'analyst', 'opinion', 'on', 'june'],\n",
       " [],\n",
       " ['and',\n",
       "  'are',\n",
       "  'all',\n",
       "  'down',\n",
       "  'because',\n",
       "  'of',\n",
       "  'trade',\n",
       "  'concern',\n",
       "  'will',\n",
       "  'still',\n",
       "  'be',\n",
       "  'worth',\n",
       "  'it',\n",
       "  'weight',\n",
       "  'in',\n",
       "  'faucet',\n",
       "  'and',\n",
       "  'now',\n",
       "  'little',\n",
       "  'bit',\n",
       "  'of',\n",
       "  'lighting'],\n",
       " ['three',\n",
       "  'falling',\n",
       "  'peak',\n",
       "  'bearish',\n",
       "  'with',\n",
       "  'confidence',\n",
       "  'to',\n",
       "  'reach',\n",
       "  'target',\n",
       "  'price',\n",
       "  'usd'],\n",
       " ['short', 'sale', 'volume', 'not', 'short', 'interest', 'for', 'is'],\n",
       " ['rectangle',\n",
       "  'top',\n",
       "  'bullish',\n",
       "  'with',\n",
       "  'confidence',\n",
       "  'to',\n",
       "  'reach',\n",
       "  'target',\n",
       "  'price',\n",
       "  'usd'],\n",
       " ['any', 'more', 'really', 'jetsonbs', 'design', 'they', 'announce'],\n",
       " ['bull', 'have', 'reason', 'on', 'to', 'pay', 'more', 'attention'],\n",
       " ['cogsworth', 'cog', 'will', 'take', 'on', 'boeing', 'soon', 'right'],\n",
       " ['really',\n",
       "  'baked',\n",
       "  'right',\n",
       "  'now',\n",
       "  'having',\n",
       "  'deep',\n",
       "  'thought',\n",
       "  'short',\n",
       "  'coming',\n",
       "  'back',\n",
       "  'to',\n",
       "  'look',\n",
       "  'at',\n",
       "  'this',\n",
       "  'tweet',\n",
       "  'in',\n",
       "  'year'],\n",
       " ['this',\n",
       "  'one',\n",
       "  'will',\n",
       "  'test',\n",
       "  'if',\n",
       "  'fails',\n",
       "  'my',\n",
       "  'target',\n",
       "  'is',\n",
       "  'to',\n",
       "  'start',\n",
       "  'buying',\n",
       "  'this',\n",
       "  'again',\n",
       "  'houseofpain'],\n",
       " [],\n",
       " ['making', 'more', 'than', 'ever', 'thanks', 'to', 'amp'],\n",
       " [],\n",
       " ['atl', 'fed', 'forecast', 'whew', 'baby', 'up', 'we', 'go'],\n",
       " ['here',\n",
       "  'it',\n",
       "  'is',\n",
       "  'june',\n",
       "  'grr',\n",
       "  'date',\n",
       "  'is',\n",
       "  'came',\n",
       "  'out',\n",
       "  'early',\n",
       "  'read',\n",
       "  'away'],\n",
       " ['bull', 'have', 'reason', 'on', 'to', 'pay', 'more', 'attention'],\n",
       " ['stericycle',\n",
       "  'current',\n",
       "  'chance',\n",
       "  'of',\n",
       "  'distress',\n",
       "  'is',\n",
       "  'about',\n",
       "  'below',\n",
       "  'average'],\n",
       " ['ggr', 'is', 'out', 'for', 'june'],\n",
       " ['today', 'insight', 'on'],\n",
       " ['fyi'],\n",
       " ['will', 'this', 'go', 'over', 'before', 'earnings'],\n",
       " ['extremely',\n",
       "  'undervalued',\n",
       "  'this',\n",
       "  'will',\n",
       "  'be',\n",
       "  'within',\n",
       "  'year',\n",
       "  'great',\n",
       "  'for',\n",
       "  'midterm',\n",
       "  'investment'],\n",
       " ['may', 'go', 'slightly', 'down', 'on', 'this', 'news', 'june', 'ggr'],\n",
       " ['stupid', 'spammer', 'wasting', 'time'],\n",
       " ['but',\n",
       "  'it',\n",
       "  'already',\n",
       "  'oversold',\n",
       "  'so',\n",
       "  'not',\n",
       "  'much',\n",
       "  'consolidation',\n",
       "  'and',\n",
       "  'then',\n",
       "  'up'],\n",
       " ['this', 'is', 'just', 'the', 'start'],\n",
       " ['short',\n",
       "  'interest',\n",
       "  'ratio',\n",
       "  'of',\n",
       "  'is',\n",
       "  'at',\n",
       "  'and',\n",
       "  'short',\n",
       "  'to',\n",
       "  'float',\n",
       "  'is'],\n",
       " ['purchasing',\n",
       "  'pill',\n",
       "  'pack',\n",
       "  'last',\n",
       "  'thursday',\n",
       "  'and',\n",
       "  'breaking',\n",
       "  'into',\n",
       "  'the',\n",
       "  'pharmaceutical',\n",
       "  'field',\n",
       "  'increase',\n",
       "  'amazon',\n",
       "  'bottom',\n",
       "  'line',\n",
       "  'will',\n",
       "  'retest',\n",
       "  'quickly'],\n",
       " ['june',\n",
       "  'ggr',\n",
       "  'up',\n",
       "  'still',\n",
       "  'after',\n",
       "  'the',\n",
       "  'soccer',\n",
       "  'world',\n",
       "  'cup',\n",
       "  'and',\n",
       "  'holiday'],\n",
       " ['purchasing',\n",
       "  'pill',\n",
       "  'pack',\n",
       "  'last',\n",
       "  'thurs',\n",
       "  'amp',\n",
       "  'breaking',\n",
       "  'into',\n",
       "  'the',\n",
       "  'pharmaceutical',\n",
       "  'field',\n",
       "  'increase',\n",
       "  'amazon',\n",
       "  'bottom',\n",
       "  'line',\n",
       "  'will',\n",
       "  'retest',\n",
       "  'quickly'],\n",
       " ['buy', 'back', 'they', 'want', 'cheap'],\n",
       " ['not',\n",
       "  'too',\n",
       "  'expensive',\n",
       "  'and',\n",
       "  'growing',\n",
       "  'strongly',\n",
       "  'check',\n",
       "  'out',\n",
       "  'now',\n",
       "  'part',\n",
       "  'of',\n",
       "  'our',\n",
       "  'affordable',\n",
       "  'growth',\n",
       "  'selection'],\n",
       " ['option',\n",
       "  'volume',\n",
       "  'wa',\n",
       "  'normal',\n",
       "  'on',\n",
       "  'friday',\n",
       "  'with',\n",
       "  'contract',\n",
       "  'call',\n",
       "  'volume',\n",
       "  'wa',\n",
       "  'and',\n",
       "  'put',\n",
       "  'volume',\n",
       "  'wa'],\n",
       " ['the',\n",
       "  'long',\n",
       "  'term',\n",
       "  'trend',\n",
       "  'is',\n",
       "  'positive',\n",
       "  'and',\n",
       "  'the',\n",
       "  'short',\n",
       "  'term',\n",
       "  'trend',\n",
       "  'is',\n",
       "  'neutral',\n",
       "  'so',\n",
       "  'the',\n",
       "  'benefit',\n",
       "  'of',\n",
       "  'the',\n",
       "  'doubt',\n",
       "  'for',\n",
       "  'now'],\n",
       " ['lot',\n",
       "  'of',\n",
       "  'buyer',\n",
       "  'fri',\n",
       "  'when',\n",
       "  'mm',\n",
       "  'pinned',\n",
       "  'at',\n",
       "  'quot',\n",
       "  'trader',\n",
       "  'buy',\n",
       "  'amazon',\n",
       "  'com',\n",
       "  'amzn',\n",
       "  'on',\n",
       "  'weakness',\n",
       "  'quot'],\n",
       " ['in',\n",
       "  'term',\n",
       "  'of',\n",
       "  'positive',\n",
       "  'for',\n",
       "  'there',\n",
       "  'are',\n",
       "  'bullish',\n",
       "  'indicator',\n",
       "  'a',\n",
       "  'of'],\n",
       " ['know', 'what', 'hold'],\n",
       " ['never',\n",
       "  'have',\n",
       "  'seen',\n",
       "  'right',\n",
       "  'angle',\n",
       "  'in',\n",
       "  'apple',\n",
       "  'lol',\n",
       "  'that',\n",
       "  'wa',\n",
       "  'crazy'],\n",
       " ['wanna',\n",
       "  'hear',\n",
       "  'the',\n",
       "  'er',\n",
       "  'ok',\n",
       "  'yeah',\n",
       "  'all',\n",
       "  'got',\n",
       "  'great',\n",
       "  'product',\n",
       "  'so',\n",
       "  'what',\n",
       "  'this',\n",
       "  'is',\n",
       "  'the',\n",
       "  'stock',\n",
       "  'market',\n",
       "  'want',\n",
       "  'report',\n",
       "  'what',\n",
       "  'the',\n",
       "  'news'],\n",
       " ['starbucks',\n",
       "  'to',\n",
       "  'become',\n",
       "  'the',\n",
       "  'pioneer',\n",
       "  'in',\n",
       "  'medical',\n",
       "  'coverage',\n",
       "  'for',\n",
       "  'sex',\n",
       "  'change',\n",
       "  'get',\n",
       "  'your',\n",
       "  'free',\n",
       "  'sex',\n",
       "  'change',\n",
       "  'here'],\n",
       " ['today', 'insight', 'on'],\n",
       " ['today', 'insight', 'on'],\n",
       " ['short', 'sale', 'volume', 'not', 'short', 'interest', 'for', 'on', 'is'],\n",
       " ['all',\n",
       "  'in',\n",
       "  'on',\n",
       "  'august',\n",
       "  'call',\n",
       "  'either',\n",
       "  'gonna',\n",
       "  'make',\n",
       "  'fortune',\n",
       "  'or',\n",
       "  'declare',\n",
       "  'bankruptcy'],\n",
       " ['wtf'],\n",
       " [],\n",
       " ['macau', 'casino', 'ggr', 'up', 'nearly', 'pct', 'in', 'june', 'govt'],\n",
       " ['jul',\n",
       "  'casino',\n",
       "  'gross',\n",
       "  'gaming',\n",
       "  'revenue',\n",
       "  'ggr',\n",
       "  'in',\n",
       "  'macau',\n",
       "  'rose',\n",
       "  'by',\n",
       "  'percent',\n",
       "  'year',\n",
       "  'on',\n",
       "  'year',\n",
       "  'in',\n",
       "  'june',\n",
       "  'to'],\n",
       " ['what'],\n",
       " ['is', 'gonna', 'be', 'cheaper', 'than', 'also'],\n",
       " ['the',\n",
       "  'monster',\n",
       "  'core',\n",
       "  'amd',\n",
       "  'ryzen',\n",
       "  'threadripper',\n",
       "  'cpu',\n",
       "  'rumored',\n",
       "  'usd'],\n",
       " ['we',\n",
       "  'have',\n",
       "  'detected',\n",
       "  'negative',\n",
       "  'indicator',\n",
       "  'a',\n",
       "  'of',\n",
       "  'for',\n",
       "  'more',\n",
       "  'info',\n",
       "  'at'],\n",
       " ['someone', 'give', 'me', 'like'],\n",
       " ['short',\n",
       "  'interest',\n",
       "  'ratio',\n",
       "  'is',\n",
       "  'on',\n",
       "  'and',\n",
       "  'short',\n",
       "  'to',\n",
       "  'float',\n",
       "  'is'],\n",
       " [],\n",
       " ['valued', 'll', 'take', 'at', 'this', 'point'],\n",
       " [],\n",
       " ['short',\n",
       "  'interest',\n",
       "  'ratio',\n",
       "  'of',\n",
       "  'is',\n",
       "  'at',\n",
       "  'and',\n",
       "  'short',\n",
       "  'to',\n",
       "  'float',\n",
       "  'is'],\n",
       " ['trump', 'will', 'cause', 'oil', 'price', 'to', 'go', 'down'],\n",
       " ['if',\n",
       "  'were',\n",
       "  'and',\n",
       "  'need',\n",
       "  'to',\n",
       "  'buyback',\n",
       "  'bln',\n",
       "  'share',\n",
       "  'wouldn',\n",
       "  'try',\n",
       "  'to',\n",
       "  'buy',\n",
       "  'the',\n",
       "  'dip'],\n",
       " ['option',\n",
       "  'volume',\n",
       "  'wa',\n",
       "  'normal',\n",
       "  'on',\n",
       "  'friday',\n",
       "  'with',\n",
       "  'contract',\n",
       "  'call',\n",
       "  'volume',\n",
       "  'wa',\n",
       "  'and',\n",
       "  'put',\n",
       "  'volume',\n",
       "  'wa'],\n",
       " ['short', 'sale', 'volume', 'not', 'short', 'interest', 'for', 'is'],\n",
       " ['gigabyte', 'amp', 'epyc', 'cpu', 'with', 'large', 'density', 'server'],\n",
       " ['now',\n",
       "  'intel',\n",
       "  'can',\n",
       "  'produce',\n",
       "  'full',\n",
       "  'silicon',\n",
       "  'wafer',\n",
       "  'for',\n",
       "  'quantum',\n",
       "  'computing',\n",
       "  'chip'],\n",
       " ['short', 'sale', 'volume', 'not', 'short', 'interest', 'for', 'on', 'is'],\n",
       " ['good',\n",
       "  'technical',\n",
       "  'but',\n",
       "  'also',\n",
       "  'nice',\n",
       "  'setup',\n",
       "  'pattern',\n",
       "  'forming',\n",
       "  'for',\n",
       "  'now',\n",
       "  'part',\n",
       "  'of',\n",
       "  'our',\n",
       "  'top',\n",
       "  'breakout',\n",
       "  'selection'],\n",
       " ['bear', 'have', 'reason', 'on', 'to', 'pay', 'more', 'attention'],\n",
       " ['june',\n",
       "  'ggr',\n",
       "  'only',\n",
       "  'up',\n",
       "  'very',\n",
       "  'bad',\n",
       "  'stock',\n",
       "  'are',\n",
       "  'going',\n",
       "  'to',\n",
       "  'get',\n",
       "  'crushed'],\n",
       " ['amazon',\n",
       "  'with',\n",
       "  'hook',\n",
       "  'pattern',\n",
       "  'set',\n",
       "  'up',\n",
       "  'on',\n",
       "  'the',\n",
       "  'monthly',\n",
       "  'looking',\n",
       "  'at',\n",
       "  'strong',\n",
       "  'move',\n",
       "  'up',\n",
       "  'on',\n",
       "  'monday',\n",
       "  'expected'],\n",
       " ['paychex',\n",
       "  'social',\n",
       "  'hype',\n",
       "  'low',\n",
       "  'key',\n",
       "  'current',\n",
       "  'chance',\n",
       "  'of',\n",
       "  'financial',\n",
       "  'distress',\n",
       "  'is',\n",
       "  'under'],\n",
       " ['today', 'insight', 'on'],\n",
       " [],\n",
       " ['bear', 'have', 'reason', 'on', 'to', 'pay', 'more', 'attention'],\n",
       " ['buy', 'more', 'on', 'the', 'dip', 'buying', 'opp'],\n",
       " ['here',\n",
       "  'is',\n",
       "  'an',\n",
       "  'example',\n",
       "  'of',\n",
       "  'hook',\n",
       "  'pattern',\n",
       "  'virtually',\n",
       "  'identical',\n",
       "  'to',\n",
       "  'what',\n",
       "  'amazon',\n",
       "  'monthly',\n",
       "  'chart',\n",
       "  'look',\n",
       "  'like',\n",
       "  'now'],\n",
       " ['the',\n",
       "  'eps',\n",
       "  'ha',\n",
       "  'been',\n",
       "  'growing',\n",
       "  'by',\n",
       "  'on',\n",
       "  'average',\n",
       "  'over',\n",
       "  'the',\n",
       "  'past',\n",
       "  'year',\n",
       "  'this',\n",
       "  'is',\n",
       "  'quite',\n",
       "  'good'],\n",
       " ['short',\n",
       "  'interest',\n",
       "  'ratio',\n",
       "  'of',\n",
       "  'is',\n",
       "  'at',\n",
       "  'and',\n",
       "  'short',\n",
       "  'to',\n",
       "  'float',\n",
       "  'is'],\n",
       " ['showing', 'up', 'in', 'our', 'top', 'breakout', 'selection'],\n",
       " ['overbought', 'sell', 'signal'],\n",
       " ['short', 'ratio', 'is', 'at', 'and', 'short', 'to', 'float', 'is'],\n",
       " ['rsi', 'deathcross'],\n",
       " ['will',\n",
       "  'be',\n",
       "  'selling',\n",
       "  'pre',\n",
       "  'market',\n",
       "  'and',\n",
       "  'trying',\n",
       "  'to',\n",
       "  'buy',\n",
       "  'in',\n",
       "  'very',\n",
       "  'bullish',\n",
       "  'but',\n",
       "  'would',\n",
       "  'like',\n",
       "  'to',\n",
       "  'take',\n",
       "  'advantage',\n",
       "  'of',\n",
       "  'dip'],\n",
       " ['a',\n",
       "  'it',\n",
       "  'pertains',\n",
       "  'to',\n",
       "  'if',\n",
       "  'started',\n",
       "  'day',\n",
       "  'ago',\n",
       "  'bearish',\n",
       "  'investor',\n",
       "  'would',\n",
       "  'have',\n",
       "  'lost',\n",
       "  'around',\n",
       "  'a',\n",
       "  'of',\n",
       "  'according',\n",
       "  'to',\n",
       "  'iex'],\n",
       " ['short',\n",
       "  'volume',\n",
       "  'for',\n",
       "  'on',\n",
       "  'wa',\n",
       "  'th',\n",
       "  'percentile',\n",
       "  'in',\n",
       "  'term',\n",
       "  'of',\n",
       "  'last',\n",
       "  'trading',\n",
       "  'day'],\n",
       " ['bring',\n",
       "  'on',\n",
       "  'the',\n",
       "  'gloom',\n",
       "  'amp',\n",
       "  'doom',\n",
       "  'on',\n",
       "  'the',\n",
       "  'pull',\n",
       "  'back',\n",
       "  'ahead',\n",
       "  'of',\n",
       "  'er',\n",
       "  'happens',\n",
       "  'ever',\n",
       "  'time',\n",
       "  'after',\n",
       "  'don',\n",
       "  'fight',\n",
       "  'the',\n",
       "  'plan',\n",
       "  'buy',\n",
       "  'it',\n",
       "  'no',\n",
       "  'way',\n",
       "  'it',\n",
       "  'fall'],\n",
       " ['overbought', 'death', 'cross', 'sell', 'signal'],\n",
       " ['short',\n",
       "  'interest',\n",
       "  'ratio',\n",
       "  'is',\n",
       "  'on',\n",
       "  'and',\n",
       "  'short',\n",
       "  'to',\n",
       "  'float',\n",
       "  'is'],\n",
       " ['bad',\n",
       "  'news',\n",
       "  'is',\n",
       "  'baked',\n",
       "  'in',\n",
       "  'to',\n",
       "  'the',\n",
       "  'sector',\n",
       "  'but',\n",
       "  'second',\n",
       "  'major',\n",
       "  'miss',\n",
       "  'in',\n",
       "  'row',\n",
       "  'like',\n",
       "  'this',\n",
       "  'is',\n",
       "  'going',\n",
       "  'to',\n",
       "  'spook',\n",
       "  'lot',\n",
       "  'of',\n",
       "  'investor'],\n",
       " ['short', 'volume', 'percent', 'for', 'wa', 'on', 'versus', 'on'],\n",
       " ['here',\n",
       "  'is',\n",
       "  'artcile',\n",
       "  'with',\n",
       "  'expectation',\n",
       "  'for',\n",
       "  'june',\n",
       "  'great',\n",
       "  'buying',\n",
       "  'opp',\n",
       "  'on',\n",
       "  'dip',\n",
       "  'july',\n",
       "  'august'],\n",
       " ['short', 'sale', 'volume', 'not', 'short', 'interest', 'for', 'is'],\n",
       " ['we',\n",
       "  'have',\n",
       "  'detected',\n",
       "  'positive',\n",
       "  'indicator',\n",
       "  'a',\n",
       "  'of',\n",
       "  'for',\n",
       "  'more',\n",
       "  'info',\n",
       "  'at'],\n",
       " ['short', 'ratio', 'is', 'at', 'and', 'short', 'to', 'float', 'is'],\n",
       " ['well',\n",
       "  'if',\n",
       "  'can',\n",
       "  'sell',\n",
       "  'premarket',\n",
       "  'and',\n",
       "  'then',\n",
       "  'buy',\n",
       "  'back',\n",
       "  'in',\n",
       "  'summer',\n",
       "  'july',\n",
       "  'tariff',\n",
       "  'coming',\n",
       "  'up',\n",
       "  'lower',\n",
       "  'price',\n",
       "  'why',\n",
       "  'not',\n",
       "  'ggr'],\n",
       " ['in',\n",
       "  'term',\n",
       "  'of',\n",
       "  'positive',\n",
       "  'for',\n",
       "  'there',\n",
       "  'are',\n",
       "  'bullish',\n",
       "  'indicator',\n",
       "  'a',\n",
       "  'of'],\n",
       " ['is',\n",
       "  'currently',\n",
       "  'trading',\n",
       "  'in',\n",
       "  'the',\n",
       "  'upper',\n",
       "  'part',\n",
       "  'of',\n",
       "  'it',\n",
       "  'week',\n",
       "  'range',\n",
       "  'outperforming',\n",
       "  'the',\n",
       "  'market'],\n",
       " ['today', 'insight', 'on'],\n",
       " ['huge',\n",
       "  'miss',\n",
       "  'on',\n",
       "  'june',\n",
       "  'ggr',\n",
       "  'right',\n",
       "  'before',\n",
       "  'july',\n",
       "  'tariff',\n",
       "  'oh',\n",
       "  'shit',\n",
       "  'selling',\n",
       "  'premarket',\n",
       "  'and',\n",
       "  'buying',\n",
       "  'back',\n",
       "  'in'],\n",
       " ['epd',\n",
       "  'sjr',\n",
       "  'aos',\n",
       "  'desp',\n",
       "  'gcp',\n",
       "  'jpi',\n",
       "  'stk',\n",
       "  'newgrandboscan',\n",
       "  'highest',\n",
       "  'vol',\n",
       "  'accum'],\n",
       " ['quot',\n",
       "  'amazon',\n",
       "  'online',\n",
       "  'pharmacy',\n",
       "  'acquisition',\n",
       "  'prof',\n",
       "  'it',\n",
       "  'serious',\n",
       "  'about',\n",
       "  'disrupting',\n",
       "  'healthcare',\n",
       "  'quot'],\n",
       " ['according',\n",
       "  'to',\n",
       "  'data',\n",
       "  'reported',\n",
       "  'to',\n",
       "  'finra',\n",
       "  'short',\n",
       "  'volume',\n",
       "  'percent',\n",
       "  'for',\n",
       "  'clocked',\n",
       "  'in',\n",
       "  'at',\n",
       "  'on'],\n",
       " ['bull', 'have', 'reason', 'on', 'to', 'pay', 'more', 'attention'],\n",
       " ['short', 'ratio', 'on', 'is', 'and', 'short', 'to', 'float', 'is'],\n",
       " ['based',\n",
       "  'on',\n",
       "  'iex',\n",
       "  'data',\n",
       "  'bearish',\n",
       "  'investor',\n",
       "  'have',\n",
       "  'taken',\n",
       "  'some',\n",
       "  'punishment',\n",
       "  'in',\n",
       "  'if',\n",
       "  'started',\n",
       "  'month',\n",
       "  'ago',\n",
       "  'their',\n",
       "  'return',\n",
       "  'is',\n",
       "  'around',\n",
       "  'a',\n",
       "  'of'],\n",
       " ['guess',\n",
       "  'we',\n",
       "  'will',\n",
       "  'wait',\n",
       "  'to',\n",
       "  'see',\n",
       "  'how',\n",
       "  'it',\n",
       "  'will',\n",
       "  'trade',\n",
       "  'tomorrow',\n",
       "  'night',\n",
       "  'when',\n",
       "  'hong',\n",
       "  'kong',\n",
       "  'market',\n",
       "  'open'],\n",
       " ['why', 'did', 'even', 'start', 'trading'],\n",
       " ['because', 'it', 'ha', 'better', 'valuation', 'than', 'read', 'the', 'news'],\n",
       " ['short', 'sale', 'volume', 'not', 'short', 'interest', 'for', 'at', 'is'],\n",
       " ['ha',\n",
       "  'good',\n",
       "  'piotroski',\n",
       "  'score',\n",
       "  'of',\n",
       "  'this',\n",
       "  'indicates',\n",
       "  'good',\n",
       "  'health',\n",
       "  'and',\n",
       "  'profitability'],\n",
       " ['we',\n",
       "  'have',\n",
       "  'detected',\n",
       "  'positive',\n",
       "  'indicator',\n",
       "  'a',\n",
       "  'of',\n",
       "  'for',\n",
       "  'more',\n",
       "  'info',\n",
       "  'at'],\n",
       " ['think',\n",
       "  'in',\n",
       "  'my',\n",
       "  'opinion',\n",
       "  'it',\n",
       "  'is',\n",
       "  'the',\n",
       "  'most',\n",
       "  'consolidated',\n",
       "  'amp',\n",
       "  'with',\n",
       "  'the',\n",
       "  'greatest',\n",
       "  'business',\n",
       "  'support',\n",
       "  'in',\n",
       "  'different',\n",
       "  'area',\n",
       "  'and',\n",
       "  'strategy'],\n",
       " ['anyone', 'have', 'any', 'idea', 'on', 'what', 'is', 'coming', 'next'],\n",
       " ['happened', 'last', 'june', 'too', 'miss', 'june', 'ggr'],\n",
       " ['happened', 'last', 'june', 'too'],\n",
       " ['based',\n",
       "  'on',\n",
       "  'iex',\n",
       "  'data',\n",
       "  'bearish',\n",
       "  'investor',\n",
       "  'have',\n",
       "  'taken',\n",
       "  'some',\n",
       "  'punishment',\n",
       "  'in',\n",
       "  'if',\n",
       "  'started',\n",
       "  'month',\n",
       "  'ago',\n",
       "  'their',\n",
       "  'return',\n",
       "  'is',\n",
       "  'around',\n",
       "  'a',\n",
       "  'of'],\n",
       " ['bull', 'have', 'reason', 'on', 'to', 'pay', 'more', 'attention'],\n",
       " ['wow',\n",
       "  'for',\n",
       "  'if',\n",
       "  'started',\n",
       "  'one',\n",
       "  'month',\n",
       "  'ago',\n",
       "  'the',\n",
       "  'bear',\n",
       "  'return',\n",
       "  'would',\n",
       "  'be',\n",
       "  'around',\n",
       "  'a',\n",
       "  'of',\n",
       "  'iex',\n",
       "  'data'],\n",
       " ['today', 'insight', 'on'],\n",
       " ['according',\n",
       "  'to',\n",
       "  'data',\n",
       "  'reported',\n",
       "  'to',\n",
       "  'finra',\n",
       "  'short',\n",
       "  'volume',\n",
       "  'percent',\n",
       "  'for',\n",
       "  'clocked',\n",
       "  'in',\n",
       "  'at',\n",
       "  'on'],\n",
       " ['today', 'insight', 'on'],\n",
       " ['new', 'hotel', 'with', 'casino', 'coming', 'in', 'macau'],\n",
       " ['newspscan', 'vol'],\n",
       " ['short', 'sale', 'volume', 'not', 'short', 'interest', 'for', 'is'],\n",
       " ['newspscan', 'vol', 'accum'],\n",
       " ['ve', 'what', 'are', 'your', 'thought', 'on', 'bank'],\n",
       " ['short',\n",
       "  'interest',\n",
       "  'ratio',\n",
       "  'of',\n",
       "  'is',\n",
       "  'at',\n",
       "  'and',\n",
       "  'short',\n",
       "  'to',\n",
       "  'float',\n",
       "  'is'],\n",
       " ['the',\n",
       "  'long',\n",
       "  'and',\n",
       "  'short',\n",
       "  'term',\n",
       "  'trend',\n",
       "  'are',\n",
       "  'both',\n",
       "  'positive',\n",
       "  'this',\n",
       "  'is',\n",
       "  'looking',\n",
       "  'good'],\n",
       " ['weekly',\n",
       "  'bullflag',\n",
       "  'in',\n",
       "  'great',\n",
       "  'condition',\n",
       "  'major',\n",
       "  'support',\n",
       "  'at',\n",
       "  'breakout',\n",
       "  'at',\n",
       "  'pt',\n",
       "  'at',\n",
       "  'amp',\n",
       "  'indicator',\n",
       "  'look',\n",
       "  'good'],\n",
       " ['chiplets', 'adoredtv'],\n",
       " ['per',\n",
       "  'data',\n",
       "  'reported',\n",
       "  'to',\n",
       "  'finra',\n",
       "  'short',\n",
       "  'volume',\n",
       "  'divided',\n",
       "  'by',\n",
       "  'total',\n",
       "  'volume',\n",
       "  'for',\n",
       "  'wa',\n",
       "  'on'],\n",
       " ['short', 'sale', 'volume', 'not', 'short', 'interest', 'for', 'at', 'is'],\n",
       " ['chart', 'of', 'the', 'day', 'at', 'buy'],\n",
       " ['oldspscan', 'volaccum'],\n",
       " ['we',\n",
       "  'have',\n",
       "  'detected',\n",
       "  'positive',\n",
       "  'indicator',\n",
       "  'a',\n",
       "  'of',\n",
       "  'for',\n",
       "  'more',\n",
       "  'info',\n",
       "  'at'],\n",
       " ['ha',\n",
       "  'bad',\n",
       "  'technical',\n",
       "  'rating',\n",
       "  'but',\n",
       "  'it',\n",
       "  'doe',\n",
       "  'show',\n",
       "  'decent',\n",
       "  'setup',\n",
       "  'pattern'],\n",
       " ['old', 'spscanw', 'vol', 'accum'],\n",
       " ['percent', 'short', 'volume', 'for', 'wa', 'on'],\n",
       " ['in',\n",
       "  'term',\n",
       "  'of',\n",
       "  'positive',\n",
       "  'for',\n",
       "  'there',\n",
       "  'are',\n",
       "  'bullish',\n",
       "  'indicator',\n",
       "  'a',\n",
       "  'of'],\n",
       " ['confidently',\n",
       "  'can',\n",
       "  'invest',\n",
       "  'and',\n",
       "  'forget',\n",
       "  'generation',\n",
       "  'for',\n",
       "  'yr',\n",
       "  'to',\n",
       "  'enjoy',\n",
       "  'the',\n",
       "  'fruit',\n",
       "  'of',\n",
       "  'my',\n",
       "  'labor',\n",
       "  'extending',\n",
       "  'to',\n",
       "  'the',\n",
       "  'future'],\n",
       " ['is',\n",
       "  'rated',\n",
       "  'buy',\n",
       "  'since',\n",
       "  'may',\n",
       "  'and',\n",
       "  'is',\n",
       "  'above',\n",
       "  'it',\n",
       "  'median',\n",
       "  'level'],\n",
       " ['financials',\n",
       "  'broke',\n",
       "  'wedge',\n",
       "  'on',\n",
       "  'weekly',\n",
       "  'chart',\n",
       "  'all',\n",
       "  'indicator',\n",
       "  'are',\n",
       "  'bearish',\n",
       "  'and',\n",
       "  'price',\n",
       "  'target',\n",
       "  'is',\n",
       "  'the',\n",
       "  'dma',\n",
       "  'at'],\n",
       " ['ha',\n",
       "  'profit',\n",
       "  'margin',\n",
       "  'of',\n",
       "  'this',\n",
       "  'is',\n",
       "  'amongst',\n",
       "  'the',\n",
       "  'best',\n",
       "  'return',\n",
       "  'in',\n",
       "  'the',\n",
       "  'industry'],\n",
       " ['today', 'insight', 'on'],\n",
       " ['short', 'volume', 'reported', 'to', 'finra', 'on', 'on'],\n",
       " ['today', 'insight', 'on'],\n",
       " ['today', 'insight', 'on'],\n",
       " ['weekly',\n",
       "  'bf',\n",
       "  'look',\n",
       "  'great',\n",
       "  'dma',\n",
       "  'crossing',\n",
       "  'dma',\n",
       "  'bullish',\n",
       "  'sign',\n",
       "  'buying',\n",
       "  'volume',\n",
       "  'gt',\n",
       "  'selling',\n",
       "  'volume',\n",
       "  'make',\n",
       "  'this',\n",
       "  'very',\n",
       "  'attractive'],\n",
       " ['today', 'insight', 'on'],\n",
       " ['short', 'ratio', 'of', 'is', 'at', 'and', 'short', 'to', 'float', 'is'],\n",
       " ['bull', 'have', 'reason', 'on', 'to', 'pay', 'more', 'attention'],\n",
       " ['maybe',\n",
       "  'or',\n",
       "  'buy',\n",
       "  'this',\n",
       "  'out',\n",
       "  'moviepass',\n",
       "  'is',\n",
       "  'superb',\n",
       "  'income',\n",
       "  'generator'],\n",
       " ['we',\n",
       "  'have',\n",
       "  'detected',\n",
       "  'positive',\n",
       "  'indicator',\n",
       "  'a',\n",
       "  'of',\n",
       "  'for',\n",
       "  'more',\n",
       "  'info',\n",
       "  'at'],\n",
       " ['short', 'sale', 'volume', 'not', 'short', 'interest', 'for', 'is'],\n",
       " ['is',\n",
       "  'one',\n",
       "  'of',\n",
       "  'the',\n",
       "  'better',\n",
       "  'performing',\n",
       "  'stock',\n",
       "  'in',\n",
       "  'the',\n",
       "  'metal',\n",
       "  'mining',\n",
       "  'industry'],\n",
       " ['of',\n",
       "  'conservative',\n",
       "  'believe',\n",
       "  'social',\n",
       "  'network',\n",
       "  'censor',\n",
       "  'political',\n",
       "  'speech',\n",
       "  'according',\n",
       "  'to',\n",
       "  'pew',\n",
       "  'study'],\n",
       " ['ouch',\n",
       "  'for',\n",
       "  'if',\n",
       "  'started',\n",
       "  'trading',\n",
       "  'day',\n",
       "  'ago',\n",
       "  'shorter',\n",
       "  'return',\n",
       "  'would',\n",
       "  'be',\n",
       "  'around',\n",
       "  'a',\n",
       "  'of',\n",
       "  'iex',\n",
       "  'data'],\n",
       " ['short',\n",
       "  'volume',\n",
       "  'percent',\n",
       "  'for',\n",
       "  'wa',\n",
       "  'on',\n",
       "  'an',\n",
       "  'increase',\n",
       "  'of',\n",
       "  'from'],\n",
       " ['ha',\n",
       "  'profit',\n",
       "  'margin',\n",
       "  'of',\n",
       "  'this',\n",
       "  'is',\n",
       "  'better',\n",
       "  'than',\n",
       "  'the',\n",
       "  'industry',\n",
       "  'average',\n",
       "  'of'],\n",
       " ['the',\n",
       "  'short',\n",
       "  'sale',\n",
       "  'volume',\n",
       "  'not',\n",
       "  'short',\n",
       "  'interest',\n",
       "  'for',\n",
       "  'on',\n",
       "  'is'],\n",
       " ['short', 'sale', 'volume', 'not', 'short', 'interest', 'for', 'at', 'is'],\n",
       " ['today', 'insight', 'on'],\n",
       " ['today', 'insight', 'on'],\n",
       " ['bull', 'have', 'reason', 'on', 'to', 'pay', 'more', 'attention'],\n",
       " ['short',\n",
       "  'interest',\n",
       "  'ratio',\n",
       "  'at',\n",
       "  'is',\n",
       "  'and',\n",
       "  'short',\n",
       "  'to',\n",
       "  'float',\n",
       "  'is'],\n",
       " ['the',\n",
       "  'bigger',\n",
       "  'news',\n",
       "  'is',\n",
       "  'when',\n",
       "  'the',\n",
       "  'doj',\n",
       "  'give',\n",
       "  'clearance',\n",
       "  'to',\n",
       "  'with',\n",
       "  'condition',\n",
       "  'then',\n",
       "  'we',\n",
       "  'will',\n",
       "  'see',\n",
       "  'very',\n",
       "  'huge',\n",
       "  'counter',\n",
       "  'offer'],\n",
       " ['short', 'sale', 'volume', 'not', 'short', 'interest', 'for', 'is'],\n",
       " ['per',\n",
       "  'data',\n",
       "  'reported',\n",
       "  'to',\n",
       "  'finra',\n",
       "  'short',\n",
       "  'volume',\n",
       "  'divided',\n",
       "  'by',\n",
       "  'total',\n",
       "  'volume',\n",
       "  'for',\n",
       "  'wa',\n",
       "  'on'],\n",
       " ['short', 'volume', 'reported', 'to', 'finra', 'on', 'on'],\n",
       " ['bull', 'have', 'reason', 'on', 'to', 'pay', 'more', 'attention'],\n",
       " ['the',\n",
       "  'fund',\n",
       "  'follow',\n",
       "  'added',\n",
       "  'micron',\n",
       "  'at',\n",
       "  'another',\n",
       "  'fund',\n",
       "  'manager',\n",
       "  'ha',\n",
       "  'had',\n",
       "  'it',\n",
       "  'since',\n",
       "  'and',\n",
       "  'is',\n",
       "  'still',\n",
       "  'holding',\n",
       "  'both',\n",
       "  'targeting',\n",
       "  'higher',\n",
       "  'high'],\n",
       " ['short', 'sale', 'volume', 'not', 'short', 'interest', 'for', 'is'],\n",
       " ['bull', 'have', 'reason', 'on', 'to', 'pay', 'more', 'attention'],\n",
       " [],\n",
       " ['today', 'insight', 'on'],\n",
       " ['aggregate',\n",
       "  'short',\n",
       "  'volume',\n",
       "  'reported',\n",
       "  'to',\n",
       "  'finra',\n",
       "  'for',\n",
       "  'wa',\n",
       "  'on'],\n",
       " ['today', 'insight', 'on'],\n",
       " ['today', 'insight', 'on'],\n",
       " ['today', 'insight', 'on'],\n",
       " ['the',\n",
       "  'eps',\n",
       "  'ha',\n",
       "  'been',\n",
       "  'growing',\n",
       "  'by',\n",
       "  'on',\n",
       "  'average',\n",
       "  'over',\n",
       "  'the',\n",
       "  'past',\n",
       "  'year',\n",
       "  'this',\n",
       "  'is',\n",
       "  'very',\n",
       "  'strong',\n",
       "  'growth'],\n",
       " ['short',\n",
       "  'have',\n",
       "  'sure',\n",
       "  'felt',\n",
       "  'some',\n",
       "  'pain',\n",
       "  'in',\n",
       "  'if',\n",
       "  'shorted',\n",
       "  'on',\n",
       "  'the',\n",
       "  'first',\n",
       "  'their',\n",
       "  'ytd',\n",
       "  'return',\n",
       "  'is',\n",
       "  'around',\n",
       "  'a',\n",
       "  'of'],\n",
       " ['short', 'volume', 'reported', 'to', 'finra', 'on', 'on'],\n",
       " ['we',\n",
       "  'have',\n",
       "  'detected',\n",
       "  'negative',\n",
       "  'indicator',\n",
       "  'a',\n",
       "  'of',\n",
       "  'for',\n",
       "  'more',\n",
       "  'info',\n",
       "  'at'],\n",
       " ['short', 'sale', 'volume', 'not', 'short', 'interest', 'for', 'at', 'is'],\n",
       " ['that', 'would', 'make', 'me', 'very', 'happy', 'camper'],\n",
       " ['rt',\n",
       "  'show',\n",
       "  'quite',\n",
       "  'strong',\n",
       "  'growth',\n",
       "  'in',\n",
       "  'eps',\n",
       "  'over',\n",
       "  'the',\n",
       "  'last',\n",
       "  'year',\n",
       "  'the',\n",
       "  'eps',\n",
       "  'ha',\n",
       "  'been',\n",
       "  'growing',\n",
       "  'by',\n",
       "  'yearly'],\n",
       " ['bear', 'have', 'reason', 'on', 'to', 'pay', 'more', 'attention'],\n",
       " ['sorry',\n",
       "  'bull',\n",
       "  'but',\n",
       "  'after',\n",
       "  'trump',\n",
       "  'attack',\n",
       "  'on',\n",
       "  'great',\n",
       "  'american',\n",
       "  'brand'],\n",
       " ['anyone', 'have', 'thought', 'on', 'price', 'target'],\n",
       " ['short',\n",
       "  'volume',\n",
       "  'for',\n",
       "  'on',\n",
       "  'wa',\n",
       "  'th',\n",
       "  'percentile',\n",
       "  'in',\n",
       "  'term',\n",
       "  'of',\n",
       "  'last',\n",
       "  'trading',\n",
       "  'day'],\n",
       " ['absolutely',\n",
       "  'true',\n",
       "  'and',\n",
       "  'throwing',\n",
       "  'more',\n",
       "  'body',\n",
       "  'at',\n",
       "  'the',\n",
       "  'issue',\n",
       "  'often',\n",
       "  'creates',\n",
       "  'new',\n",
       "  'one',\n",
       "  'stay',\n",
       "  'the',\n",
       "  'course'],\n",
       " ['agree', 'with', 'these', 'guy'],\n",
       " ['short', 'sale', 'volume', 'not', 'short', 'interest', 'for', 'is'],\n",
       " ['in',\n",
       "  'term',\n",
       "  'of',\n",
       "  'positive',\n",
       "  'for',\n",
       "  'there',\n",
       "  'are',\n",
       "  'bullish',\n",
       "  'indicator',\n",
       "  'a',\n",
       "  'of'],\n",
       " ['if',\n",
       "  'it',\n",
       "  'ran',\n",
       "  'and',\n",
       "  'looked',\n",
       "  'like',\n",
       "  'the',\n",
       "  'folding',\n",
       "  'device',\n",
       "  'in',\n",
       "  'westworld',\n",
       "  'even',\n",
       "  'this',\n",
       "  'apple',\n",
       "  'fan',\n",
       "  'would',\n",
       "  'buy',\n",
       "  'one'],\n",
       " ['fed', 'waterboarding', 'deutschebank', 'also'],\n",
       " ['a',\n",
       "  'soon',\n",
       "  'a',\n",
       "  'they',\n",
       "  'did',\n",
       "  'that',\n",
       "  'they',\n",
       "  'tip',\n",
       "  'their',\n",
       "  'hand',\n",
       "  'to',\n",
       "  'the',\n",
       "  'competition',\n",
       "  'approve',\n",
       "  'of',\n",
       "  'that',\n",
       "  'purchase',\n",
       "  'all',\n",
       "  'the',\n",
       "  'same'],\n",
       " ['short', 'volume', 'percent', 'for', 'wa', 'on', 'decrease', 'of', 'from'],\n",
       " ['space',\n",
       "  'grey',\n",
       "  'macbook',\n",
       "  'pro',\n",
       "  'with',\n",
       "  'touch',\n",
       "  'bar',\n",
       "  'running',\n",
       "  'mojave',\n",
       "  'dark',\n",
       "  'mode'],\n",
       " ['short', 'ratio', 'on', 'is', 'and', 'short', 'to', 'float', 'is'],\n",
       " ['today', 'insight', 'on'],\n",
       " ['aggregate',\n",
       "  'short',\n",
       "  'volume',\n",
       "  'reported',\n",
       "  'to',\n",
       "  'finra',\n",
       "  'for',\n",
       "  'wa',\n",
       "  'on'],\n",
       " ['today', 'insight', 'on'],\n",
       " ['ha',\n",
       "  'an',\n",
       "  'altman',\n",
       "  'score',\n",
       "  'of',\n",
       "  'meaning',\n",
       "  'it',\n",
       "  'is',\n",
       "  'financially',\n",
       "  'healthy',\n",
       "  'with',\n",
       "  'little',\n",
       "  'risk',\n",
       "  'of',\n",
       "  'bankruptcy'],\n",
       " ['special', 'on', 'sale', 'one', 'day', 'only', 'only', 'each'],\n",
       " ['short', 'sale', 'volume', 'not', 'short', 'interest', 'for', 'on', 'is'],\n",
       " ['bear', 'have', 'reason', 'on', 'to', 'pay', 'more', 'attention'],\n",
       " ['just',\n",
       "  'rant',\n",
       "  'no',\n",
       "  'position',\n",
       "  'trip',\n",
       "  'advisor',\n",
       "  'search',\n",
       "  'algo',\n",
       "  'is',\n",
       "  'horrible',\n",
       "  'have',\n",
       "  'to',\n",
       "  'search',\n",
       "  'on',\n",
       "  'google',\n",
       "  'to',\n",
       "  'find',\n",
       "  'anything',\n",
       "  'on',\n",
       "  'trip',\n",
       "  'fire',\n",
       "  'developer'],\n",
       " ['aggregate',\n",
       "  'short',\n",
       "  'volume',\n",
       "  'reported',\n",
       "  'to',\n",
       "  'finra',\n",
       "  'for',\n",
       "  'wa',\n",
       "  'on'],\n",
       " ['the',\n",
       "  'short',\n",
       "  'sale',\n",
       "  'volume',\n",
       "  'not',\n",
       "  'short',\n",
       "  'interest',\n",
       "  'for',\n",
       "  'on',\n",
       "  'is'],\n",
       " ['move',\n",
       "  'down',\n",
       "  'on',\n",
       "  'monday',\n",
       "  'signaled',\n",
       "  'major',\n",
       "  'reversal',\n",
       "  'could',\n",
       "  'rally',\n",
       "  'in',\n",
       "  'anticipation',\n",
       "  'of',\n",
       "  'earnings',\n",
       "  'but',\n",
       "  'that',\n",
       "  'will',\n",
       "  'be',\n",
       "  'the',\n",
       "  'end'],\n",
       " ['smart',\n",
       "  'money',\n",
       "  'getting',\n",
       "  'out',\n",
       "  'of',\n",
       "  'the',\n",
       "  'faangs',\n",
       "  'especially',\n",
       "  'amzn',\n",
       "  'fb',\n",
       "  'nflx',\n",
       "  'bubble',\n",
       "  'deflating',\n",
       "  'a',\n",
       "  'cash',\n",
       "  'becomes',\n",
       "  'more',\n",
       "  'attractive',\n",
       "  'with',\n",
       "  'higher',\n",
       "  'rate'],\n",
       " ['short', 'volume', 'percent', 'for', 'wa', 'on'],\n",
       " ['bull', 'have', 'reason', 'on', 'to', 'pay', 'more', 'attention'],\n",
       " ['the',\n",
       "  'piotroski',\n",
       "  'score',\n",
       "  'of',\n",
       "  'is',\n",
       "  'indicating',\n",
       "  'great',\n",
       "  'health',\n",
       "  'for'],\n",
       " ['in',\n",
       "  'term',\n",
       "  'of',\n",
       "  'negative',\n",
       "  'for',\n",
       "  'there',\n",
       "  'are',\n",
       "  'bearish',\n",
       "  'indicator',\n",
       "  'a',\n",
       "  'of'],\n",
       " [],\n",
       " [],\n",
       " ['buy',\n",
       "  'opportunity',\n",
       "  'at',\n",
       "  'intel',\n",
       "  'intc',\n",
       "  'monthly',\n",
       "  'demand',\n",
       "  'level',\n",
       "  'intel',\n",
       "  'intc',\n",
       "  'ha',\n",
       "  'clear',\n",
       "  'long',\n",
       "  'term',\n",
       "  'long',\n",
       "  'bias',\n",
       "  'buy',\n",
       "  'opportunt'],\n",
       " ['lot',\n",
       "  'of',\n",
       "  'people',\n",
       "  'chuckling',\n",
       "  'a',\n",
       "  'short',\n",
       "  'been',\n",
       "  'saying',\n",
       "  'this',\n",
       "  'all',\n",
       "  'year',\n",
       "  'but',\n",
       "  'selling',\n",
       "  'into',\n",
       "  'strength',\n",
       "  'since',\n",
       "  'monday',\n",
       "  'spanking',\n",
       "  'show',\n",
       "  'issue'],\n",
       " ['will',\n",
       "  'it',\n",
       "  'break',\n",
       "  'this',\n",
       "  'level',\n",
       "  'of',\n",
       "  'resistance',\n",
       "  'hi',\n",
       "  'guy',\n",
       "  'this',\n",
       "  'is',\n",
       "  'just',\n",
       "  'my',\n",
       "  'novice',\n",
       "  'analysis',\n",
       "  'on',\n",
       "  'apc',\n",
       "  'any',\n",
       "  'insight',\n",
       "  'argument'],\n",
       " ['earning',\n",
       "  'update',\n",
       "  'micron',\n",
       "  'technology',\n",
       "  'inc',\n",
       "  'for',\n",
       "  'quarter',\n",
       "  'ending',\n",
       "  'may'],\n",
       " ['earning', 'update', 'carmax', 'inc', 'for', 'quarter', 'ending', 'may'],\n",
       " ['you',\n",
       "  'can',\n",
       "  'read',\n",
       "  'the',\n",
       "  'transcript',\n",
       "  'yourself',\n",
       "  'saudi',\n",
       "  'have',\n",
       "  'million',\n",
       "  'barrel',\n",
       "  'not',\n",
       "  'that',\n",
       "  'they',\n",
       "  'can',\n",
       "  'produce',\n",
       "  'extra',\n",
       "  'what',\n",
       "  'read'],\n",
       " ['ouch',\n",
       "  'for',\n",
       "  'if',\n",
       "  'started',\n",
       "  'trading',\n",
       "  'day',\n",
       "  'ago',\n",
       "  'shorter',\n",
       "  'return',\n",
       "  'would',\n",
       "  'be',\n",
       "  'around',\n",
       "  'a',\n",
       "  'of',\n",
       "  'iex',\n",
       "  'data'],\n",
       " ['very',\n",
       "  'interesting',\n",
       "  'trend',\n",
       "  'on',\n",
       "  'the',\n",
       "  'month',\n",
       "  'chart',\n",
       "  'big',\n",
       "  'drop',\n",
       "  'followed',\n",
       "  'by',\n",
       "  'the',\n",
       "  'buy',\n",
       "  'then',\n",
       "  'quick',\n",
       "  'sell',\n",
       "  'buy',\n",
       "  'indicator',\n",
       "  'happens',\n",
       "  'before',\n",
       "  'every',\n",
       "  'run',\n",
       "  'up'],\n",
       " ['come',\n",
       "  'on',\n",
       "  'bear',\n",
       "  'scare',\n",
       "  'them',\n",
       "  'because',\n",
       "  'want',\n",
       "  'to',\n",
       "  'buy',\n",
       "  'this',\n",
       "  'cheaper',\n",
       "  'before',\n",
       "  'er',\n",
       "  'day',\n",
       "  'rip'],\n",
       " ['today', 'insight', 'on'],\n",
       " ['short', 'sale', 'volume', 'not', 'short', 'interest', 'for', 'on', 'is'],\n",
       " ['short',\n",
       "  'interest',\n",
       "  'ratio',\n",
       "  'is',\n",
       "  'on',\n",
       "  'and',\n",
       "  'short',\n",
       "  'to',\n",
       "  'float',\n",
       "  'is'],\n",
       " ['is', 'buy', 'or', 'sell'],\n",
       " ['we',\n",
       "  'have',\n",
       "  'detected',\n",
       "  'negative',\n",
       "  'indicator',\n",
       "  'a',\n",
       "  'of',\n",
       "  'for',\n",
       "  'more',\n",
       "  'info',\n",
       "  'at'],\n",
       " ['facebook', 'had', 'data', 'sharing', 'partnership', 'with', 'tech', 'firm'],\n",
       " [],\n",
       " ['bear', 'have', 'reason', 'on', 'to', 'pay', 'more', 'attention'],\n",
       " ['earning',\n",
       "  'update',\n",
       "  'mccormick',\n",
       "  'amp',\n",
       "  'company',\n",
       "  'incorporated',\n",
       "  'for',\n",
       "  'quarter',\n",
       "  'ending',\n",
       "  'may',\n",
       "  'revenue',\n",
       "  'rose',\n",
       "  'but',\n",
       "  'margin',\n",
       "  'contracted'],\n",
       " ['earning',\n",
       "  'update',\n",
       "  'nike',\n",
       "  'inc',\n",
       "  'for',\n",
       "  'quarter',\n",
       "  'ending',\n",
       "  'may',\n",
       "  'revenue',\n",
       "  'grew',\n",
       "  'margin',\n",
       "  'expanded'],\n",
       " ['aggregate',\n",
       "  'short',\n",
       "  'volume',\n",
       "  'reported',\n",
       "  'to',\n",
       "  'finra',\n",
       "  'for',\n",
       "  'wa',\n",
       "  'on'],\n",
       " ['crude',\n",
       "  'oil',\n",
       "  'and',\n",
       "  'the',\n",
       "  'moving',\n",
       "  'in',\n",
       "  'tandem',\n",
       "  'since',\n",
       "  'the',\n",
       "  'feb',\n",
       "  'low',\n",
       "  'low',\n",
       "  'for',\n",
       "  'u',\n",
       "  'correlation',\n",
       "  'trader',\n",
       "  'are',\n",
       "  'an',\n",
       "  'extinct',\n",
       "  'breed',\n",
       "  'of',\n",
       "  'trader',\n",
       "  'these',\n",
       "  'day'],\n",
       " ['could',\n",
       "  'be',\n",
       "  'going',\n",
       "  'up',\n",
       "  'lol',\n",
       "  'with',\n",
       "  'wc',\n",
       "  'and',\n",
       "  'le',\n",
       "  'vip',\n",
       "  'still',\n",
       "  'easy',\n",
       "  'monday'],\n",
       " ['ha',\n",
       "  'bad',\n",
       "  'technical',\n",
       "  'rating',\n",
       "  'but',\n",
       "  'it',\n",
       "  'doe',\n",
       "  'show',\n",
       "  'decent',\n",
       "  'setup',\n",
       "  'pattern'],\n",
       " ['short',\n",
       "  'volume',\n",
       "  'for',\n",
       "  'on',\n",
       "  'wa',\n",
       "  'th',\n",
       "  'percentile',\n",
       "  'in',\n",
       "  'term',\n",
       "  'of',\n",
       "  'last',\n",
       "  'trading',\n",
       "  'day'],\n",
       " ['would',\n",
       "  'any',\n",
       "  'of',\n",
       "  'the',\n",
       "  'energy',\n",
       "  'major',\n",
       "  'bring',\n",
       "  'solar',\n",
       "  'into',\n",
       "  'their',\n",
       "  'business',\n",
       "  'in',\n",
       "  'order',\n",
       "  'to',\n",
       "  'diversify',\n",
       "  'long',\n",
       "  'term',\n",
       "  'or',\n",
       "  'just',\n",
       "  'poor',\n",
       "  'use',\n",
       "  'of',\n",
       "  'capital'],\n",
       " ['short', 'sale', 'volume', 'not', 'short', 'interest', 'for', 'on', 'is'],\n",
       " [],\n",
       " ['ouch',\n",
       "  'for',\n",
       "  'if',\n",
       "  'started',\n",
       "  'trading',\n",
       "  'day',\n",
       "  'ago',\n",
       "  'shorter',\n",
       "  'return',\n",
       "  'would',\n",
       "  'be',\n",
       "  'around',\n",
       "  'a',\n",
       "  'of',\n",
       "  'iex',\n",
       "  'data'],\n",
       " ['permabulls',\n",
       "  'here',\n",
       "  'gonna',\n",
       "  'be',\n",
       "  'posting',\n",
       "  'like',\n",
       "  'the',\n",
       "  'one',\n",
       "  'at',\n",
       "  'in',\n",
       "  'no',\n",
       "  'time'],\n",
       " ['according',\n",
       "  'to',\n",
       "  'data',\n",
       "  'reported',\n",
       "  'to',\n",
       "  'finra',\n",
       "  'short',\n",
       "  'volume',\n",
       "  'percent',\n",
       "  'for',\n",
       "  'clocked',\n",
       "  'in',\n",
       "  'at',\n",
       "  'on'],\n",
       " ['today', 'insight', 'on'],\n",
       " ['today', 'insight', 'on'],\n",
       " ['today', 'insight', 'on'],\n",
       " ['hehe',\n",
       "  'we',\n",
       "  've',\n",
       "  'been',\n",
       "  'through',\n",
       "  'hate',\n",
       "  'phase',\n",
       "  'before',\n",
       "  'remember',\n",
       "  'when',\n",
       "  'the',\n",
       "  'subae',\n",
       "  'post',\n",
       "  'became',\n",
       "  'lisahate',\n",
       "  'during',\n",
       "  'the',\n",
       "  'gt',\n",
       "  'gt',\n",
       "  'amp',\n",
       "  'er'],\n",
       " [],\n",
       " ['short', 'sale', 'volume', 'not', 'short', 'interest', 'for', 'is'],\n",
       " ['short', 'volume', 'percent', 'for', 'wa', 'on', 'versus', 'on'],\n",
       " ['market',\n",
       "  'will',\n",
       "  'gap',\n",
       "  'down',\n",
       "  'in',\n",
       "  'monday',\n",
       "  'big',\n",
       "  'sell',\n",
       "  'off',\n",
       "  'again'],\n",
       " ['short', 'sale', 'volume', 'not', 'short', 'interest', 'for', 'on', 'is'],\n",
       " ['we',\n",
       "  'have',\n",
       "  'detected',\n",
       "  'negative',\n",
       "  'indicator',\n",
       "  'a',\n",
       "  'of',\n",
       "  'for',\n",
       "  'more',\n",
       "  'info',\n",
       "  'at'],\n",
       " ['according',\n",
       "  'to',\n",
       "  'data',\n",
       "  'reported',\n",
       "  'to',\n",
       "  'finra',\n",
       "  'short',\n",
       "  'volume',\n",
       "  'percent',\n",
       "  'for',\n",
       "  'clocked',\n",
       "  'in',\n",
       "  'at',\n",
       "  'on'],\n",
       " ['bank',\n",
       "  'of',\n",
       "  'america',\n",
       "  'corp',\n",
       "  'bac',\n",
       "  'is',\n",
       "  'swarthmore',\n",
       "  'group',\n",
       "  'inc',\n",
       "  'th',\n",
       "  'largest',\n",
       "  'position'],\n",
       " ['short', 'sale', 'volume', 'not', 'short', 'interest', 'for', 'at', 'is'],\n",
       " ['monday', 'wl'],\n",
       " ['we',\n",
       "  'have',\n",
       "  'detected',\n",
       "  'positive',\n",
       "  'indicator',\n",
       "  'a',\n",
       "  'of',\n",
       "  'for',\n",
       "  'more',\n",
       "  'info',\n",
       "  'at'],\n",
       " ['short',\n",
       "  'interest',\n",
       "  'ratio',\n",
       "  'is',\n",
       "  'on',\n",
       "  'and',\n",
       "  'short',\n",
       "  'to',\n",
       "  'float',\n",
       "  'is'],\n",
       " ['retailer',\n",
       "  'jill',\n",
       "  'ipo',\n",
       "  'at',\n",
       "  'bad',\n",
       "  'time',\n",
       "  'but',\n",
       "  'you',\n",
       "  'can',\n",
       "  'buy',\n",
       "  'at',\n",
       "  'good',\n",
       "  'time',\n",
       "  'also'],\n",
       " ['disney',\n",
       "  'never',\n",
       "  'missed',\n",
       "  'chance',\n",
       "  'to',\n",
       "  'push',\n",
       "  'their',\n",
       "  'liberal',\n",
       "  'unnatural',\n",
       "  'agenda',\n",
       "  'the',\n",
       "  'army',\n",
       "  'men',\n",
       "  'at',\n",
       "  'new',\n",
       "  'toy',\n",
       "  'story',\n",
       "  'land',\n",
       "  'ha',\n",
       "  'woman',\n",
       "  'just',\n",
       "  'absurd'],\n",
       " ['aggregate',\n",
       "  'short',\n",
       "  'volume',\n",
       "  'reported',\n",
       "  'to',\n",
       "  'finra',\n",
       "  'for',\n",
       "  'wa',\n",
       "  'on'],\n",
       " ['to',\n",
       "  'me',\n",
       "  'it',\n",
       "  'look',\n",
       "  'like',\n",
       "  'drop',\n",
       "  'off',\n",
       "  'due',\n",
       "  'to',\n",
       "  'wc',\n",
       "  'if',\n",
       "  'we',\n",
       "  'were',\n",
       "  'in',\n",
       "  'the',\n",
       "  'worry',\n",
       "  'at',\n",
       "  'think',\n",
       "  'we',\n",
       "  'hover',\n",
       "  'around',\n",
       "  'here',\n",
       "  'till',\n",
       "  'earnings'],\n",
       " ['today', 'insight', 'on'],\n",
       " ['remember',\n",
       "  'drink',\n",
       "  'your',\n",
       "  'poison',\n",
       "  'water',\n",
       "  'need',\n",
       "  'to',\n",
       "  'get',\n",
       "  'back',\n",
       "  'over',\n",
       "  'by',\n",
       "  'september',\n",
       "  'lol',\n",
       "  'drink',\n",
       "  'it',\n",
       "  'you',\n",
       "  'little',\n",
       "  'bastard',\n",
       "  'drink',\n",
       "  'it'],\n",
       " ['company',\n",
       "  'offer',\n",
       "  'trans',\n",
       "  'health',\n",
       "  'plan',\n",
       "  'this',\n",
       "  'year',\n",
       "  'relax',\n",
       "  'with',\n",
       "  'the',\n",
       "  'comment',\n",
       "  'and',\n",
       "  'actually',\n",
       "  'read',\n",
       "  'the',\n",
       "  'article'],\n",
       " ['of', 'course', 'he', 'lied', 'again'],\n",
       " ['short', 'sale', 'volume', 'not', 'short', 'interest', 'for', 'at', 'is'],\n",
       " ['bull', 'have', 'reason', 'on', 'to', 'pay', 'more', 'attention'],\n",
       " ['option',\n",
       "  'volume',\n",
       "  'wa',\n",
       "  'normal',\n",
       "  'on',\n",
       "  'friday',\n",
       "  'with',\n",
       "  'contract',\n",
       "  'call',\n",
       "  'volume',\n",
       "  'wa',\n",
       "  'and',\n",
       "  'put',\n",
       "  'volume',\n",
       "  'wa'],\n",
       " ['short', 'ratio', 'of', 'is', 'at', 'and', 'short', 'to', 'float', 'is'],\n",
       " ['in',\n",
       "  'term',\n",
       "  'of',\n",
       "  'positive',\n",
       "  'for',\n",
       "  'there',\n",
       "  'are',\n",
       "  'bullish',\n",
       "  'indicator',\n",
       "  'a',\n",
       "  'of'],\n",
       " ['my',\n",
       "  'favorite',\n",
       "  'set',\n",
       "  'up',\n",
       "  'this',\n",
       "  'week',\n",
       "  'year',\n",
       "  'chart',\n",
       "  'bottom',\n",
       "  'of',\n",
       "  'wedge',\n",
       "  'watch',\n",
       "  'and',\n",
       "  'bought',\n",
       "  'target',\n",
       "  'on',\n",
       "  'break'],\n",
       " ['accelerating',\n",
       "  'growth',\n",
       "  'is',\n",
       "  'expecting',\n",
       "  'stronger',\n",
       "  'growth',\n",
       "  'in',\n",
       "  'the',\n",
       "  'upcoming',\n",
       "  'year',\n",
       "  'than',\n",
       "  'in',\n",
       "  'the',\n",
       "  'passed',\n",
       "  'year'],\n",
       " ['long', 'over'],\n",
       " ['besides',\n",
       "  'having',\n",
       "  'an',\n",
       "  'excellent',\n",
       "  'technical',\n",
       "  'rating',\n",
       "  'also',\n",
       "  'present',\n",
       "  'decent',\n",
       "  'setup',\n",
       "  'pattern'],\n",
       " ['long', 'over'],\n",
       " ['long', 'over'],\n",
       " ['freaked',\n",
       "  'out',\n",
       "  'american',\n",
       "  'desperately',\n",
       "  'seek',\n",
       "  'to',\n",
       "  'escape',\n",
       "  'the',\n",
       "  'news',\n",
       "  'msm',\n",
       "  'fake',\n",
       "  'news',\n",
       "  'data',\n",
       "  'outrageous',\n",
       "  'lie',\n",
       "  'propaganda'],\n",
       " ['making', 'more', 'than', 'ever', 'thanks', 'to', 'amp'],\n",
       " ['short', 'volume', 'percent', 'for', 'wa', 'on'],\n",
       " ['dont', 'let', 'bear', 'fool', 'you'],\n",
       " ['can', 'buffet', 'increase', 'his', 'holding'],\n",
       " ['ha',\n",
       "  'return',\n",
       "  'on',\n",
       "  'asset',\n",
       "  'of',\n",
       "  'this',\n",
       "  'is',\n",
       "  'better',\n",
       "  'than',\n",
       "  'the',\n",
       "  'industry',\n",
       "  'average',\n",
       "  'of'],\n",
       " ['will', 'we', 'see', 'another', 'soon'],\n",
       " ['double',\n",
       "  'top',\n",
       "  'bearish',\n",
       "  'divergence',\n",
       "  'bearish',\n",
       "  'convergence',\n",
       "  'bearish',\n",
       "  'hidden',\n",
       "  'divergence',\n",
       "  'double',\n",
       "  'top',\n",
       "  'breakaway',\n",
       "  'gap',\n",
       "  'to',\n",
       "  'the',\n",
       "  'dow'],\n",
       " ['return',\n",
       "  'on',\n",
       "  'equity',\n",
       "  'of',\n",
       "  'is',\n",
       "  'amongst',\n",
       "  'the',\n",
       "  'best',\n",
       "  'of',\n",
       "  'the',\n",
       "  'industry'],\n",
       " ['max', 'pain', 'maturity', 'maxpain', 'option'],\n",
       " ['we', 'can', 'expect', 'another', 'ath', 'in', 'coming', 'week'],\n",
       " [],\n",
       " ['the',\n",
       "  'semi',\n",
       "  'took',\n",
       "  'beating',\n",
       "  'and',\n",
       "  'think',\n",
       "  'this',\n",
       "  'will',\n",
       "  'edge',\n",
       "  'higher',\n",
       "  'towards',\n",
       "  'earnings'],\n",
       " [],\n",
       " ['weighing',\n",
       "  'the',\n",
       "  'week',\n",
       "  'ahead',\n",
       "  'is',\n",
       "  'it',\n",
       "  'time',\n",
       "  'to',\n",
       "  'worry',\n",
       "  'about'],\n",
       " ['short',\n",
       "  'volume',\n",
       "  'for',\n",
       "  'on',\n",
       "  'wa',\n",
       "  'th',\n",
       "  'percentile',\n",
       "  'in',\n",
       "  'term',\n",
       "  'of',\n",
       "  'last',\n",
       "  'trading',\n",
       "  'day'],\n",
       " ['cv', 'health', 'buy', 'rating', 'reiterated', 'at', 'mizuho'],\n",
       " ['bernstein',\n",
       "  'analyst',\n",
       "  'todd',\n",
       "  'juenger',\n",
       "  'see',\n",
       "  'big',\n",
       "  'amp',\n",
       "  'potential',\n",
       "  'for',\n",
       "  'video',\n",
       "  'game',\n",
       "  'publisher'],\n",
       " ['bear', 'have', 'reason', 'on', 'to', 'pay', 'more', 'attention'],\n",
       " ['today', 'insight', 'on'],\n",
       " ['if',\n",
       "  'anything',\n",
       "  'it',\n",
       "  'is',\n",
       "  'prolly',\n",
       "  'more',\n",
       "  'likely',\n",
       "  'that',\n",
       "  'opec',\n",
       "  'will',\n",
       "  'not',\n",
       "  'increase',\n",
       "  'production',\n",
       "  'given',\n",
       "  'the',\n",
       "  'development',\n",
       "  'over',\n",
       "  'trump',\n",
       "  'statement'],\n",
       " ['short',\n",
       "  'volume',\n",
       "  'percent',\n",
       "  'for',\n",
       "  'wa',\n",
       "  'on',\n",
       "  'and',\n",
       "  'day',\n",
       "  'rank',\n",
       "  'wa',\n",
       "  'th',\n",
       "  'percentile'],\n",
       " ['if',\n",
       "  'economic',\n",
       "  'growth',\n",
       "  'accelerates',\n",
       "  'further',\n",
       "  'oil',\n",
       "  'demand',\n",
       "  'will',\n",
       "  'increase',\n",
       "  'and',\n",
       "  'producer',\n",
       "  'will',\n",
       "  'not',\n",
       "  'be',\n",
       "  'able',\n",
       "  'even',\n",
       "  'if',\n",
       "  'willing',\n",
       "  'to',\n",
       "  'ramp',\n",
       "  'up',\n",
       "  'production'],\n",
       " ['recent',\n",
       "  'survey',\n",
       "  'show',\n",
       "  'consumer',\n",
       "  'are',\n",
       "  'reluctant',\n",
       "  'to',\n",
       "  'cancel',\n",
       "  'netflix',\n",
       "  'when',\n",
       "  'disney',\n",
       "  'content',\n",
       "  'get',\n",
       "  'pulled',\n",
       "  'from',\n",
       "  'it'],\n",
       " ['short', 'sale', 'volume', 'not', 'short', 'interest', 'for', 'is'],\n",
       " ['we',\n",
       "  'have',\n",
       "  'the',\n",
       "  'perfect',\n",
       "  'storm',\n",
       "  'rising',\n",
       "  'demand',\n",
       "  'pulling',\n",
       "  'price',\n",
       "  'higher',\n",
       "  'producer',\n",
       "  'unable',\n",
       "  'to',\n",
       "  'increase',\n",
       "  'supply',\n",
       "  'chk',\n",
       "  'debt',\n",
       "  'red',\n",
       "  'and',\n",
       "  'more',\n",
       "  'eff',\n",
       "  'ops'],\n",
       " ['will', 'walmart', 'buy', 'uhn'],\n",
       " ['chk',\n",
       "  'profit',\n",
       "  'set',\n",
       "  'to',\n",
       "  'soar',\n",
       "  'based',\n",
       "  'on',\n",
       "  'more',\n",
       "  'eff',\n",
       "  'ops',\n",
       "  'and',\n",
       "  'significantly',\n",
       "  'higher',\n",
       "  'energy',\n",
       "  'price'],\n",
       " ['jpmorgan',\n",
       "  'chase',\n",
       "  'is',\n",
       "  'rolling',\n",
       "  'out',\n",
       "  'it',\n",
       "  'finn',\n",
       "  'app',\n",
       "  'only',\n",
       "  'bank',\n",
       "  'account',\n",
       "  'nationwide'],\n",
       " ['been',\n",
       "  'while',\n",
       "  'since',\n",
       "  'higher',\n",
       "  'oil',\n",
       "  'brought',\n",
       "  'higher',\n",
       "  'interest',\n",
       "  'rate',\n",
       "  'and',\n",
       "  'inflation',\n",
       "  'triggering',\n",
       "  'broader',\n",
       "  'market',\n",
       "  'meltdown',\n",
       "  'oil',\n",
       "  'stock',\n",
       "  'soared',\n",
       "  'tho'],\n",
       " ['short', 'sale', 'volume', 'not', 'short', 'interest', 'for', 'on', 'is'],\n",
       " ['staying',\n",
       "  'bullish',\n",
       "  'is',\n",
       "  'hard',\n",
       "  'right',\n",
       "  'now',\n",
       "  'but',\n",
       "  'here',\n",
       "  'my',\n",
       "  'plan',\n",
       "  'tradecrew',\n",
       "  'focus'],\n",
       " ['apple', 'map', 'is', 'here', 'to', 'stay', 'unfortunately'],\n",
       " ['big', 'big', 'volume', 'with', 'news'],\n",
       " ['in',\n",
       "  'term',\n",
       "  'of',\n",
       "  'positive',\n",
       "  'for',\n",
       "  'there',\n",
       "  'are',\n",
       "  'bullish',\n",
       "  'indicator',\n",
       "  'a',\n",
       "  'of'],\n",
       " ['baked',\n",
       "  'in',\n",
       "  'already',\n",
       "  'due',\n",
       "  'to',\n",
       "  'soccer',\n",
       "  'world',\n",
       "  'cup',\n",
       "  'open',\n",
       "  'monday'],\n",
       " ['worst', 'consumer', 'discretionary', 'stock', 'in', 'amp', 'for', 'june'],\n",
       " ['doubting', 'nvidia', 'future', 'is', 'dumb'],\n",
       " ['short',\n",
       "  'this',\n",
       "  'pig',\n",
       "  'tom',\n",
       "  'clarke',\n",
       "  'is',\n",
       "  'the',\n",
       "  'boogeyman',\n",
       "  'and',\n",
       "  'he',\n",
       "  'is',\n",
       "  'coming',\n",
       "  'to',\n",
       "  'getcha'],\n",
       " ['option',\n",
       "  'volume',\n",
       "  'wa',\n",
       "  'normal',\n",
       "  'on',\n",
       "  'friday',\n",
       "  'with',\n",
       "  'contract',\n",
       "  'call',\n",
       "  'volume',\n",
       "  'wa',\n",
       "  'and',\n",
       "  'put',\n",
       "  'volume',\n",
       "  'wa'],\n",
       " ['best', 'consumer', 'discretionary', 'stock', 'in', 'amp', 'for', 'june'],\n",
       " ['go',\n",
       "  'look',\n",
       "  'at',\n",
       "  'and',\n",
       "  'soccer',\n",
       "  'world',\n",
       "  'cup',\n",
       "  'turnaround',\n",
       "  'it',\n",
       "  'deep',\n",
       "  'red',\n",
       "  'but',\n",
       "  'we',\n",
       "  'are',\n",
       "  'now',\n",
       "  'up',\n",
       "  'which',\n",
       "  'is',\n",
       "  'great',\n",
       "  'improvement'],\n",
       " ['max', 'pain', 'is', 'for', 'maturity', 'maxpain', 'option'],\n",
       " ['baked', 'in', 'bullish', 'monday'],\n",
       " ['ha',\n",
       "  'bad',\n",
       "  'technical',\n",
       "  'rating',\n",
       "  'but',\n",
       "  'it',\n",
       "  'doe',\n",
       "  'show',\n",
       "  'decent',\n",
       "  'setup',\n",
       "  'pattern'],\n",
       " ['we',\n",
       "  'have',\n",
       "  'detected',\n",
       "  'negative',\n",
       "  'indicator',\n",
       "  'a',\n",
       "  'of',\n",
       "  'for',\n",
       "  'more',\n",
       "  'info',\n",
       "  'at'],\n",
       " [],\n",
       " ['on', 'the', 'fly', 'top', 'stock', 'story'],\n",
       " ['short',\n",
       "  'interest',\n",
       "  'ratio',\n",
       "  'at',\n",
       "  'is',\n",
       "  'and',\n",
       "  'short',\n",
       "  'to',\n",
       "  'float',\n",
       "  'is'],\n",
       " ['we',\n",
       "  'have',\n",
       "  'detected',\n",
       "  'positive',\n",
       "  'indicator',\n",
       "  'a',\n",
       "  'of',\n",
       "  'for',\n",
       "  'more',\n",
       "  'info',\n",
       "  'at'],\n",
       " ['this', 'is', 'good', 'for', 'and'],\n",
       " ['very'],\n",
       " ['short', 'sale', 'volume', 'not', 'short', 'interest', 'for', 'is'],\n",
       " ['do',\n",
       "  'agree',\n",
       "  'with',\n",
       "  'off',\n",
       "  'loading',\n",
       "  'it',\n",
       "  'pizza',\n",
       "  'chain',\n",
       "  'with',\n",
       "  'lot',\n",
       "  'of',\n",
       "  'competitor',\n",
       "  'and',\n",
       "  'marginal',\n",
       "  'product',\n",
       "  'different',\n",
       "  'story'],\n",
       " ['ha',\n",
       "  'very',\n",
       "  'good',\n",
       "  'piotroski',\n",
       "  'score',\n",
       "  'of',\n",
       "  'this',\n",
       "  'indicates',\n",
       "  'great',\n",
       "  'health',\n",
       "  'and',\n",
       "  'profitability'],\n",
       " ['long',\n",
       "  'gaming',\n",
       "  'stock',\n",
       "  'all',\n",
       "  'will',\n",
       "  'do',\n",
       "  'well',\n",
       "  'huge',\n",
       "  'secular',\n",
       "  'growth',\n",
       "  'winner'],\n",
       " ['if',\n",
       "  'started',\n",
       "  'on',\n",
       "  'st',\n",
       "  'the',\n",
       "  'short',\n",
       "  'year',\n",
       "  'to',\n",
       "  'date',\n",
       "  'return',\n",
       "  'would',\n",
       "  'be',\n",
       "  'around',\n",
       "  'a',\n",
       "  'of'],\n",
       " ['option',\n",
       "  'volume',\n",
       "  'wa',\n",
       "  'normal',\n",
       "  'on',\n",
       "  'friday',\n",
       "  'with',\n",
       "  'contract',\n",
       "  'call',\n",
       "  'volume',\n",
       "  'wa',\n",
       "  'and',\n",
       "  'put',\n",
       "  'volume',\n",
       "  'wa'],\n",
       " ['bear', 'have', 'reason', 'on', 'to', 'pay', 'more', 'attention'],\n",
       " ['yep', 'joining', 'the', 'darkside', 'tradecrew', 'focus'],\n",
       " [],\n",
       " ['iraepstein',\n",
       "  'end',\n",
       "  'of',\n",
       "  'the',\n",
       "  'day',\n",
       "  'financial',\n",
       "  'video',\n",
       "  'weekend',\n",
       "  'edition'],\n",
       " ['xerox',\n",
       "  'is',\n",
       "  'above',\n",
       "  'it',\n",
       "  'year',\n",
       "  'low',\n",
       "  'and',\n",
       "  'below',\n",
       "  'it',\n",
       "  'year',\n",
       "  'high'],\n",
       " ['here',\n",
       "  'the',\n",
       "  'top',\n",
       "  'rated',\n",
       "  'big',\n",
       "  'cap',\n",
       "  'stock',\n",
       "  'in',\n",
       "  'exodus',\n",
       "  'heading',\n",
       "  'into',\n",
       "  'july',\n",
       "  'dr',\n",
       "  'fly'],\n",
       " [],\n",
       " ['both',\n",
       "  'the',\n",
       "  'short',\n",
       "  'term',\n",
       "  'and',\n",
       "  'long',\n",
       "  'term',\n",
       "  'trend',\n",
       "  'are',\n",
       "  'positive',\n",
       "  'this',\n",
       "  'is',\n",
       "  'very',\n",
       "  'positive',\n",
       "  'sign'],\n",
       " ['th'],\n",
       " ['ouch',\n",
       "  'for',\n",
       "  'if',\n",
       "  'started',\n",
       "  'trading',\n",
       "  'day',\n",
       "  'ago',\n",
       "  'shorter',\n",
       "  'return',\n",
       "  'would',\n",
       "  'be',\n",
       "  'around',\n",
       "  'a',\n",
       "  'of',\n",
       "  'iex',\n",
       "  'data'],\n",
       " ['weekly',\n",
       "  'still',\n",
       "  'short',\n",
       "  'nflx',\n",
       "  'pa',\n",
       "  'nothing',\n",
       "  'to',\n",
       "  'write',\n",
       "  'home',\n",
       "  'about',\n",
       "  'either',\n",
       "  'way',\n",
       "  'on',\n",
       "  'this',\n",
       "  'tf',\n",
       "  'price',\n",
       "  'overall',\n",
       "  'massively',\n",
       "  'over',\n",
       "  'extended',\n",
       "  'when',\n",
       "  'er'],\n",
       " ['alliance',\n",
       "  'data',\n",
       "  'is',\n",
       "  'the',\n",
       "  'only',\n",
       "  'info',\n",
       "  'tech',\n",
       "  'sector',\n",
       "  'stock',\n",
       "  'in',\n",
       "  'the',\n",
       "  'amp',\n",
       "  'with',\n",
       "  'negative',\n",
       "  'year',\n",
       "  'total',\n",
       "  'return',\n",
       "  'out',\n",
       "  'of'],\n",
       " ['since',\n",
       "  'last',\n",
       "  'er',\n",
       "  'stock',\n",
       "  'dropped',\n",
       "  'reporting',\n",
       "  'earnings',\n",
       "  'on',\n",
       "  'before',\n",
       "  'open',\n",
       "  'confirmed'],\n",
       " ['look',\n",
       "  'at',\n",
       "  'amp',\n",
       "  'there',\n",
       "  'are',\n",
       "  'many',\n",
       "  'different',\n",
       "  'comp',\n",
       "  'that',\n",
       "  'lost',\n",
       "  'money',\n",
       "  'for',\n",
       "  'year',\n",
       "  'amp',\n",
       "  'are',\n",
       "  'only',\n",
       "  'now',\n",
       "  'turning',\n",
       "  'profit',\n",
       "  'read',\n",
       "  'this'],\n",
       " ['looking', 'for', 'good', 'growth', 'with', 'this'],\n",
       " ['bet',\n",
       "  'intel',\n",
       "  'ceo',\n",
       "  'wa',\n",
       "  'fired',\n",
       "  'revealing',\n",
       "  'too',\n",
       "  'much',\n",
       "  'trade',\n",
       "  'secret',\n",
       "  'to',\n",
       "  'competitor',\n",
       "  'intel',\n",
       "  'is',\n",
       "  'losing',\n",
       "  'data',\n",
       "  'center',\n",
       "  'server',\n",
       "  'market',\n",
       "  'the',\n",
       "  'real',\n",
       "  'truth'],\n",
       " ['civil',\n",
       "  'lawsuit',\n",
       "  'and',\n",
       "  'arbitration',\n",
       "  'filed',\n",
       "  'against',\n",
       "  'ge',\n",
       "  'for',\n",
       "  'retaliation',\n",
       "  'by',\n",
       "  'employee',\n",
       "  'in',\n",
       "  'boston',\n",
       "  'office',\n",
       "  'may'],\n",
       " ['short', 'sale', 'volume', 'not', 'short', 'interest', 'for', 'on', 'is'],\n",
       " ['breakout',\n",
       "  'on',\n",
       "  'monthly',\n",
       "  'amp',\n",
       "  'weekly',\n",
       "  'enter',\n",
       "  'now',\n",
       "  'and',\n",
       "  'or',\n",
       "  'add',\n",
       "  'on',\n",
       "  'pullback',\n",
       "  'with',\n",
       "  'low',\n",
       "  'volume'],\n",
       " [],\n",
       " ['strong', 'buy'],\n",
       " ['this',\n",
       "  'board',\n",
       "  'need',\n",
       "  'to',\n",
       "  'be',\n",
       "  'more',\n",
       "  'active',\n",
       "  'on',\n",
       "  'weekend',\n",
       "  'need',\n",
       "  'my',\n",
       "  'fix'],\n",
       " ['how',\n",
       "  'to',\n",
       "  'position',\n",
       "  'your',\n",
       "  'portfolio',\n",
       "  'against',\n",
       "  'threat',\n",
       "  'like',\n",
       "  'trade',\n",
       "  'war',\n",
       "  'and',\n",
       "  'recession'],\n",
       " ['why',\n",
       "  'microsoft',\n",
       "  'samsung',\n",
       "  'and',\n",
       "  'others',\n",
       "  'are',\n",
       "  'interested',\n",
       "  'in',\n",
       "  'foldable',\n",
       "  'display'],\n",
       " ['last',\n",
       "  'year',\n",
       "  'same',\n",
       "  'time',\n",
       "  'month',\n",
       "  'price',\n",
       "  'target',\n",
       "  'reached',\n",
       "  'so',\n",
       "  'there',\n",
       "  'is',\n",
       "  'hope',\n",
       "  'for',\n",
       "  'rebound',\n",
       "  'if',\n",
       "  'china',\n",
       "  'trade',\n",
       "  'issue',\n",
       "  'is',\n",
       "  'resolved',\n",
       "  'quickly'],\n",
       " ['max', 'pain', 'is', 'for', 'maturity', 'maxpain', 'option'],\n",
       " ['recent',\n",
       "  'technical',\n",
       "  'alert',\n",
       "  'stochastic',\n",
       "  'buy',\n",
       "  'signal',\n",
       "  'plus',\n",
       "  'more',\n",
       "  'alert'],\n",
       " ['recent', 'technical', 'alert', 'new', 'uptrend', 'plus', 'more', 'alert'],\n",
       " ['recent',\n",
       "  'technical',\n",
       "  'alert',\n",
       "  'lower',\n",
       "  'bollinger',\n",
       "  'band',\n",
       "  'walk',\n",
       "  'plus',\n",
       "  'more',\n",
       "  'alert'],\n",
       " ['recent',\n",
       "  'technical',\n",
       "  'alert',\n",
       "  'bollinger',\n",
       "  'band',\n",
       "  'squeeze',\n",
       "  'plus',\n",
       "  'more',\n",
       "  'alert'],\n",
       " ['recent',\n",
       "  'technical',\n",
       "  'alert',\n",
       "  'macd',\n",
       "  'bearish',\n",
       "  'centerline',\n",
       "  'cross',\n",
       "  'plus',\n",
       "  'more',\n",
       "  'alert'],\n",
       " ['recent',\n",
       "  'technical',\n",
       "  'alert',\n",
       "  'bollinger',\n",
       "  'band',\n",
       "  'squeeze',\n",
       "  'plus',\n",
       "  'more',\n",
       "  'alert'],\n",
       " ['recent',\n",
       "  'technical',\n",
       "  'alert',\n",
       "  'slingshot',\n",
       "  'bearish',\n",
       "  'plus',\n",
       "  'more',\n",
       "  'alert'],\n",
       " ['short',\n",
       "  'have',\n",
       "  'sure',\n",
       "  'felt',\n",
       "  'some',\n",
       "  'pain',\n",
       "  'in',\n",
       "  'if',\n",
       "  'shorted',\n",
       "  'on',\n",
       "  'the',\n",
       "  'first',\n",
       "  'their',\n",
       "  'ytd',\n",
       "  'return',\n",
       "  'is',\n",
       "  'around',\n",
       "  'a',\n",
       "  'of'],\n",
       " ['short', 'volume', 'percent', 'for', 'wa', 'on', 'versus', 'on'],\n",
       " ['we',\n",
       "  'have',\n",
       "  'detected',\n",
       "  'positive',\n",
       "  'indicator',\n",
       "  'a',\n",
       "  'of',\n",
       "  'for',\n",
       "  'more',\n",
       "  'info',\n",
       "  'at'],\n",
       " ['bear',\n",
       "  'here',\n",
       "  'are',\n",
       "  'paying',\n",
       "  'zero',\n",
       "  'attention',\n",
       "  'ford',\n",
       "  'is',\n",
       "  'destroying',\n",
       "  'sale'],\n",
       " [],\n",
       " ['dragonfly', 'capital', 'trade', 'idea', 'for', 'monday'],\n",
       " ['nice',\n",
       "  'email',\n",
       "  'from',\n",
       "  'about',\n",
       "  'essential',\n",
       "  'nike',\n",
       "  'for',\n",
       "  'this',\n",
       "  'summer',\n",
       "  'glad',\n",
       "  'own',\n",
       "  'both'],\n",
       " ['depleting',\n",
       "  'revenue',\n",
       "  'stream',\n",
       "  'run',\n",
       "  'by',\n",
       "  'old',\n",
       "  'world',\n",
       "  'mentality',\n",
       "  'not',\n",
       "  'feeling',\n",
       "  'the',\n",
       "  'love',\n",
       "  'rip',\n",
       "  'consolidation',\n",
       "  'have',\n",
       "  'ended',\n",
       "  'lower'],\n",
       " ['patience', 'scaling', 'in', 'btd', 'str'],\n",
       " ['more', 'trump', 'lie'],\n",
       " ['june',\n",
       "  'macau',\n",
       "  'ggr',\n",
       "  'up',\n",
       "  'despite',\n",
       "  'world',\n",
       "  'cup',\n",
       "  'great',\n",
       "  'number',\n",
       "  'imo',\n",
       "  'amp',\n",
       "  'world',\n",
       "  'cup',\n",
       "  'were',\n",
       "  'terribly',\n",
       "  'deep',\n",
       "  'negative',\n",
       "  'bullish',\n",
       "  'force',\n",
       "  'say'],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " ['percent', 'short', 'volume', 'for', 'wa', 'on'],\n",
       " ['in',\n",
       "  'term',\n",
       "  'of',\n",
       "  'negative',\n",
       "  'for',\n",
       "  'there',\n",
       "  'are',\n",
       "  'bearish',\n",
       "  'indicator',\n",
       "  'a',\n",
       "  'of'],\n",
       " ['already',\n",
       "  'for',\n",
       "  'and',\n",
       "  'for',\n",
       "  'from',\n",
       "  'it',\n",
       "  'high',\n",
       "  'healthy',\n",
       "  'to',\n",
       "  'begin',\n",
       "  'opening',\n",
       "  'position',\n",
       "  'fear',\n",
       "  'is',\n",
       "  'your',\n",
       "  'friend'],\n",
       " ['releasing',\n",
       "  'earnings',\n",
       "  'on',\n",
       "  'before',\n",
       "  'open',\n",
       "  'confirmed',\n",
       "  'anybody',\n",
       "  'buying',\n",
       "  'selling',\n",
       "  'in',\n",
       "  'earnings'],\n",
       " ['for', 'people', 'who', 'can', 'read', 'there', 'is', 'this'],\n",
       " ['how', 'trump', 'moved', 'stock'],\n",
       " [],\n",
       " ['what', 'shame', 'delisted'],\n",
       " ['got', 'it', 'will', 'rule', 'the', 'world'],\n",
       " ['short', 'ratio', 'of', 'is', 'at', 'and', 'short', 'to', 'float', 'is'],\n",
       " ['hiring',\n",
       "  'seasonal',\n",
       "  'worker',\n",
       "  'for',\n",
       "  'the',\n",
       "  'back',\n",
       "  'to',\n",
       "  'school',\n",
       "  'rush'],\n",
       " ['thought'],\n",
       " ['leave',\n",
       "  'for',\n",
       "  'vega',\n",
       "  'on',\n",
       "  'august',\n",
       "  'th',\n",
       "  'know',\n",
       "  'micron',\n",
       "  'will',\n",
       "  'be',\n",
       "  'providing',\n",
       "  'me',\n",
       "  'with',\n",
       "  'for',\n",
       "  'that',\n",
       "  'day',\n",
       "  'good',\n",
       "  'day'],\n",
       " ['this', 'week', 'research', 'report', 'at'],\n",
       " ['video', 'best', 'stock', 'chart'],\n",
       " ['max', 'pain', 'maturity', 'maxpain', 'option'],\n",
       " ['what', 'next', 'for'],\n",
       " ['libya', 'army', 'haftar', 'this', 'will', 'be', 'mess', 'for', 'while'],\n",
       " ['the', 'context', 'is', 'in', 'the', 'codename', 'via'],\n",
       " ['we',\n",
       "  'have',\n",
       "  'detected',\n",
       "  'negative',\n",
       "  'indicator',\n",
       "  'a',\n",
       "  'of',\n",
       "  'for',\n",
       "  'more',\n",
       "  'info',\n",
       "  'at'],\n",
       " ['short',\n",
       "  'interest',\n",
       "  'ratio',\n",
       "  'is',\n",
       "  'on',\n",
       "  'and',\n",
       "  'short',\n",
       "  'to',\n",
       "  'float',\n",
       "  'is'],\n",
       " [],\n",
       " ['take', 'step', 'back', 'just', 'the', 'beginning'],\n",
       " ['pain',\n",
       "  'alert',\n",
       "  'bearish',\n",
       "  'investor',\n",
       "  'have',\n",
       "  'given',\n",
       "  'back',\n",
       "  'in',\n",
       "  'on',\n",
       "  'per',\n",
       "  'iex'],\n",
       " ['wsj',\n",
       "  'auto',\n",
       "  'maker',\n",
       "  'in',\n",
       "  'the',\n",
       "  'including',\n",
       "  'tesla',\n",
       "  'and',\n",
       "  'ford',\n",
       "  'brace',\n",
       "  'for',\n",
       "  'additional',\n",
       "  'tariff',\n",
       "  'from',\n",
       "  'china',\n",
       "  'an',\n",
       "  'extra',\n",
       "  'tariff',\n",
       "  'on',\n",
       "  'auto',\n",
       "  'import'],\n",
       " [],\n",
       " ['midterm',\n",
       "  'election',\n",
       "  'are',\n",
       "  'black',\n",
       "  'cloud',\n",
       "  'hanging',\n",
       "  'over',\n",
       "  'the',\n",
       "  'dow',\n",
       "  'head'],\n",
       " ['bull',\n",
       "  'better',\n",
       "  'hope',\n",
       "  'history',\n",
       "  'dont',\n",
       "  'repeat',\n",
       "  'sure',\n",
       "  'looking',\n",
       "  'like',\n",
       "  'bearish',\n",
       "  'reversal',\n",
       "  'redux',\n",
       "  'huge',\n",
       "  'monthly',\n",
       "  'candle'],\n",
       " ['began',\n",
       "  'buying',\n",
       "  'at',\n",
       "  'added',\n",
       "  'multiple',\n",
       "  'time',\n",
       "  'average',\n",
       "  'sold',\n",
       "  'at',\n",
       "  'in',\n",
       "  'chunk',\n",
       "  'will',\n",
       "  'begin',\n",
       "  'buying',\n",
       "  'below',\n",
       "  'again'],\n",
       " ['now',\n",
       "  'that',\n",
       "  'macau',\n",
       "  'gaming',\n",
       "  'revenue',\n",
       "  'for',\n",
       "  'june',\n",
       "  'is',\n",
       "  'released',\n",
       "  'do',\n",
       "  'you',\n",
       "  'see',\n",
       "  'upside',\n",
       "  'or',\n",
       "  'downside',\n",
       "  'for'],\n",
       " ['is',\n",
       "  'currently',\n",
       "  'trading',\n",
       "  'in',\n",
       "  'the',\n",
       "  'upper',\n",
       "  'part',\n",
       "  'of',\n",
       "  'it',\n",
       "  'week',\n",
       "  'range',\n",
       "  'outperforming',\n",
       "  'the',\n",
       "  'market'],\n",
       " ['how', 'about', 'that', 'price', 'action'],\n",
       " ['aggregate',\n",
       "  'short',\n",
       "  'volume',\n",
       "  'reported',\n",
       "  'to',\n",
       "  'finra',\n",
       "  'for',\n",
       "  'wa',\n",
       "  'on'],\n",
       " ['the',\n",
       "  'only',\n",
       "  'positive',\n",
       "  'tom',\n",
       "  'is',\n",
       "  'that',\n",
       "  'it',\n",
       "  'is',\n",
       "  'new',\n",
       "  'quarter',\n",
       "  'beginning'],\n",
       " ['bull',\n",
       "  'failed',\n",
       "  'reversal',\n",
       "  'amp',\n",
       "  'bearish',\n",
       "  'signal',\n",
       "  'dyor',\n",
       "  'if',\n",
       "  'you',\n",
       "  'continue',\n",
       "  'to',\n",
       "  'buy',\n",
       "  'weakness'],\n",
       " ['july', 'look', 'hot'],\n",
       " ['since',\n",
       "  'last',\n",
       "  'er',\n",
       "  'stock',\n",
       "  'dropped',\n",
       "  'reporting',\n",
       "  'earnings',\n",
       "  'on',\n",
       "  'before',\n",
       "  'open',\n",
       "  'confirmed'],\n",
       " ['bear', 'have', 'reason', 'on', 'to', 'pay', 'more', 'attention'],\n",
       " ['jeana',\n",
       "  'thanks',\n",
       "  'for',\n",
       "  'posting',\n",
       "  'tariff',\n",
       "  'combined',\n",
       "  'with',\n",
       "  'retaliation',\n",
       "  'from',\n",
       "  'angry',\n",
       "  'trading',\n",
       "  'partner',\n",
       "  'may',\n",
       "  'end',\n",
       "  'up',\n",
       "  'causing',\n",
       "  'more',\n",
       "  'harm',\n",
       "  'than',\n",
       "  'good'],\n",
       " ['nflx', 'nflx'],\n",
       " ['the',\n",
       "  'apple',\n",
       "  'ipad',\n",
       "  'is',\n",
       "  'killer',\n",
       "  'gaming',\n",
       "  'tablet',\n",
       "  'is',\n",
       "  'up',\n",
       "  'since',\n",
       "  'this',\n",
       "  'bullish',\n",
       "  'forecast'],\n",
       " ['an',\n",
       "  'estimate',\n",
       "  'from',\n",
       "  'trade',\n",
       "  'partnership',\n",
       "  'forecast',\n",
       "  'about',\n",
       "  'job',\n",
       "  'lost',\n",
       "  'versus',\n",
       "  'created',\n",
       "  'a',\n",
       "  'result',\n",
       "  'of',\n",
       "  'the',\n",
       "  'metal',\n",
       "  'tariff'],\n",
       " ['is',\n",
       "  'currently',\n",
       "  'showing',\n",
       "  'bull',\n",
       "  'flag',\n",
       "  'pattern',\n",
       "  'bull',\n",
       "  'flag',\n",
       "  'pattern',\n",
       "  'is',\n",
       "  'pull',\n",
       "  'back',\n",
       "  'after',\n",
       "  'strong',\n",
       "  'rise',\n",
       "  'up'],\n",
       " ['even',\n",
       "  'during',\n",
       "  'recession',\n",
       "  'people',\n",
       "  'will',\n",
       "  'sit',\n",
       "  'on',\n",
       "  'their',\n",
       "  'as',\n",
       "  'and',\n",
       "  'play',\n",
       "  'video',\n",
       "  'game',\n",
       "  'lol'],\n",
       " ['warns',\n",
       "  'of',\n",
       "  'trade',\n",
       "  'shrinkage',\n",
       "  'vulnerable',\n",
       "  'quot',\n",
       "  'bearish',\n",
       "  'engulfed',\n",
       "  'quot',\n",
       "  'begun'],\n",
       " ['ish',\n",
       "  'better',\n",
       "  'priced',\n",
       "  'than',\n",
       "  'the',\n",
       "  'other',\n",
       "  'fang',\n",
       "  'stock',\n",
       "  'amzn',\n",
       "  'is',\n",
       "  'insanity'],\n",
       " ['hi',\n",
       "  'wa',\n",
       "  'wondering',\n",
       "  'what',\n",
       "  'your',\n",
       "  'thought',\n",
       "  'are',\n",
       "  'on',\n",
       "  'look',\n",
       "  'ripe',\n",
       "  'for',\n",
       "  'pop',\n",
       "  'to',\n",
       "  'me'],\n",
       " [],\n",
       " ['so',\n",
       "  'on',\n",
       "  'wednesday',\n",
       "  'ah',\n",
       "  'we',\n",
       "  'saw',\n",
       "  'this',\n",
       "  'and',\n",
       "  'we',\n",
       "  'got',\n",
       "  'the',\n",
       "  'pop',\n",
       "  'friday',\n",
       "  'do',\n",
       "  'we',\n",
       "  'see',\n",
       "  'friday',\n",
       "  'ah',\n",
       "  'print',\n",
       "  'early',\n",
       "  'next',\n",
       "  'week'],\n",
       " [],\n",
       " ['short', 'volume', 'reported', 'to', 'finra', 'on', 'on'],\n",
       " ['today', 'insight', 'on'],\n",
       " ['we',\n",
       "  'have',\n",
       "  'detected',\n",
       "  'positive',\n",
       "  'indicator',\n",
       "  'a',\n",
       "  'of',\n",
       "  'for',\n",
       "  'more',\n",
       "  'info',\n",
       "  'at'],\n",
       " ['starting',\n",
       "  'to',\n",
       "  'get',\n",
       "  'some',\n",
       "  'momentum',\n",
       "  'if',\n",
       "  'it',\n",
       "  'pick',\n",
       "  'up',\n",
       "  'below',\n",
       "  'favor',\n",
       "  'it',\n",
       "  'see',\n",
       "  'strong',\n",
       "  'breakdown',\n",
       "  'towards',\n",
       "  'the',\n",
       "  'measured',\n",
       "  'move',\n",
       "  'target',\n",
       "  'at',\n",
       "  'ish'],\n",
       " ['recent',\n",
       "  'technical',\n",
       "  'alert',\n",
       "  'jack',\n",
       "  'in',\n",
       "  'the',\n",
       "  'box',\n",
       "  'bearish',\n",
       "  'plus',\n",
       "  'more',\n",
       "  'alert'],\n",
       " ['max', 'pain', 'maturity', 'maxpain', 'option'],\n",
       " ['lot',\n",
       "  'of',\n",
       "  'ta',\n",
       "  'short',\n",
       "  'in',\n",
       "  'financials',\n",
       "  'right',\n",
       "  'now',\n",
       "  'but',\n",
       "  'let',\n",
       "  'ask',\n",
       "  'the',\n",
       "  'guy',\n",
       "  'who',\n",
       "  'made',\n",
       "  'the',\n",
       "  'most',\n",
       "  'in',\n",
       "  'bank',\n",
       "  'how',\n",
       "  'he',\n",
       "  'us',\n",
       "  'chart'],\n",
       " ['no',\n",
       "  'chance',\n",
       "  'get',\n",
       "  'approval',\n",
       "  'before',\n",
       "  'this',\n",
       "  'play',\n",
       "  'out',\n",
       "  'took',\n",
       "  'six',\n",
       "  'month',\n",
       "  'and',\n",
       "  'that',\n",
       "  'wa',\n",
       "  'clearly',\n",
       "  'fast',\n",
       "  'tracked',\n",
       "  'for',\n",
       "  'rupert'],\n",
       " ['cool',\n",
       "  'world',\n",
       "  'cup',\n",
       "  'experience',\n",
       "  'world',\n",
       "  'cup',\n",
       "  'in',\n",
       "  'virtual',\n",
       "  'reality',\n",
       "  'bbc',\n",
       "  'sport'],\n",
       " ['july', 'stock', 'picking', 'contest', 'is', 'now', 'open'],\n",
       " ['barron',\n",
       "  'pick',\n",
       "  'and',\n",
       "  'pan',\n",
       "  'apple',\n",
       "  'mastercard',\n",
       "  'sirius',\n",
       "  'xm',\n",
       "  'verizon',\n",
       "  'and',\n",
       "  'more'],\n",
       " ['specialize', 'in', 'er', 'game', 'on', 'or', 'low'],\n",
       " ['thomas',\n",
       "  'read',\n",
       "  'on',\n",
       "  'couple',\n",
       "  'brokerage',\n",
       "  'report',\n",
       "  'pt',\n",
       "  'are',\n",
       "  'value',\n",
       "  'forward',\n",
       "  'pe',\n",
       "  'prem',\n",
       "  'above',\n",
       "  'avg',\n",
       "  'for',\n",
       "  'semi',\n",
       "  'overpriced'],\n",
       " ['what',\n",
       "  'the',\n",
       "  'damn',\n",
       "  'third',\n",
       "  'design',\n",
       "  'win',\n",
       "  'that',\n",
       "  'supposed',\n",
       "  'to',\n",
       "  'be',\n",
       "  'ramping',\n",
       "  'nd',\n",
       "  'half',\n",
       "  'who',\n",
       "  'making',\n",
       "  'odds',\n",
       "  'on',\n",
       "  'customer',\n",
       "  've',\n",
       "  'got',\n",
       "  'on',\n",
       "  'apple'],\n",
       " ['apple',\n",
       "  'other',\n",
       "  'product',\n",
       "  'expanding',\n",
       "  'airpods',\n",
       "  'could',\n",
       "  'hit',\n",
       "  'of',\n",
       "  'iphone',\n",
       "  'unit',\n",
       "  'sale',\n",
       "  'rbc'],\n",
       " ['careful',\n",
       "  'where',\n",
       "  'you',\n",
       "  'get',\n",
       "  'your',\n",
       "  'news',\n",
       "  'this',\n",
       "  'system',\n",
       "  'doesn',\n",
       "  'exist'],\n",
       " ['bank',\n",
       "  'of',\n",
       "  'america',\n",
       "  'to',\n",
       "  'increase',\n",
       "  'quarterly',\n",
       "  'common',\n",
       "  'stock',\n",
       "  'dividend',\n",
       "  'to',\n",
       "  'and',\n",
       "  'repurchase',\n",
       "  'up',\n",
       "  'to',\n",
       "  'billion'],\n",
       " ['dataprotection'],\n",
       " ['mizuho', 'security', 'upgrade', 'scana', 'corp', 'to', 'buy'],\n",
       " ['netapp',\n",
       "  'pt',\n",
       "  'raised',\n",
       "  'to',\n",
       "  'at',\n",
       "  'bofa',\n",
       "  'merrill',\n",
       "  'lynch',\n",
       "  'to',\n",
       "  'benefit',\n",
       "  'from',\n",
       "  'ai'],\n",
       " ['manipulation'],\n",
       " ['it', 'undervalue', 'but', 'will', 'go', 'lower'],\n",
       " ['video',\n",
       "  'game',\n",
       "  'stock',\n",
       "  'seen',\n",
       "  'a',\n",
       "  'potential',\n",
       "  'medium',\n",
       "  'company',\n",
       "  'acquisition',\n",
       "  'target'],\n",
       " ['got',\n",
       "  'pullback',\n",
       "  'if',\n",
       "  'the',\n",
       "  'bull',\n",
       "  'want',\n",
       "  'new',\n",
       "  'high',\n",
       "  'here',\n",
       "  'is',\n",
       "  'where',\n",
       "  'you',\n",
       "  'need',\n",
       "  'to',\n",
       "  'step',\n",
       "  'get',\n",
       "  'it',\n",
       "  'above',\n",
       "  'to',\n",
       "  'suggest',\n",
       "  'new',\n",
       "  'high',\n",
       "  'for',\n",
       "  'wave'],\n",
       " ['folk',\n",
       "  'it',\n",
       "  'sunday',\n",
       "  'go',\n",
       "  'to',\n",
       "  'church',\n",
       "  'volunteer',\n",
       "  'get',\n",
       "  'outside',\n",
       "  'go',\n",
       "  'talk',\n",
       "  'to',\n",
       "  'friend',\n",
       "  'or',\n",
       "  'make',\n",
       "  'new',\n",
       "  'one',\n",
       "  'let',\n",
       "  'this',\n",
       "  'go',\n",
       "  'till',\n",
       "  'monday',\n",
       "  'glta'],\n",
       " ['my', 'top', 'growth', 'stock', 'for', 'the', 'next', 'decade'],\n",
       " ['credit', 'suisse', 'set', 'pt', 'at'],\n",
       " ['soccer',\n",
       "  'season',\n",
       "  'with',\n",
       "  'up',\n",
       "  'would',\n",
       "  'say',\n",
       "  'it',\n",
       "  'beat',\n",
       "  'and',\n",
       "  'huge',\n",
       "  'upside',\n",
       "  'from',\n",
       "  'here'],\n",
       " ['why',\n",
       "  'cv',\n",
       "  'may',\n",
       "  'be',\n",
       "  'le',\n",
       "  'vulnerable',\n",
       "  'to',\n",
       "  'amazon',\n",
       "  'healthcare',\n",
       "  'attack',\n",
       "  'than',\n",
       "  'walgreens'],\n",
       " ['credit', 'suisse', 'set', 'pt', 'at'],\n",
       " ['credit', 'suisse', 'set', 'pt', 'at'],\n",
       " ['cantor', 'fitzgerald', 'set', 'pt', 'at'],\n",
       " ['stephen', 'set', 'pt', 'at'],\n",
       " ['pivotal', 'research', 'set', 'pt', 'at'],\n",
       " ['mkm', 'partner', 'set', 'pt', 'at'],\n",
       " ['option',\n",
       "  'volume',\n",
       "  'wa',\n",
       "  'normal',\n",
       "  'on',\n",
       "  'friday',\n",
       "  'with',\n",
       "  'contract',\n",
       "  'call',\n",
       "  'volume',\n",
       "  'wa',\n",
       "  'and',\n",
       "  'put',\n",
       "  'volume',\n",
       "  'wa'],\n",
       " ['mizuho', 'security', 'set', 'pt', 'at'],\n",
       " ['top',\n",
       "  'stock',\n",
       "  'to',\n",
       "  'buy',\n",
       "  'ahead',\n",
       "  'of',\n",
       "  'the',\n",
       "  'most',\n",
       "  'bullish',\n",
       "  'day',\n",
       "  'of',\n",
       "  'the',\n",
       "  'year'],\n",
       " ['doubting', 'nvidia', 'future', 'is', 'dumb'],\n",
       " ['short',\n",
       "  'volume',\n",
       "  'percent',\n",
       "  'for',\n",
       "  'wa',\n",
       "  'on',\n",
       "  'and',\n",
       "  'day',\n",
       "  'rank',\n",
       "  'wa',\n",
       "  'th',\n",
       "  'percentile'],\n",
       " ['facebook',\n",
       "  'snapchat',\n",
       "  'story',\n",
       "  'clone',\n",
       "  'are',\n",
       "  'mostly',\n",
       "  'untapped',\n",
       "  'gold',\n",
       "  'mine'],\n",
       " ['this', 'crap', 'can', 'reach', 'again'],\n",
       " ['gm',\n",
       "  'say',\n",
       "  'import',\n",
       "  'tariff',\n",
       "  'could',\n",
       "  'lead',\n",
       "  'to',\n",
       "  'smaller',\n",
       "  'company',\n",
       "  'fewer',\n",
       "  'job'],\n",
       " ['ha', 'netflix', 'finally', 'peaked'],\n",
       " ['lead', 'ad', 'on', 'costco', 'com', 'under', 'computer', 'back', 'school'],\n",
       " ['the',\n",
       "  'long',\n",
       "  'and',\n",
       "  'short',\n",
       "  'term',\n",
       "  'trend',\n",
       "  'are',\n",
       "  'both',\n",
       "  'positive',\n",
       "  'this',\n",
       "  'is',\n",
       "  'looking',\n",
       "  'good'],\n",
       " ['we',\n",
       "  'all',\n",
       "  'know',\n",
       "  'it',\n",
       "  'will',\n",
       "  'go',\n",
       "  'back',\n",
       "  'up',\n",
       "  'to',\n",
       "  'in',\n",
       "  'coming',\n",
       "  'day',\n",
       "  'this',\n",
       "  'chat',\n",
       "  'room',\n",
       "  'is',\n",
       "  'waste',\n",
       "  'of',\n",
       "  'time'],\n",
       " ['vertex',\n",
       "  'pharma',\n",
       "  'jump',\n",
       "  'after',\n",
       "  'rival',\n",
       "  'release',\n",
       "  'poor',\n",
       "  'cystic',\n",
       "  'fibrosis',\n",
       "  'drug',\n",
       "  'result'],\n",
       " ['world',\n",
       "  'cup',\n",
       "  'drag',\n",
       "  'june',\n",
       "  'ggr',\n",
       "  'from',\n",
       "  'may',\n",
       "  'june',\n",
       "  'from',\n",
       "  'may',\n",
       "  'this',\n",
       "  'year',\n",
       "  'without',\n",
       "  'wc',\n",
       "  'effect',\n",
       "  'ggr',\n",
       "  'would',\n",
       "  've',\n",
       "  'been',\n",
       "  'yoy'],\n",
       " ['all',\n",
       "  'eye',\n",
       "  'will',\n",
       "  'be',\n",
       "  'on',\n",
       "  'oil',\n",
       "  'when',\n",
       "  'the',\n",
       "  'market',\n",
       "  'open',\n",
       "  'for',\n",
       "  'the',\n",
       "  'week',\n",
       "  'after',\n",
       "  'trump',\n",
       "  'tweet',\n",
       "  'forex',\n",
       "  'live'],\n",
       " ['amazon', 'latest', 'disruption', 'prime', 'rx', 'delivery'],\n",
       " ['percent', 'short', 'volume', 'for', 'wa', 'on'],\n",
       " ['we',\n",
       "  'have',\n",
       "  'detected',\n",
       "  'negative',\n",
       "  'indicator',\n",
       "  'a',\n",
       "  'of',\n",
       "  'for',\n",
       "  'more',\n",
       "  'info',\n",
       "  'at'],\n",
       " ['how',\n",
       "  'visa',\n",
       "  'and',\n",
       "  'mastercard',\n",
       "  'could',\n",
       "  'benefit',\n",
       "  'from',\n",
       "  'settlement',\n",
       "  'over',\n",
       "  'card',\n",
       "  'swipe',\n",
       "  'fee'],\n",
       " [],\n",
       " ['watchlist'],\n",
       " ['price',\n",
       "  'have',\n",
       "  'been',\n",
       "  'consolidating',\n",
       "  'recently',\n",
       "  'this',\n",
       "  'may',\n",
       "  'present',\n",
       "  'good',\n",
       "  'entry',\n",
       "  'opportunity'],\n",
       " ['maria',\n",
       "  'bartiromo',\n",
       "  'ha',\n",
       "  'always',\n",
       "  'been',\n",
       "  'shill',\n",
       "  'never',\n",
       "  'forget',\n",
       "  'amp',\n",
       "  'her',\n",
       "  'defending',\n",
       "  'lehman',\n",
       "  'disgusting'],\n",
       " ['cruise',\n",
       "  'line',\n",
       "  'stock',\n",
       "  'to',\n",
       "  'buy',\n",
       "  'royal',\n",
       "  'caribbean',\n",
       "  'carnival',\n",
       "  'or',\n",
       "  'norwegian'],\n",
       " ['long',\n",
       "  'term',\n",
       "  'estimate',\n",
       "  'per',\n",
       "  'barrel',\n",
       "  'crude',\n",
       "  'could',\n",
       "  'be',\n",
       "  'in',\n",
       "  'the',\n",
       "  'card',\n",
       "  'rbc',\n",
       "  'helima',\n",
       "  'croft'],\n",
       " ['the',\n",
       "  'long',\n",
       "  'and',\n",
       "  'short',\n",
       "  'term',\n",
       "  'trend',\n",
       "  'are',\n",
       "  'both',\n",
       "  'positive',\n",
       "  'this',\n",
       "  'is',\n",
       "  'looking',\n",
       "  'good'],\n",
       " ['releasing',\n",
       "  'earnings',\n",
       "  'on',\n",
       "  'before',\n",
       "  'open',\n",
       "  'confirmed',\n",
       "  'anybody',\n",
       "  'buying',\n",
       "  'selling',\n",
       "  'in',\n",
       "  'earnings'],\n",
       " ['ba', 'ba'],\n",
       " ['not', 'at', 'all', 'afraid', 'to', 'hold', 'my', 'short', 'in', 'bank'],\n",
       " ['retaliation',\n",
       "  'for',\n",
       "  'u',\n",
       "  'tariff',\n",
       "  'on',\n",
       "  'sun',\n",
       "  'canada',\n",
       "  'on',\n",
       "  'july',\n",
       "  'china',\n",
       "  'expected',\n",
       "  'to',\n",
       "  'impose',\n",
       "  'tariff',\n",
       "  'on',\n",
       "  'u',\n",
       "  'soybean',\n",
       "  'cnbc'],\n",
       " ['short', 'ratio', 'of', 'is', 'at', 'and', 'short', 'to', 'float', 'is'],\n",
       " ['wonder', 'how', 'many', 'matebook', 'are', 'selling'],\n",
       " ['bac', 'bac'],\n",
       " ['good', 'plan', 'right', 'here', 'close', 'to', 'mine'],\n",
       " ['very', 'optimistic', 'melikey'],\n",
       " ['high',\n",
       "  'oi',\n",
       "  'range',\n",
       "  'is',\n",
       "  'to',\n",
       "  'for',\n",
       "  'option',\n",
       "  'expiration',\n",
       "  'maxpain',\n",
       "  'option'],\n",
       " ['oversold', 'with', 'sign', 'of', 'possible', 'reversal'],\n",
       " ['would',\n",
       "  'not',\n",
       "  'want',\n",
       "  'to',\n",
       "  'be',\n",
       "  'in',\n",
       "  'this',\n",
       "  'for',\n",
       "  'the',\n",
       "  'next',\n",
       "  'er'],\n",
       " ['don', 'tell', 'me', 'you', 'are', 'still', 'holding'],\n",
       " ['ok',\n",
       "  'you',\n",
       "  'keep',\n",
       "  'telling',\n",
       "  'telling',\n",
       "  'yourself',\n",
       "  'that',\n",
       "  'he',\n",
       "  'bked',\n",
       "  'casino',\n",
       "  'casino',\n",
       "  'now',\n",
       "  'is',\n",
       "  'and',\n",
       "  'soon'],\n",
       " ['this',\n",
       "  'is',\n",
       "  'the',\n",
       "  'only',\n",
       "  'table',\n",
       "  'service',\n",
       "  'can',\n",
       "  'afford',\n",
       "  'right',\n",
       "  'now',\n",
       "  'can',\n",
       "  'even',\n",
       "  'afford',\n",
       "  'the',\n",
       "  'mcdouble',\n",
       "  'anymore',\n",
       "  'after',\n",
       "  'the',\n",
       "  'price',\n",
       "  'hike'],\n",
       " ['can',\n",
       "  'someone',\n",
       "  'explain',\n",
       "  'what',\n",
       "  'happens',\n",
       "  'with',\n",
       "  'the',\n",
       "  'div',\n",
       "  'payout',\n",
       "  'if',\n",
       "  'buy',\n",
       "  'in',\n",
       "  'here'],\n",
       " ['economy',\n",
       "  'that',\n",
       "  'time',\n",
       "  'sending',\n",
       "  'job',\n",
       "  'overseas',\n",
       "  'after',\n",
       "  'supporting',\n",
       "  'them',\n",
       "  'gut',\n",
       "  'of',\n",
       "  'trump',\n",
       "  'calling',\n",
       "  'them',\n",
       "  'out'],\n",
       " ['yeah', 'sleep', 'with', 'elon', 'musk'],\n",
       " ['compared',\n",
       "  'to',\n",
       "  'an',\n",
       "  'average',\n",
       "  'industry',\n",
       "  'price',\n",
       "  'book',\n",
       "  'ratio',\n",
       "  'of',\n",
       "  'is',\n",
       "  'valued',\n",
       "  'rather',\n",
       "  'cheaply'],\n",
       " ['since',\n",
       "  'last',\n",
       "  'er',\n",
       "  'stock',\n",
       "  'dropped',\n",
       "  'reporting',\n",
       "  'earnings',\n",
       "  'on',\n",
       "  'before',\n",
       "  'open',\n",
       "  'confirmed'],\n",
       " ['if',\n",
       "  'all',\n",
       "  'be',\n",
       "  'nice',\n",
       "  'to',\n",
       "  'me',\n",
       "  'can',\n",
       "  'give',\n",
       "  'you',\n",
       "  'an',\n",
       "  'accurate',\n",
       "  'direction',\n",
       "  'of',\n",
       "  'which',\n",
       "  'way',\n",
       "  'this',\n",
       "  'will',\n",
       "  'go'],\n",
       " ['below',\n",
       "  'all',\n",
       "  'sma',\n",
       "  'in',\n",
       "  'falling',\n",
       "  'wedge',\n",
       "  'bearish',\n",
       "  'until',\n",
       "  'breakout'],\n",
       " ['think',\n",
       "  'most',\n",
       "  'of',\n",
       "  'the',\n",
       "  'peep',\n",
       "  'on',\n",
       "  'here',\n",
       "  'have',\n",
       "  'blocked',\n",
       "  'bro',\n",
       "  'time',\n",
       "  'to',\n",
       "  'use',\n",
       "  'an',\n",
       "  'alternate',\n",
       "  'account',\n",
       "  'sr',\n",
       "  'are',\n",
       "  'taken'],\n",
       " ['you',\n",
       "  'bet',\n",
       "  'how',\n",
       "  'about',\n",
       "  'show',\n",
       "  'some',\n",
       "  'fact',\n",
       "  'sport',\n",
       "  'now',\n",
       "  'ha',\n",
       "  'control',\n",
       "  'of',\n",
       "  'nfl',\n",
       "  'mlb',\n",
       "  'march',\n",
       "  'madness',\n",
       "  'etc',\n",
       "  'roku',\n",
       "  'suck',\n",
       "  'donkey',\n",
       "  'dks'],\n",
       " ['alibaba', 'buy', 'stake', 'in', 'turkey', 'trendyol'],\n",
       " ['think',\n",
       "  'the',\n",
       "  'whole',\n",
       "  'dump',\n",
       "  'for',\n",
       "  'the',\n",
       "  'past',\n",
       "  'few',\n",
       "  'year',\n",
       "  'wa',\n",
       "  'absolutely',\n",
       "  'necessary',\n",
       "  'their',\n",
       "  'sht',\n",
       "  'wa',\n",
       "  'getting',\n",
       "  'way',\n",
       "  'too',\n",
       "  'expensive',\n",
       "  'they',\n",
       "  'can',\n",
       "  'grow',\n",
       "  'bter',\n",
       "  'now'],\n",
       " ['if', 'feel', 'good', 'to', 'be', 'right', 'with', 'this', 'stock'],\n",
       " ['remember',\n",
       "  'even',\n",
       "  'the',\n",
       "  'capital',\n",
       "  'investment',\n",
       "  'will',\n",
       "  'only',\n",
       "  'be',\n",
       "  'in',\n",
       "  'dividend',\n",
       "  'payout'],\n",
       " ['since',\n",
       "  'last',\n",
       "  'er',\n",
       "  'stock',\n",
       "  'dropped',\n",
       "  'reporting',\n",
       "  'earnings',\n",
       "  'on',\n",
       "  'before',\n",
       "  'open',\n",
       "  'confirmed'],\n",
       " ['whats',\n",
       "  'up',\n",
       "  'bro',\n",
       "  'you',\n",
       "  'still',\n",
       "  'trade',\n",
       "  'this',\n",
       "  'stock',\n",
       "  'or',\n",
       "  'did',\n",
       "  'you',\n",
       "  'give',\n",
       "  'up'],\n",
       " ['short', 'volume', 'percent', 'for', 'wa', 'on'],\n",
       " ['bull', 'have', 'reason', 'on', 'to', 'pay', 'more', 'attention'],\n",
       " ['talking',\n",
       "  'about',\n",
       "  'gravity',\n",
       "  'in',\n",
       "  'stock',\n",
       "  'market',\n",
       "  'is',\n",
       "  'fool',\n",
       "  'errond',\n",
       "  'take',\n",
       "  'look',\n",
       "  'at'],\n",
       " ['read',\n",
       "  'your',\n",
       "  'comment',\n",
       "  'on',\n",
       "  'on',\n",
       "  'seeking',\n",
       "  'alpha',\n",
       "  'you',\n",
       "  'know',\n",
       "  'lot',\n",
       "  'about',\n",
       "  'casino',\n",
       "  'stock',\n",
       "  'will',\n",
       "  'this',\n",
       "  'ggr',\n",
       "  'hurt',\n",
       "  'the',\n",
       "  'price',\n",
       "  'more',\n",
       "  'or',\n",
       "  'ok',\n",
       "  'here'],\n",
       " ['open', 'tomorrow'],\n",
       " ['is',\n",
       "  'more',\n",
       "  'then',\n",
       "  'enough',\n",
       "  'we',\n",
       "  'should',\n",
       "  'be',\n",
       "  'at',\n",
       "  'and',\n",
       "  'earning',\n",
       "  'are',\n",
       "  'coming',\n",
       "  'up'],\n",
       " ['should', 'be', 'loading', 'on', 'on', 'this', 'stock', 'here'],\n",
       " ['wall',\n",
       "  'street',\n",
       "  'is',\n",
       "  'full',\n",
       "  'of',\n",
       "  'idiot',\n",
       "  'who',\n",
       "  'gamble',\n",
       "  'until',\n",
       "  'they',\n",
       "  'lose'],\n",
       " ['hope',\n",
       "  'citibank',\n",
       "  'go',\n",
       "  'bankrupt',\n",
       "  'stealing',\n",
       "  'money',\n",
       "  'by',\n",
       "  'nickel',\n",
       "  'and',\n",
       "  'dimming',\n",
       "  'costumer',\n",
       "  'with',\n",
       "  'stupid',\n",
       "  'little',\n",
       "  'fee'],\n",
       " [],\n",
       " ['don',\n",
       "  'worry',\n",
       "  'scumbags',\n",
       "  'at',\n",
       "  'citibank',\n",
       "  'll',\n",
       "  'make',\n",
       "  'more',\n",
       "  'money',\n",
       "  'shorting',\n",
       "  'your',\n",
       "  'stock',\n",
       "  'to',\n",
       "  'the',\n",
       "  'ground',\n",
       "  'than',\n",
       "  'you',\n",
       "  'will',\n",
       "  'make',\n",
       "  'from',\n",
       "  'fee'],\n",
       " ['choppy',\n",
       "  'head',\n",
       "  'amp',\n",
       "  'shoulder',\n",
       "  'watch',\n",
       "  'for',\n",
       "  'the',\n",
       "  'breakdown',\n",
       "  'watch',\n",
       "  'for',\n",
       "  'the',\n",
       "  'breakdown'],\n",
       " ['releasing',\n",
       "  'earnings',\n",
       "  'on',\n",
       "  'before',\n",
       "  'open',\n",
       "  'confirmed',\n",
       "  'anybody',\n",
       "  'buying',\n",
       "  'selling',\n",
       "  'in',\n",
       "  'earnings'],\n",
       " [],\n",
       " ['it', 'is', 'now', 'time', 'for', 'the', 'trumpy', 'bear', 'market'],\n",
       " ['gravity',\n",
       "  'applies',\n",
       "  'to',\n",
       "  'overbot',\n",
       "  'condition',\n",
       "  'and',\n",
       "  'applied',\n",
       "  'to',\n",
       "  'in',\n",
       "  'past',\n",
       "  'a',\n",
       "  'well'],\n",
       " ['highlight', 'in', 'cancer', 'from', 'the', 'week'],\n",
       " ['jcp', 'jcpenney', 'ha', 'rev', 'per', 'employee', 'of'],\n",
       " ['vrsk',\n",
       "  'beta',\n",
       "  'of',\n",
       "  'veriskanalytics',\n",
       "  'is',\n",
       "  'making',\n",
       "  'it',\n",
       "  'le',\n",
       "  'volatile',\n",
       "  'than',\n",
       "  'the',\n",
       "  'market'],\n",
       " ['viavisolutions', 'dipped', 'by', 'in', 'the', 'last', 'year', 'viav'],\n",
       " ['it', 'gartner', 'ha', 'very', 'low', 'roce', 'of'],\n",
       " ['etn', 'the', 'rpe', 'revenue', 'per', 'employee', 'of', 'eatonplc', 'is'],\n",
       " ['rrdonnelleysons',\n",
       "  'is',\n",
       "  'oversold',\n",
       "  'according',\n",
       "  'to',\n",
       "  'it',\n",
       "  'stoch',\n",
       "  'rsi',\n",
       "  'of',\n",
       "  'rrd'],\n",
       " ['ba', 'the', 'payout', 'ratio', 'of', 'boeing', 'is'],\n",
       " ['releasing',\n",
       "  'earnings',\n",
       "  'on',\n",
       "  'before',\n",
       "  'open',\n",
       "  'confirmed',\n",
       "  'anybody',\n",
       "  'buying',\n",
       "  'selling',\n",
       "  'in',\n",
       "  'earnings'],\n",
       " ['psx', 'fcf', 'of', 'phillips', 'is'],\n",
       " ['citigroup', 'ha', 'recommendation', 'mean', 'of'],\n",
       " ['mco',\n",
       "  'sma',\n",
       "  'of',\n",
       "  'moody',\n",
       "  'is',\n",
       "  'now',\n",
       "  'down',\n",
       "  'by',\n",
       "  'and',\n",
       "  'sma',\n",
       "  'is',\n",
       "  'now',\n",
       "  'up',\n",
       "  'by'],\n",
       " ['fslr',\n",
       "  'the',\n",
       "  'percentage',\n",
       "  'price',\n",
       "  'oscillator',\n",
       "  'or',\n",
       "  'ppo',\n",
       "  'of',\n",
       "  'firstsolar',\n",
       "  'is'],\n",
       " ['aonplc',\n",
       "  'ha',\n",
       "  'beta',\n",
       "  'of',\n",
       "  'making',\n",
       "  'it',\n",
       "  'le',\n",
       "  'volatile',\n",
       "  'than',\n",
       "  'the',\n",
       "  'market',\n",
       "  'aon'],\n",
       " ['microsoft', 'ha', 'adx', 'of', 'hinting', 'it', 'weak', 'trend', 'msft'],\n",
       " ['apa',\n",
       "  'apache',\n",
       "  'ha',\n",
       "  'sma',\n",
       "  'of',\n",
       "  'now',\n",
       "  'up',\n",
       "  'by',\n",
       "  'and',\n",
       "  'sma',\n",
       "  'of',\n",
       "  'now',\n",
       "  'up',\n",
       "  'by'],\n",
       " ['yte', 'ha', 'ppo', 'of', 'incy'],\n",
       " ['jmsmucker', 'ha', 'recommendation', 'mean', 'of', 'sjm'],\n",
       " ['tel', 'teconnectivity', 'ha', 'ppo', 'of'],\n",
       " ['operating', 'margin', 'of', 'internationalbusinessmachines', 'is', 'ibm'],\n",
       " ['northerntrust', 'ha', 'recommendation', 'mean', 'of', 'ntrs'],\n",
       " ['bankofnewyorkmellon', 'ha', 'short', 'of', 'float', 'of', 'bk'],\n",
       " ['nowhere',\n",
       "  'to',\n",
       "  'go',\n",
       "  'but',\n",
       "  'up',\n",
       "  'focus',\n",
       "  'on',\n",
       "  'fundamental',\n",
       "  'epyc',\n",
       "  'v',\n",
       "  'xeon',\n",
       "  'tam',\n",
       "  'all',\n",
       "  'revenue',\n",
       "  'and',\n",
       "  'profit',\n",
       "  'coming',\n",
       "  'now',\n",
       "  'revenue',\n",
       "  'ramp',\n",
       "  'year',\n",
       "  'pt'],\n",
       " ['etfc', 'insider', 'ownership', 'of', 'etrade', 'is'],\n",
       " ['envisionhealthcare', 'ha', 'short', 'of', 'float', 'of', 'evhc'],\n",
       " ['baxterinternational',\n",
       "  'is',\n",
       "  'overbought',\n",
       "  'with',\n",
       "  'percentage',\n",
       "  'price',\n",
       "  'oscillator',\n",
       "  'or',\n",
       "  'ppo',\n",
       "  'of',\n",
       "  'bax'],\n",
       " ['profit', 'margin', 'of', 'att', 'is'],\n",
       " ['eogresources',\n",
       "  'is',\n",
       "  'more',\n",
       "  'volatile',\n",
       "  'than',\n",
       "  'the',\n",
       "  'market',\n",
       "  'with',\n",
       "  'beta',\n",
       "  'of',\n",
       "  'eog'],\n",
       " ['diamondoffshoredrilling',\n",
       "  'ha',\n",
       "  'adx',\n",
       "  'of',\n",
       "  'signifying',\n",
       "  'it',\n",
       "  'weak',\n",
       "  'trend',\n",
       "  'do'],\n",
       " ['the', 'dividend', 'yield', 'of', 'averydennison', 'is', 'avy'],\n",
       " ['southern',\n",
       "  'ha',\n",
       "  'very',\n",
       "  'high',\n",
       "  'return',\n",
       "  'on',\n",
       "  'capital',\n",
       "  'employed',\n",
       "  'of',\n",
       "  'so'],\n",
       " ['insider', 'ownership', 'of', 'davita', 'is', 'dva'],\n",
       " ['western',\n",
       "  'ma',\n",
       "  'berkshire',\n",
       "  'cty',\n",
       "  'today',\n",
       "  'already',\n",
       "  'deg',\n",
       "  'today',\n",
       "  'the',\n",
       "  'cool',\n",
       "  'end',\n",
       "  'of',\n",
       "  'the',\n",
       "  'state'],\n",
       " ['citizen', 'ha', 'stoch', 'of', 'making', 'it', 'oversold', 'cfg'],\n",
       " ['bear',\n",
       "  'have',\n",
       "  'lost',\n",
       "  'on',\n",
       "  'alone',\n",
       "  'in',\n",
       "  'according',\n",
       "  'to',\n",
       "  'iex',\n",
       "  'data'],\n",
       " ['cimarexco', 'ha', 'adx', 'of', 'signifying', 'it', 'weak', 'trend', 'xec'],\n",
       " ['all', 'allstate', 'ha', 'very', 'high', 'return', 'on', 'equity', 'of'],\n",
       " ['cxo', 'conchoresources', 'went', 'up', 'by', 'in', 'the', 'last', 'year'],\n",
       " ['compared',\n",
       "  'to',\n",
       "  'an',\n",
       "  'average',\n",
       "  'enterprise',\n",
       "  'value',\n",
       "  'to',\n",
       "  'ebitda',\n",
       "  'ratio',\n",
       "  'of',\n",
       "  'is',\n",
       "  'valued',\n",
       "  'rather',\n",
       "  'cheaply'],\n",
       " ['bull', 'have', 'reason', 'on', 'to', 'pay', 'more', 'attention'],\n",
       " ['qepresources',\n",
       "  'ha',\n",
       "  'very',\n",
       "  'high',\n",
       "  'revenue',\n",
       "  'per',\n",
       "  'employee',\n",
       "  'of',\n",
       "  'qep'],\n",
       " ['ans', 'fcf', 'of', 'ansys', 'is'],\n",
       " ['coty', 'the', 'recommendation', 'mean', 'of', 'coty', 'is'],\n",
       " ['mtd', 'profit', 'margin', 'of', 'mettler', 'toledointernational', 'is'],\n",
       " ['anyone', 'know', 'what', 'this', 'is', 'referring', 'to'],\n",
       " ['gross', 'margin', 'of', 'motorolasolutions', 'is', 'msi'],\n",
       " ['operating', 'margin', 'of', 'michaelkors', 'is', 'kor'],\n",
       " ['allegionplc',\n",
       "  'is',\n",
       "  'overbought',\n",
       "  'according',\n",
       "  'to',\n",
       "  'it',\n",
       "  'stochastic',\n",
       "  'rsi',\n",
       "  'indicator',\n",
       "  'of',\n",
       "  'alle'],\n",
       " ['nlsn',\n",
       "  'the',\n",
       "  'percentage',\n",
       "  'price',\n",
       "  'oscillator',\n",
       "  'or',\n",
       "  'ppo',\n",
       "  'of',\n",
       "  'nielsennv',\n",
       "  'is'],\n",
       " ['wpx', 'wpx', 'ha', 'rev', 'per', 'employee', 'of'],\n",
       " ['whr', 'whirlpool', 'ha', 'dividend', 'yield', 'of'],\n",
       " ['chrw', 'chrobinsonworldwide', 'ha', 'short', 'of', 'float', 'of'],\n",
       " ['the', 'recommendation', 'mean', 'of', 'wellsfargo', 'is', 'wfc'],\n",
       " ['ccl', 'carnival', 'ha', 'operating', 'margin', 'of'],\n",
       " ['short', 'sale', 'volume', 'not', 'short', 'interest', 'for', 'on', 'is'],\n",
       " ['sma',\n",
       "  'of',\n",
       "  'pepsico',\n",
       "  'is',\n",
       "  'now',\n",
       "  'up',\n",
       "  'by',\n",
       "  'and',\n",
       "  'sma',\n",
       "  'is',\n",
       "  'now',\n",
       "  'down',\n",
       "  'by',\n",
       "  'pep'],\n",
       " ['pfe', 'pfizer', 'ha', 'very', 'high', 'return', 'on', 'equity', 'of'],\n",
       " ['so',\n",
       "  'funny',\n",
       "  'how',\n",
       "  'bear',\n",
       "  'disappear',\n",
       "  'from',\n",
       "  'to',\n",
       "  'but',\n",
       "  'it',\n",
       "  'pull',\n",
       "  'back',\n",
       "  'to',\n",
       "  'and',\n",
       "  'the',\n",
       "  'sky',\n",
       "  'is',\n",
       "  'falling',\n",
       "  'lollll',\n",
       "  'the',\n",
       "  'nature',\n",
       "  'of',\n",
       "  'stock',\n",
       "  'is',\n",
       "  'up',\n",
       "  'and',\n",
       "  'down'],\n",
       " ['deltaairlines',\n",
       "  'ha',\n",
       "  'adx',\n",
       "  'of',\n",
       "  'signifying',\n",
       "  'it',\n",
       "  'weak',\n",
       "  'trend',\n",
       "  'dal'],\n",
       " ['adtalemglobaleducation', 'ha', 'operating', 'margin', 'of', 'atge'],\n",
       " ['bsx', 'bostonscientific', 'ha', 'institutional', 'ownership', 'of'],\n",
       " ['mck', 'mckesson', 'went', 'down', 'by', 'in', 'the', 'last', 'year'],\n",
       " ['pbct',\n",
       "  'peoplesunited',\n",
       "  'is',\n",
       "  'overbought',\n",
       "  'with',\n",
       "  'percentage',\n",
       "  'price',\n",
       "  'oscillator',\n",
       "  'or',\n",
       "  'ppo',\n",
       "  'of'],\n",
       " ['insider',\n",
       "  'ownership',\n",
       "  'of',\n",
       "  'vertexpharmaceuticalsorporated',\n",
       "  'is',\n",
       "  'vrtx'],\n",
       " ['bkng', 'volatility', 'of', 'booking', 'is'],\n",
       " ['dis', 'waltdisney', 'ha', 'ppo', 'of'],\n",
       " ['abbottlaboratories', 'ha', 'insider', 'ownership', 'of', 'abt'],\n",
       " ['arthurjgallagherco',\n",
       "  'ha',\n",
       "  'adx',\n",
       "  'of',\n",
       "  'signifying',\n",
       "  'it',\n",
       "  'strong',\n",
       "  'trend',\n",
       "  'ajg'],\n",
       " ['disca', 'discoverycommunications', 'ha', 'gross', 'margin', 'of'],\n",
       " ['lyondellbasellindustriesnv',\n",
       "  'ha',\n",
       "  'weak',\n",
       "  'trend',\n",
       "  'according',\n",
       "  'to',\n",
       "  'it',\n",
       "  'adx',\n",
       "  'of',\n",
       "  'lyb'],\n",
       " ['so',\n",
       "  'basically',\n",
       "  'the',\n",
       "  'vip',\n",
       "  'and',\n",
       "  'premium',\n",
       "  'mass',\n",
       "  'aren',\n",
       "  'spending',\n",
       "  'a',\n",
       "  'much',\n",
       "  'analyst',\n",
       "  'fooled',\n",
       "  'by',\n",
       "  'the',\n",
       "  'appearance',\n",
       "  'given',\n",
       "  'by',\n",
       "  'lower',\n",
       "  'quality',\n",
       "  'mass'],\n",
       " ['skyworkssolutions', 'ha', 'institutional', 'ownership', 'of', 'swks'],\n",
       " ['edisoninternational',\n",
       "  'ha',\n",
       "  'adx',\n",
       "  'of',\n",
       "  'signifying',\n",
       "  'it',\n",
       "  'weak',\n",
       "  'trend',\n",
       "  'eix'],\n",
       " ['wmb', 'williamscompanies', 'ha', 'volatility', 'of'],\n",
       " ['is',\n",
       "  'the',\n",
       "  'competition',\n",
       "  'profitable',\n",
       "  'yes',\n",
       "  'are',\n",
       "  'they',\n",
       "  'collaboration',\n",
       "  'with',\n",
       "  'waymo',\n",
       "  'yes',\n",
       "  'do',\n",
       "  'they',\n",
       "  'have',\n",
       "  'cash',\n",
       "  'yes'],\n",
       " ['releasing',\n",
       "  'earnings',\n",
       "  'on',\n",
       "  'before',\n",
       "  'open',\n",
       "  'confirmed',\n",
       "  'anybody',\n",
       "  'buying',\n",
       "  'selling',\n",
       "  'in',\n",
       "  'earnings'],\n",
       " ['kroger', 'ha', 'very', 'high', 'roce', 'of', 'kr'],\n",
       " ['pcar', 'institutional', 'ownership', 'of', 'paccar', 'is'],\n",
       " ['fcf', 'of', 'citrixsystems', 'is', 'ctxs'],\n",
       " ['profit', 'margin', 'of', 'verisign', 'is', 'vrsn'],\n",
       " ['honeywellinternational',\n",
       "  'ha',\n",
       "  'beta',\n",
       "  'of',\n",
       "  'making',\n",
       "  'it',\n",
       "  'more',\n",
       "  'volatile',\n",
       "  'than',\n",
       "  'the',\n",
       "  'market',\n",
       "  'hon'],\n",
       " ['the', 'dividend', 'yield', 'of', 'lincolnnational', 'is', 'lnc'],\n",
       " ['txn',\n",
       "  'texasinstrumentsorporated',\n",
       "  'ha',\n",
       "  'very',\n",
       "  'high',\n",
       "  'return',\n",
       "  'on',\n",
       "  'equity',\n",
       "  'of'],\n",
       " ['tdc', 'short', 'percent', 'of', 'float', 'of', 'teradata', 'is'],\n",
       " ['sma',\n",
       "  'of',\n",
       "  'smithao',\n",
       "  'is',\n",
       "  'now',\n",
       "  'down',\n",
       "  'by',\n",
       "  'and',\n",
       "  'sma',\n",
       "  'is',\n",
       "  'now',\n",
       "  'down',\n",
       "  'by',\n",
       "  'aos'],\n",
       " ['idexxlaboratories', 'ha', 'operating', 'margin', 'of', 'idxx'],\n",
       " ['bby', 'bestbuyco', 'ha', 'revenue', 'per', 'employee', 'of'],\n",
       " ['masco', 'ha', 'gross', 'margin', 'of', 'ma'],\n",
       " ['the', 'payout', 'ratio', 'of', 'nike', 'is', 'nke'],\n",
       " ['len', 'lennar', 'rose', 'by', 'in', 'the', 'last', 'month'],\n",
       " ['clf', 'the', 'roce', 'of', 'cliffsnaturalresources', 'is'],\n",
       " ['totalsystemservices',\n",
       "  'ha',\n",
       "  'very',\n",
       "  'high',\n",
       "  'return',\n",
       "  'on',\n",
       "  'equity',\n",
       "  'of',\n",
       "  'tss'],\n",
       " ['symantec', 'dipped', 'by', 'in', 'the', 'last', 'year', 'symc'],\n",
       " ['rrc', 'rangeresources', 'went', 'down', 'by', 'in', 'the', 'last', 'month'],\n",
       " ['nsc', 'norfolksouther', 'ha', 'revenue', 'per', 'employee', 'of'],\n",
       " ['the',\n",
       "  'return',\n",
       "  'on',\n",
       "  'capital',\n",
       "  'employed',\n",
       "  'of',\n",
       "  'accentureplc',\n",
       "  'is',\n",
       "  'acn'],\n",
       " ['willistowerswatsonpublic',\n",
       "  'is',\n",
       "  'le',\n",
       "  'volatile',\n",
       "  'than',\n",
       "  'the',\n",
       "  'market',\n",
       "  'with',\n",
       "  'beta',\n",
       "  'of',\n",
       "  'wltw'],\n",
       " ['genworth', 'ha', 'institutional', 'ownership', 'of', 'gnw'],\n",
       " ['martinmariettamaterials',\n",
       "  'ha',\n",
       "  'adx',\n",
       "  'of',\n",
       "  'signifying',\n",
       "  'it',\n",
       "  'strong',\n",
       "  'trend',\n",
       "  'mlm'],\n",
       " ['intc', 'operating', 'margin', 'of', 'intel', 'is'],\n",
       " ['operating', 'margin', 'of', 'affiliatedmanagers', 'is', 'amg'],\n",
       " ['spgi', 'spglobal', 'ha', 'volatility', 'of'],\n",
       " ['fbhs',\n",
       "  'beta',\n",
       "  'of',\n",
       "  'fortunebrandshomesecurity',\n",
       "  'is',\n",
       "  'making',\n",
       "  'it',\n",
       "  'more',\n",
       "  'volatile',\n",
       "  'than',\n",
       "  'the',\n",
       "  'market'],\n",
       " ['nwl', 'newellbrands', 'dipped', 'by', 'in', 'the', 'last', 'year'],\n",
       " ['coopercompanies', 'ha', 'operating', 'margin', 'of', 'coo'],\n",
       " ['brighthouse',\n",
       "  'is',\n",
       "  'oversold',\n",
       "  'according',\n",
       "  'to',\n",
       "  'it',\n",
       "  'stoch',\n",
       "  'rsi',\n",
       "  'of',\n",
       "  'bhf'],\n",
       " ['ebay', 'the', 'revenue', 'per', 'employee', 'of', 'ebay', 'is'],\n",
       " ['slg', 'operating', 'margin', 'of', 'slgreenrealty', 'is'],\n",
       " ['the', 'recommendation', 'mean', 'of', 'ppgindustries', 'is', 'ppg'],\n",
       " ['tegna', 'dipped', 'by', 'in', 'the', 'last', 'month', 'tgna'],\n",
       " ['dollargeneral', 'ha', 'gross', 'margin', 'of', 'dg'],\n",
       " ['beta',\n",
       "  'of',\n",
       "  'hess',\n",
       "  'make',\n",
       "  'more',\n",
       "  'volatile',\n",
       "  'than',\n",
       "  'the',\n",
       "  'market',\n",
       "  'he'],\n",
       " ['insider', 'ownership', 'of', 'vulcanmaterials', 'is', 'vmc'],\n",
       " ['jpm',\n",
       "  'of',\n",
       "  'floating',\n",
       "  'share',\n",
       "  'of',\n",
       "  'jpmorganchaseco',\n",
       "  'are',\n",
       "  'being',\n",
       "  'shorted'],\n",
       " ['beta',\n",
       "  'of',\n",
       "  'perrigo',\n",
       "  'is',\n",
       "  'making',\n",
       "  'it',\n",
       "  'le',\n",
       "  'volatile',\n",
       "  'than',\n",
       "  'the',\n",
       "  'market',\n",
       "  'prgo'],\n",
       " ['mmc',\n",
       "  'marshmclennancompanies',\n",
       "  'ha',\n",
       "  'very',\n",
       "  'high',\n",
       "  'return',\n",
       "  'on',\n",
       "  'equity',\n",
       "  'of'],\n",
       " ['tsn',\n",
       "  'tysonfoods',\n",
       "  'ha',\n",
       "  'price',\n",
       "  'to',\n",
       "  'free',\n",
       "  'cash',\n",
       "  'flow',\n",
       "  'ratio',\n",
       "  'of'],\n",
       " ['the',\n",
       "  'rpe',\n",
       "  'revenue',\n",
       "  'per',\n",
       "  'employee',\n",
       "  'of',\n",
       "  'intercontinentalexchange',\n",
       "  'is',\n",
       "  'ice'],\n",
       " ['bectondickinsonand',\n",
       "  'ha',\n",
       "  'adx',\n",
       "  'of',\n",
       "  'hinting',\n",
       "  'it',\n",
       "  'weak',\n",
       "  'trend',\n",
       "  'bdx'],\n",
       " ['the',\n",
       "  'percentage',\n",
       "  'price',\n",
       "  'oscillator',\n",
       "  'or',\n",
       "  'ppo',\n",
       "  'of',\n",
       "  'fluor',\n",
       "  'is',\n",
       "  'flr'],\n",
       " ['pdco',\n",
       "  'pattersoncompanies',\n",
       "  'ha',\n",
       "  'price',\n",
       "  'to',\n",
       "  'free',\n",
       "  'cash',\n",
       "  'flow',\n",
       "  'ratio',\n",
       "  'of'],\n",
       " ['footlocker', 'rose', 'by', 'in', 'the', 'last', 'year', 'fl'],\n",
       " ['we',\n",
       "  'have',\n",
       "  'detected',\n",
       "  'negative',\n",
       "  'indicator',\n",
       "  'a',\n",
       "  'of',\n",
       "  'for',\n",
       "  'more',\n",
       "  'info',\n",
       "  'at'],\n",
       " ['aph', 'amphenol', 'ha', 'fcf', 'of'],\n",
       " ...]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TODO Implement\n",
    "\n",
    "tokenized = [preprocess(m) for m in messages]\n",
    "tokenized"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bag of Words\n",
    "Now with all of our messages tokenized, we want to create a vocabulary and count up how often each word appears in our entire corpus. Use the [`Counter`](https://docs.python.org/3.1/library/collections.html#collections.Counter) function to count up all the tokens."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['great',\n",
       " 'buy',\n",
       " 'at',\n",
       " 'ill',\n",
       " 'wait',\n",
       " 'staanalystalert',\n",
       " 'for',\n",
       " 'jefferies',\n",
       " 'maintains',\n",
       " 'with',\n",
       " 'rating',\n",
       " 'of',\n",
       " 'hold',\n",
       " 'setting',\n",
       " 'target',\n",
       " 'price',\n",
       " 'at',\n",
       " 'usd',\n",
       " 'our',\n",
       " 'own',\n",
       " 'verdict',\n",
       " 'is',\n",
       " 'buy',\n",
       " 'heard',\n",
       " 'there',\n",
       " 'guy',\n",
       " 'who',\n",
       " 'know',\n",
       " 'someone',\n",
       " 'who',\n",
       " 'think',\n",
       " 'somebody',\n",
       " 'know',\n",
       " 'something',\n",
       " 'on',\n",
       " 'stocktwits',\n",
       " 'reveal',\n",
       " 'yourself',\n",
       " 'why',\n",
       " 'the',\n",
       " 'drop',\n",
       " 'warren',\n",
       " 'buffet',\n",
       " 'taking',\n",
       " 'out',\n",
       " 'his',\n",
       " 'position',\n",
       " 'bear',\n",
       " 'have',\n",
       " 'reason',\n",
       " 'on',\n",
       " 'to',\n",
       " 'pay',\n",
       " 'more',\n",
       " 'attention',\n",
       " 'ok',\n",
       " 'good',\n",
       " 'we',\n",
       " 're',\n",
       " 'not',\n",
       " 'dropping',\n",
       " 'in',\n",
       " 'price',\n",
       " 'over',\n",
       " 'the',\n",
       " 'weekend',\n",
       " 'lol',\n",
       " 'daily',\n",
       " 'chart',\n",
       " 'we',\n",
       " 'need',\n",
       " 'to',\n",
       " 'get',\n",
       " 'back',\n",
       " 'to',\n",
       " 'above',\n",
       " 'drop',\n",
       " 'per',\n",
       " 'week',\n",
       " 'after',\n",
       " 'spike',\n",
       " 'if',\n",
       " 'no',\n",
       " 'news',\n",
       " 'in',\n",
       " 'month',\n",
       " 'back',\n",
       " 'to',\n",
       " 'if',\n",
       " 'bo',\n",
       " 'then',\n",
       " 'bingo',\n",
       " 'what',\n",
       " 'is',\n",
       " 'the',\n",
       " 'odds',\n",
       " 'strong',\n",
       " 'buy',\n",
       " 'short',\n",
       " 'ratio',\n",
       " 'is',\n",
       " 'at',\n",
       " 'and',\n",
       " 'short',\n",
       " 'to',\n",
       " 'float',\n",
       " 'is',\n",
       " 'price',\n",
       " 'squeezing',\n",
       " 'perfect',\n",
       " 'place',\n",
       " 'for',\n",
       " 'an',\n",
       " 'option',\n",
       " 'straddle',\n",
       " 'near',\n",
       " 'the',\n",
       " 'supporting',\n",
       " 'trend',\n",
       " 'start',\n",
       " 'of',\n",
       " 'new',\n",
       " 'on',\n",
       " 'monday',\n",
       " 'expect',\n",
       " 'strong',\n",
       " 'buy',\n",
       " 'volume',\n",
       " 'across',\n",
       " 'key',\n",
       " 'company',\n",
       " 'of',\n",
       " 'various',\n",
       " 'sector',\n",
       " 'breakout',\n",
       " 'strategy',\n",
       " 'current',\n",
       " 'portfolio',\n",
       " 'bull',\n",
       " 'have',\n",
       " 'reason',\n",
       " 'on',\n",
       " 'to',\n",
       " 'pay',\n",
       " 'more',\n",
       " 'attention',\n",
       " 'catalyst',\n",
       " 'continuing',\n",
       " 'this',\n",
       " 'new',\n",
       " 'uptrend',\n",
       " 'pill',\n",
       " 'pack',\n",
       " 'buy',\n",
       " 'out',\n",
       " 'amazon',\n",
       " 'prime',\n",
       " 'day',\n",
       " 'earnings',\n",
       " 'test',\n",
       " 'break',\n",
       " 'of',\n",
       " 'soon',\n",
       " 'ha',\n",
       " 'moved',\n",
       " 'on',\n",
       " 'check',\n",
       " 'out',\n",
       " 'the',\n",
       " 'movement',\n",
       " 'and',\n",
       " 'peer',\n",
       " 'at',\n",
       " 'staanalystalert',\n",
       " 'for',\n",
       " 'mkm',\n",
       " 'partner',\n",
       " 'set',\n",
       " 'price',\n",
       " 'target',\n",
       " 'with',\n",
       " 'rating',\n",
       " 'of',\n",
       " 'buy',\n",
       " 'setting',\n",
       " 'target',\n",
       " 'price',\n",
       " 'at',\n",
       " 'usd',\n",
       " 'our',\n",
       " 'own',\n",
       " 'verdict',\n",
       " 'is',\n",
       " 'buy',\n",
       " 'think',\n",
       " 'it',\n",
       " 'is',\n",
       " 'too',\n",
       " 'early',\n",
       " 'to',\n",
       " 'tell',\n",
       " 'what',\n",
       " 'going',\n",
       " 'to',\n",
       " 'happen',\n",
       " 'monday',\n",
       " 'even',\n",
       " 'with',\n",
       " 'the',\n",
       " 'current',\n",
       " 'news',\n",
       " 'about',\n",
       " 'raisinf',\n",
       " 'output',\n",
       " 'there',\n",
       " 'is',\n",
       " 'still',\n",
       " 'so',\n",
       " 'many',\n",
       " 'ha',\n",
       " 'current',\n",
       " 'ratio',\n",
       " 'of',\n",
       " 'so',\n",
       " 'it',\n",
       " 'is',\n",
       " 'financially',\n",
       " 'healthy',\n",
       " 'and',\n",
       " 'ha',\n",
       " 'no',\n",
       " 'problem',\n",
       " 'in',\n",
       " 'meeting',\n",
       " 'it',\n",
       " 'obligation',\n",
       " 'bullish',\n",
       " 'stock',\n",
       " 'to',\n",
       " 'watch',\n",
       " 'setup',\n",
       " 'timeframes',\n",
       " 'just',\n",
       " 'short',\n",
       " 'it',\n",
       " 'high',\n",
       " 'alert',\n",
       " 'for',\n",
       " 'next',\n",
       " 'week',\n",
       " 'gt',\n",
       " 'breakdown',\n",
       " 'the',\n",
       " 'current',\n",
       " 'ratio',\n",
       " 'of',\n",
       " 'is',\n",
       " 'much',\n",
       " 'better',\n",
       " 'than',\n",
       " 'the',\n",
       " 'industry',\n",
       " 'average',\n",
       " 'of',\n",
       " 'miss',\n",
       " 'these',\n",
       " 'day',\n",
       " 'if',\n",
       " 'break',\n",
       " 'and',\n",
       " 'confirms',\n",
       " 'next',\n",
       " 'week',\n",
       " 'you',\n",
       " 'will',\n",
       " 'see',\n",
       " 'violent',\n",
       " 'move',\n",
       " 'downward',\n",
       " 'to',\n",
       " 'my',\n",
       " 'buy',\n",
       " 'price',\n",
       " 'bear',\n",
       " 'have',\n",
       " 'reason',\n",
       " 'on',\n",
       " 'to',\n",
       " 'pay',\n",
       " 'more',\n",
       " 'attention',\n",
       " 'breakout',\n",
       " 'base',\n",
       " 'gap',\n",
       " 'and',\n",
       " 'day',\n",
       " 'ma',\n",
       " 'gap',\n",
       " 'gap',\n",
       " 'gap',\n",
       " 'and',\n",
       " 'day',\n",
       " 'ma',\n",
       " 'cabot',\n",
       " 'weekly',\n",
       " 'video',\n",
       " 'quot',\n",
       " 'resilient',\n",
       " 'growth',\n",
       " 'stock',\n",
       " 'to',\n",
       " 'watch',\n",
       " 'quot',\n",
       " 'when',\n",
       " 'wa',\n",
       " 'kid',\n",
       " 'my',\n",
       " 'froend',\n",
       " 'told',\n",
       " 'me',\n",
       " 'the',\n",
       " 'moon',\n",
       " 'wa',\n",
       " 'made',\n",
       " 'out',\n",
       " 'of',\n",
       " 'cheese',\n",
       " 'short',\n",
       " 'volume',\n",
       " 'percent',\n",
       " 'for',\n",
       " 'wa',\n",
       " 'on',\n",
       " 'and',\n",
       " 'day',\n",
       " 'rank',\n",
       " 'wa',\n",
       " 'th',\n",
       " 'percentile',\n",
       " 'thank',\n",
       " 'you',\n",
       " 'don',\n",
       " 'feel',\n",
       " 'the',\n",
       " 'need',\n",
       " 'to',\n",
       " 'tell',\n",
       " 'or',\n",
       " 'to',\n",
       " 'do',\n",
       " 'well',\n",
       " 'for',\n",
       " 'me',\n",
       " 'they',\n",
       " 'already',\n",
       " 'have',\n",
       " 'during',\n",
       " 'the',\n",
       " 'youtube',\n",
       " 'interview',\n",
       " 'mitch',\n",
       " 'couldn',\n",
       " 'remember',\n",
       " 'single',\n",
       " 'movie',\n",
       " 'he',\n",
       " 'watched',\n",
       " 'all',\n",
       " 'year',\n",
       " 'except',\n",
       " 'star',\n",
       " 'war',\n",
       " 'black',\n",
       " 'panther',\n",
       " 'clothes',\n",
       " 'staanalystalert',\n",
       " 'for',\n",
       " 'jefferies',\n",
       " 'downgrade',\n",
       " 'with',\n",
       " 'rating',\n",
       " 'of',\n",
       " 'hold',\n",
       " 'setting',\n",
       " 'target',\n",
       " 'price',\n",
       " 'at',\n",
       " 'usd',\n",
       " 'our',\n",
       " 'own',\n",
       " 'verdict',\n",
       " 'is',\n",
       " 'hold',\n",
       " 'short',\n",
       " 'sale',\n",
       " 'volume',\n",
       " 'not',\n",
       " 'short',\n",
       " 'interest',\n",
       " 'for',\n",
       " 'on',\n",
       " 'is',\n",
       " 'ha',\n",
       " 'better',\n",
       " 'return',\n",
       " 'on',\n",
       " 'equity',\n",
       " 'than',\n",
       " 'the',\n",
       " 'industry',\n",
       " 'average',\n",
       " 'of',\n",
       " 'although',\n",
       " 'the',\n",
       " 'market',\n",
       " 'is',\n",
       " 'up',\n",
       " 'is',\n",
       " 'doing',\n",
       " 'even',\n",
       " 'better',\n",
       " 'it',\n",
       " 'ha',\n",
       " 'advanced',\n",
       " 'a',\n",
       " 'of',\n",
       " 'more',\n",
       " 'info',\n",
       " 'peer',\n",
       " 'at',\n",
       " 'july',\n",
       " 'will',\n",
       " 'be',\n",
       " 'the',\n",
       " 'most',\n",
       " 'bullish',\n",
       " 'day',\n",
       " 'of',\n",
       " 'the',\n",
       " 'year',\n",
       " 'for',\n",
       " 'stock',\n",
       " 'option',\n",
       " 'volume',\n",
       " 'wa',\n",
       " 'normal',\n",
       " 'on',\n",
       " 'friday',\n",
       " 'with',\n",
       " 'contract',\n",
       " 'call',\n",
       " 'volume',\n",
       " 'wa',\n",
       " 'and',\n",
       " 'put',\n",
       " 'volume',\n",
       " 'wa',\n",
       " 'third',\n",
       " 'design',\n",
       " 'win',\n",
       " 'the',\n",
       " 'timing',\n",
       " 'match',\n",
       " 'it',\n",
       " 'probably',\n",
       " 'arm',\n",
       " 'alcohol',\n",
       " 'stock',\n",
       " 'tobacco',\n",
       " 'stock',\n",
       " 'and',\n",
       " 'firearm',\n",
       " 'stock',\n",
       " 'to',\n",
       " 'buy',\n",
       " 'president',\n",
       " 'trump',\n",
       " 'tweet',\n",
       " 'just',\n",
       " 'spoke',\n",
       " 'to',\n",
       " 'king',\n",
       " 'salman',\n",
       " 'of',\n",
       " 'saudi',\n",
       " 'arabia',\n",
       " 'and',\n",
       " 'explained',\n",
       " 'to',\n",
       " 'him',\n",
       " 'that',\n",
       " 'because',\n",
       " 'of',\n",
       " 'the',\n",
       " 'turmoil',\n",
       " 'amp',\n",
       " 'today',\n",
       " 'insight',\n",
       " 'on',\n",
       " 'intc',\n",
       " 'mama',\n",
       " 'said',\n",
       " 'get',\n",
       " 'ice',\n",
       " 'cream',\n",
       " 'if',\n",
       " 'finish',\n",
       " 'my',\n",
       " 'due',\n",
       " 'dil',\n",
       " 'just',\n",
       " 'noticed',\n",
       " 'they',\n",
       " 'have',\n",
       " 'the',\n",
       " 'last',\n",
       " 'jedi',\n",
       " 'on',\n",
       " 'stream',\n",
       " 'love',\n",
       " 'this',\n",
       " 'stock',\n",
       " 'here',\n",
       " 'you',\n",
       " 'go',\n",
       " 'will',\n",
       " 'just',\n",
       " 'leave',\n",
       " 'this',\n",
       " 'here',\n",
       " 'good',\n",
       " 'view',\n",
       " 'daily',\n",
       " 'still',\n",
       " 'look',\n",
       " 'good',\n",
       " 'ema',\n",
       " 'held',\n",
       " 'above',\n",
       " 'ema',\n",
       " 'and',\n",
       " 'stochastics',\n",
       " 'turning',\n",
       " 'healthy',\n",
       " 'a',\n",
       " 'spy',\n",
       " 'qqq',\n",
       " 'opposite',\n",
       " 'with',\n",
       " 'forward',\n",
       " 'pe',\n",
       " 'of',\n",
       " 'the',\n",
       " 'valuation',\n",
       " 'of',\n",
       " 'can',\n",
       " 'be',\n",
       " 'described',\n",
       " 'a',\n",
       " 'cheap',\n",
       " 'saber',\n",
       " 'capital',\n",
       " 'presentation',\n",
       " 'common',\n",
       " 'denominator',\n",
       " 'of',\n",
       " 'tencent',\n",
       " 'facebook',\n",
       " 'and',\n",
       " 'google',\n",
       " 'how',\n",
       " 'expect',\n",
       " 'the',\n",
       " 'earnings',\n",
       " 'is',\n",
       " 'one',\n",
       " 'of',\n",
       " 'the',\n",
       " 'better',\n",
       " 'performing',\n",
       " 'stock',\n",
       " 'in',\n",
       " 'the',\n",
       " 'crude',\n",
       " 'petroleum',\n",
       " 'and',\n",
       " 'natural',\n",
       " 'gas',\n",
       " 'industry',\n",
       " 'pu',\n",
       " 'it',\n",
       " 'simply',\n",
       " 'havent',\n",
       " 'lost',\n",
       " 'on',\n",
       " 'any',\n",
       " 'brown',\n",
       " 'guy',\n",
       " 'run',\n",
       " 'tech',\n",
       " 'company',\n",
       " 'mf',\n",
       " 'are',\n",
       " 'well',\n",
       " 'educated',\n",
       " 'know',\n",
       " 'their',\n",
       " 'shit',\n",
       " 'more',\n",
       " 'more',\n",
       " 'every',\n",
       " 'year',\n",
       " 'former',\n",
       " 'president',\n",
       " 'of',\n",
       " 'global',\n",
       " 'manufacturing',\n",
       " 'at',\n",
       " 'pfizer',\n",
       " 'is',\n",
       " 'an',\n",
       " 'independent',\n",
       " 'director',\n",
       " 'at',\n",
       " 'nat',\n",
       " 'ricciardi',\n",
       " 'may',\n",
       " 'be',\n",
       " 'the',\n",
       " 'safest',\n",
       " 'stock',\n",
       " 'own',\n",
       " 'special',\n",
       " 'limited',\n",
       " 'offer',\n",
       " 'june',\n",
       " 'th',\n",
       " 'june',\n",
       " 'th',\n",
       " 'tradenet',\n",
       " 'is',\n",
       " 'offering',\n",
       " 'discount',\n",
       " 'on',\n",
       " 'intro',\n",
       " 'program',\n",
       " 'below',\n",
       " 'buy',\n",
       " 'put',\n",
       " 'on',\n",
       " 'financials',\n",
       " 'great',\n",
       " 'summary',\n",
       " 'of',\n",
       " 'jeff',\n",
       " 'gundlach',\n",
       " 'sohn',\n",
       " 'presentation',\n",
       " 'long',\n",
       " 'thesis',\n",
       " 'for',\n",
       " 'energy',\n",
       " 'stock',\n",
       " 'low',\n",
       " 'peg',\n",
       " 'ratio',\n",
       " 'which',\n",
       " 'compensates',\n",
       " 'the',\n",
       " 'pe',\n",
       " 'for',\n",
       " 'growth',\n",
       " 'indicates',\n",
       " 'rather',\n",
       " 'cheap',\n",
       " 'valuation',\n",
       " 'great',\n",
       " 'summary',\n",
       " 'of',\n",
       " 'jeff',\n",
       " 'gundlach',\n",
       " 'sohn',\n",
       " 'pres',\n",
       " 'long',\n",
       " 'thesis',\n",
       " 'for',\n",
       " 'energy',\n",
       " 'equity',\n",
       " 'coming',\n",
       " 'seems',\n",
       " 'is',\n",
       " 'the',\n",
       " 'support',\n",
       " 'next',\n",
       " 'if',\n",
       " 'under',\n",
       " 'is',\n",
       " 'likely',\n",
       " 'ha',\n",
       " 'moved',\n",
       " 'on',\n",
       " 'check',\n",
       " 'out',\n",
       " 'the',\n",
       " 'movement',\n",
       " 'and',\n",
       " 'peer',\n",
       " 'at',\n",
       " 'bullshit',\n",
       " 'worthless',\n",
       " 'mean',\n",
       " 'fucking',\n",
       " 'nothing',\n",
       " 'this',\n",
       " 'is',\n",
       " 'macau',\n",
       " 'not',\n",
       " 'fucking',\n",
       " 'usa',\n",
       " 'take',\n",
       " 'this',\n",
       " 'let',\n",
       " 'me',\n",
       " 'know',\n",
       " 'where',\n",
       " 'are',\n",
       " 'we',\n",
       " 'right',\n",
       " 'now',\n",
       " 'lol',\n",
       " 'the',\n",
       " 'chart',\n",
       " 'look',\n",
       " 'so',\n",
       " 'ugly',\n",
       " 'without',\n",
       " 'clear',\n",
       " 'support',\n",
       " 'level',\n",
       " 'short',\n",
       " 'term',\n",
       " 'bearish',\n",
       " 'll',\n",
       " 'buy',\n",
       " 'when',\n",
       " 'this',\n",
       " 'is',\n",
       " 'at',\n",
       " 'great',\n",
       " 'summary',\n",
       " 'of',\n",
       " 'jeff',\n",
       " 'gundlach',\n",
       " 'sohn',\n",
       " 'presentation',\n",
       " 'long',\n",
       " 'thesis',\n",
       " 'for',\n",
       " 'energy',\n",
       " 'stock',\n",
       " 'previously',\n",
       " 'there',\n",
       " 'wa',\n",
       " 'mo',\n",
       " 'run',\n",
       " 'up',\n",
       " 'followed',\n",
       " 'by',\n",
       " 'drop',\n",
       " 'we',\n",
       " 'are',\n",
       " 'at',\n",
       " 'the',\n",
       " 'end',\n",
       " 'of',\n",
       " 'month',\n",
       " 'of',\n",
       " 'another',\n",
       " 'runup',\n",
       " 'and',\n",
       " 'have',\n",
       " 'dropped',\n",
       " 'about',\n",
       " 'smart',\n",
       " 'money',\n",
       " 'betting',\n",
       " 'on',\n",
       " 'call',\n",
       " 'deal',\n",
       " 'update',\n",
       " 'although',\n",
       " 'the',\n",
       " 'technical',\n",
       " 'rating',\n",
       " 'is',\n",
       " 'bad',\n",
       " 'doe',\n",
       " 'present',\n",
       " 'nice',\n",
       " 'setup',\n",
       " 'opportunity',\n",
       " 'will',\n",
       " 'completely',\n",
       " 'scale',\n",
       " 'out',\n",
       " 'in',\n",
       " 'time',\n",
       " 'to',\n",
       " 'gobble',\n",
       " 'up',\n",
       " 'my',\n",
       " 'next',\n",
       " 'long',\n",
       " 'play',\n",
       " 'aka',\n",
       " 'my',\n",
       " 'favorite',\n",
       " 'gt',\n",
       " 'short',\n",
       " 'sale',\n",
       " 'volume',\n",
       " 'not',\n",
       " 'short',\n",
       " 'interest',\n",
       " 'for',\n",
       " 'is',\n",
       " 'them',\n",
       " 'are',\n",
       " 'iddy',\n",
       " 'bitty',\n",
       " 'kiddy',\n",
       " 'hand',\n",
       " 'short',\n",
       " 'interest',\n",
       " 'ratio',\n",
       " 'of',\n",
       " 'is',\n",
       " 'at',\n",
       " 'and',\n",
       " 'short',\n",
       " 'to',\n",
       " 'float',\n",
       " 'is',\n",
       " 'then',\n",
       " 'awesome',\n",
       " 'it',\n",
       " 'is',\n",
       " 'now',\n",
       " 'be',\n",
       " 'concerned',\n",
       " 'if',\n",
       " 'not',\n",
       " 'over',\n",
       " 'by',\n",
       " 'eow',\n",
       " 'might',\n",
       " 'get',\n",
       " 'under',\n",
       " 'next',\n",
       " 'wk',\n",
       " 'or',\n",
       " 'soon',\n",
       " 'throwback',\n",
       " 'staanalystalert',\n",
       " 'for',\n",
       " 'u',\n",
       " 'capital',\n",
       " 'advisor',\n",
       " 'upgrade',\n",
       " 'with',\n",
       " 'rating',\n",
       " 'of',\n",
       " 'hold',\n",
       " 'our',\n",
       " 'own',\n",
       " 'verdict',\n",
       " 'is',\n",
       " 'buy',\n",
       " 'lol',\n",
       " 'all',\n",
       " 'these',\n",
       " 'shorties',\n",
       " 'are',\n",
       " 'dreaming',\n",
       " 'of',\n",
       " 'great',\n",
       " 'depression',\n",
       " 'or',\n",
       " 'somethin',\n",
       " 'loll',\n",
       " 'just',\n",
       " 'updated',\n",
       " 'hormel',\n",
       " 'food',\n",
       " 'dividend',\n",
       " 'king',\n",
       " 'stock',\n",
       " 'analysis',\n",
       " 'dividend',\n",
       " 'king',\n",
       " 'consumer',\n",
       " 'defensive',\n",
       " 'today',\n",
       " 'insight',\n",
       " 'on',\n",
       " 'just',\n",
       " 'updated',\n",
       " 'intel',\n",
       " 'valuation',\n",
       " 'profitability',\n",
       " 'and',\n",
       " 'dividend',\n",
       " 'safety',\n",
       " 'score',\n",
       " 'analysis',\n",
       " 'dividend',\n",
       " 'technology',\n",
       " 'today',\n",
       " 'insight',\n",
       " 'on',\n",
       " 'the',\n",
       " 'long',\n",
       " 'and',\n",
       " 'short',\n",
       " 'term',\n",
       " 'trend',\n",
       " 'are',\n",
       " 'both',\n",
       " 'positive',\n",
       " 'this',\n",
       " 'is',\n",
       " 'looking',\n",
       " 'good',\n",
       " 'they',\n",
       " 'so',\n",
       " 'mad',\n",
       " 'at',\n",
       " 'me',\n",
       " 'still',\n",
       " 'back',\n",
       " 'to',\n",
       " 'by',\n",
       " 'july',\n",
       " 'report',\n",
       " 'and',\n",
       " 'block',\n",
       " 'this',\n",
       " 'person',\n",
       " 'spam',\n",
       " 'should',\n",
       " 'open',\n",
       " 'at',\n",
       " 'on',\n",
       " 'monday',\n",
       " 'my',\n",
       " 'projection',\n",
       " 'for',\n",
       " 'if',\n",
       " 'thats',\n",
       " 'true',\n",
       " 'under',\n",
       " 'is',\n",
       " 'next',\n",
       " 'week',\n",
       " 'thats',\n",
       " 'why',\n",
       " 'prefer',\n",
       " 'to',\n",
       " 'buy',\n",
       " 'from',\n",
       " 'support',\n",
       " 'level',\n",
       " 'what',\n",
       " 'turd',\n",
       " 'percent',\n",
       " 'short',\n",
       " 'volume',\n",
       " 'for',\n",
       " 'wa',\n",
       " 'on',\n",
       " 'wal',\n",
       " 'mart',\n",
       " 'dividend',\n",
       " 'aristocrat',\n",
       " 'dividend',\n",
       " 'aristocrat',\n",
       " 'consumer',\n",
       " 'defensive',\n",
       " 'valueinvesting',\n",
       " 'dvb',\n",
       " 'aaamp',\n",
       " 'looking',\n",
       " 'for',\n",
       " 'marriage',\n",
       " 'have',\n",
       " 'in',\n",
       " 'my',\n",
       " 'bank',\n",
       " 'account',\n",
       " 'with',\n",
       " ...]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_flatten = [w for ts in tokenized for w in ts]\n",
    "tokenized_flatten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "Create a vocabulary by using Bag of words\n",
    "\"\"\"\n",
    "\n",
    "# TODO: Implement \n",
    "\n",
    "bow = Counter(tokenized_flatten)\n",
    "# Counter with sorted https://iq.opengenus.org/ways-to-sort-counter-in-python/\n",
    "# vocab = sorted(bow,key=bow.get,reverse=True)# key to use for comparison in sort\n",
    "# vocab_to_int = {word:i for i,word in enumerate(vocab,1)} #enumerate start with 1\n",
    "# vocab_to_int"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Frequency of Words Appearing in Message\n",
    "With our vocabulary, now we'll remove some of the most common words such as 'the', 'and', 'it', etc. These words don't contribute to identifying sentiment and are really common, resulting in a lot of noise in our input. If we can filter these out, then our network should have an easier time learning.\n",
    "\n",
    "We also want to remove really rare words that show up in a only a few twits. Here you'll want to divide the count of each word by the **number of messages** calculated in the code block above (i.e. `len(messages))`. Then remove words that only appear in some small fraction of the messages.\n",
    "\n",
    ">Note: There is not an exact number for low and high-frequency cut-offs, however there is a correct optimal range.\n",
    "You should ideally set up low-frequency cut-off from 0.0000002 to 0.000007 (inclusive) and high-frequency from 5 to 20 (inclusive). If the number is too big, we lose lots of important words that we can use in our data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['the', 'to', 'is', 'for', 'on']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "98506"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "Set the following variables:\n",
    "    freqs\n",
    "    low_cutoff\n",
    "    high_cutoff\n",
    "    K_most_common\n",
    "\"\"\"\n",
    "\n",
    "# TODO Implement \n",
    "\n",
    "# Dictionart that contains the Frequency of words appearing in messages.\n",
    "# The key is the token and the value is the frequency of that word in the corpus.\n",
    "freqs = {k:v/len(messages) for k,v in bow.items()}\n",
    "\n",
    "# print(freqs['raisinf'])\n",
    "\n",
    "# Float that is the frequency cutoff. Drop words with a frequency that is lower or equal to this number.\n",
    "low_cutoff = 0.0000002\n",
    "\n",
    "# Integer that is the cut off for most common words. Drop words that are the `high_cutoff` most common words.\n",
    "high_cutoff = 5\n",
    "\n",
    "# The k most common words in the corpus. Use `high_cutoff` as the k.\n",
    "K_most_common = [t[0] for t in bow.most_common(high_cutoff)]\n",
    "\n",
    "\n",
    "filtered_words = [word for word in freqs if (freqs[word] > low_cutoff and word not in K_most_common)]\n",
    "print(K_most_common)\n",
    "len(filtered_words) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Updating Vocabulary by Removing Filtered Words\n",
    "Let's creat three variables that will help with our vocabulary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Set the following variables:\n",
    "    vocab\n",
    "    id2vocab\n",
    "    filtered\n",
    "\"\"\"\n",
    "\n",
    "#TODO Implement\n",
    "\n",
    "# A dictionary for the `filtered_words`. The key is the word and value is an id that represents the word. \n",
    "vocab = {v:i for i,v in enumerate(filtered_words,1)}\n",
    "# Reverse of the `vocab` dictionary. The key is word id and value is the word. \n",
    "id2vocab = {v:i for i,v in vocab.items()}\n",
    "# tokenized with the words not in `filtered_words` removed.\n",
    "filtered = [[w for w in sentences if w not in K_most_common] for sentences in tokenized]\n",
    "\n",
    "assert set(vocab.keys()) == set(id2vocab.values()), 'Check vocab and id2vocab dictionaries'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Balancing the classes\n",
    "Let's do a few last pre-processing steps. If we look at how our twits are labeled, we'll find that 50% of them are neutral. This means that our network will be 50% accurate just by guessing 0 every single time. To help our network learn appropriately, we'll want to balance our classes.\n",
    "That is, make sure each of our different sentiment scores show up roughly as frequently in the data.\n",
    "\n",
    "What we can do here is go through each of our examples and randomly drop twits with neutral sentiment. What should be the probability we drop these twits if we want to get around 20% neutral twits starting at 50% neutral? We should also take this opportunity to remove messages with length 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "balanced = {'messages': [], 'sentiments':[]}\n",
    "\n",
    "n_neutral = sum(1 for each in sentiments if each == 2)\n",
    "N_examples = len(sentiments)\n",
    "keep_prob = (N_examples - n_neutral)/4/n_neutral\n",
    "\n",
    "for idx, sentiment in enumerate(sentiments):\n",
    "    message = filtered[idx]\n",
    "    if len(message) == 0:\n",
    "        # skip this message because it has length zero\n",
    "        continue\n",
    "    elif sentiment != 2 or random.random() < keep_prob:\n",
    "        balanced['messages'].append(message)\n",
    "        balanced['sentiments'].append(sentiment) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you did it correctly, you should see the following result "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.1953244137813287"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_neutral = sum(1 for each in balanced['sentiments'] if each == 2)\n",
    "N_examples = len(balanced['sentiments'])\n",
    "n_neutral/N_examples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally let's convert our tokens into integer ids which we can pass to the network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 'raisinf' in vocab.keys() by setting higher low_frq_thres we unable to retrieve some words like 'raisinf'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "token_ids = [[vocab[word] for word in message] for message in balanced['messages']]\n",
    "sentiments = balanced['sentiments']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neural Network\n",
    "Now we have our vocabulary which means we can transform our tokens into ids, which are then passed to our network. So, let's define the network now!\n",
    "\n",
    "Here is a nice diagram showing the network we'd like to build: \n",
    "\n",
    "#### Embed -> RNN -> Dense -> Softmax\n",
    "### Implement the text classifier\n",
    "Before we build text classifier, if you remember from the other network that you built in  \"Sentiment Analysis with an RNN\"  exercise  - which there, the network called \" SentimentRNN\", here we named it \"TextClassifer\" - consists of three main parts: 1) init function `__init__` 2) forward pass `forward`  3) hidden state `init_hidden`. \n",
    "\n",
    "This network is pretty similar to the network you built expect in the  `forward` pass, we use softmax instead of sigmoid. The reason we are not using sigmoid is that the output of NN is not a binary. In our network, sentiment scores have 5 possible outcomes. We are looking for an outcome with the highest probability thus softmax is a better choice."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TextClassifier(nn.Module):\n",
    "    def __init__(self, vocab_size, embed_size, lstm_size, output_size, lstm_layers=1, dropout=0.1):\n",
    "        \"\"\"\n",
    "        Initialize the model by setting up the layers.\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "            vocab_size : The vocabulary size.\n",
    "            embed_size : The embedding layer size.\n",
    "            lstm_size : The LSTM layer size.\n",
    "            output_size : The output size.\n",
    "            lstm_layers : The number of LSTM layers.\n",
    "            dropout : The dropout probability.\n",
    "        \"\"\"\n",
    "        \n",
    "        super().__init__()\n",
    "        self.vocab_size = vocab_size\n",
    "        self.embed_size = embed_size\n",
    "        self.lstm_size = lstm_size\n",
    "        self.output_size = output_size\n",
    "        self.lstm_layers = lstm_layers\n",
    "        self.dropout = dropout\n",
    "        \n",
    "        # TODO Implement\n",
    "\n",
    "        # Setup embedding layer\n",
    "        self.embedding = nn.Embedding(vocab_size,embed_size)\n",
    "        \n",
    "        # Setup additional layers\n",
    "        \n",
    "        #using batch_first=True will make nn consider input size(0) as batch size\n",
    "        #https://pytorch.org/docs/stable/generated/torch.nn.LSTM.html?highlight=lstm#torch.nn.LSTM\n",
    "        self.lstm = nn.LSTM(embed_size,lstm_size,lstm_layers,dropout=dropout,batch_first=False) \n",
    "        self.fc = nn.Linear(lstm_size,output_size)\n",
    "        self.drop = nn.Dropout(dropout) # we need to add another drop out layer, if we have dropout param in LSTM?\n",
    "        self.soft = nn.LogSoftmax(dim=1) #wrap softmax with log, using dim=1 for all columns prob added up to 1!!!\n",
    "\n",
    "\n",
    "    def init_hidden(self, batch_size):\n",
    "        \"\"\" \n",
    "        Initializes hidden state\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "            batch_size : The size of batches.\n",
    "        \n",
    "        Returns\n",
    "        -------\n",
    "            hidden_state\n",
    "            \n",
    "        \"\"\"\n",
    "        \n",
    "        # TODO Implement \n",
    "        \n",
    "        # Create two new tensors with sizes n_layers x batch_size x hidden_dim,\n",
    "        # initialized to zero, for hidden state and cell state of LSTM\n",
    "        \n",
    "        weight = next(self.parameters()).data\n",
    "        \n",
    "        if torch.cuda.is_available():\n",
    "            hidden = (weight.new(self.lstm_layers,batch_size,self.lstm_size).zero_().cuda(),\n",
    "                     weight.new(self.lstm_layers,batch_size,self.lstm_size).zero_().cuda())\n",
    "        else:\n",
    "             hidden = (weight.new(self.lstm_layers,batch_size,self.lstm_size).zero_(),\n",
    "                     weight.new(self.lstm_layers,batch_size,self.lstm_size).zero_())\n",
    "        \n",
    "        return hidden\n",
    "\n",
    "\n",
    "    def forward(self, nn_input, hidden_state):\n",
    "        \"\"\"\n",
    "        Perform a forward pass of our model on nn_input.\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "            nn_input : The batch of input to the NN.\n",
    "            hidden_state : The LSTM hidden state.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "            logps: log softmax output\n",
    "            hidden_state: The new hidden state.\n",
    "\n",
    "        \"\"\"\n",
    "        \n",
    "        # TODO Implement \n",
    "#         batch_size = nn_input.size(0)\n",
    "#         seq_length = nn_input.size(1)\n",
    "        \n",
    "#         x = nn_input.view((batch_size,seq_length)).long()\n",
    "\n",
    "        #x.size: (seq_length,batch_size)\n",
    "        x = nn_input.long()\n",
    "#         print(\"x size\",x.size())\n",
    "        #embedding\n",
    "        x = self.embedding(x)\n",
    "        lstm_out,hidden_state = self.lstm(x,hidden_state)\n",
    "#         print(\"lstm old size\",lstm_out.size())\n",
    "        lstm_out = lstm_out[-1,:, :] # getting the last time step output\n",
    "#         print(\"lstm size\",lstm_out.size())\n",
    "        out = self.fc(lstm_out)\n",
    "#         print(\"out size\",out.size())\n",
    "        # softmax\n",
    "        soft_out = self.soft(out)\n",
    "#         print(\"softmax size\",soft_out.size())\n",
    "        \n",
    "        return soft_out,hidden_state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input tensor([[ 0.7051,  0.0455,  0.9724],\n",
      "        [ 0.5740,  0.7019, -0.5033]])\n",
      "output tensor([[-1.0379, -1.6976, -0.7707],\n",
      "        [-0.9070, -0.7791, -1.9843]])\n",
      "output1 tensor([[-0.6297, -1.0742, -0.2059],\n",
      "        [-0.7609, -0.4179, -1.6816]])\n",
      "o2 tensor([[-1.0379, -1.6976, -0.7707],\n",
      "        [-0.9070, -0.7791, -1.9843]])\n",
      "o exp tensor([[ 0.3542,  0.1831,  0.4627],\n",
      "        [ 0.4037,  0.4588,  0.1375]])\n",
      "o1 exp tensor([[ 0.5327,  0.3416,  0.8139],\n",
      "        [ 0.4673,  0.6584,  0.1861]])\n",
      "o2 exp tensor([[ 0.3542,  0.1831,  0.4627],\n",
      "        [ 0.4037,  0.4588,  0.1375]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/ipykernel_launcher.py:5: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  \"\"\"\n"
     ]
    }
   ],
   "source": [
    "m = nn.LogSoftmax()\n",
    "m1 = nn.LogSoftmax(dim=0)\n",
    "m2 = nn.LogSoftmax(dim=1)\n",
    "input = torch.randn(2, 3)\n",
    "output = m(input)\n",
    "output1 = m1(input)\n",
    "output2 = m2(input)\n",
    "print(\"input\",input)\n",
    "print(\"output\",output)\n",
    "print(\"output1\",output1)\n",
    "print(\"o2\",output2)\n",
    "print(\"o exp\",output.exp())\n",
    "print(\"o1 exp\",output1.exp())\n",
    "print(\"o2 exp\",output2.exp())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### View Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-1.8627, -1.3836, -1.2610, -1.8382, -1.8864],\n",
      "        [-1.8165, -1.3990, -1.2820, -1.8027, -1.9091],\n",
      "        [-1.8366, -1.3978, -1.2703, -1.8213, -1.8908],\n",
      "        [-1.8256, -1.4107, -1.2760, -1.8169, -1.8760]], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "model = TextClassifier(len(vocab), 10, 6, 5, dropout=0.1, lstm_layers=2)\n",
    "model.embedding.weight.data.uniform_(-1, 1)\n",
    "model.to(\"cuda\")\n",
    "input = torch.randint(0, 1000, (5, 4), dtype=torch.int64).to(\"cuda\")\n",
    "hidden = model.init_hidden(4)\n",
    "\n",
    "logps, _ = model.forward(input, hidden)\n",
    "print(logps)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training\n",
    "### DataLoaders and Batching\n",
    "Now we should build a generator that we can use to loop through our data. It'll be more efficient if we can pass our sequences in as batches. Our input tensors should look like `(sequence_length, batch_size)`. So if our sequences are 40 tokens long and we pass in 25 sequences, then we'd have an input size of `(40, 25)`.\n",
    "\n",
    "If we set our sequence length to 40, what do we do with messages that are more or less than 40 tokens? For messages with fewer than 40 tokens, we will pad the empty spots with zeros. We should be sure to **left** pad so that the RNN starts from nothing before going through the data. If the message has 20 tokens, then the first 20 spots of our 40 long sequence will be 0. If a message has more than 40 tokens, we'll just keep the first 40 tokens."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dataloader(messages, labels, sequence_length=30, batch_size=32, shuffle=False):\n",
    "    \"\"\" \n",
    "    Build a dataloader.\n",
    "    \"\"\"\n",
    "    if shuffle:\n",
    "        indices = list(range(len(messages)))\n",
    "        random.shuffle(indices)\n",
    "        messages = [messages[idx] for idx in indices]\n",
    "        labels = [labels[idx] for idx in indices]\n",
    "\n",
    "    total_sequences = len(messages)\n",
    "\n",
    "    for ii in range(0, total_sequences, batch_size):\n",
    "        batch_messages = messages[ii: ii+batch_size]\n",
    "        \n",
    "        # First initialize a tensor of all zeros\n",
    "        batch = torch.zeros((sequence_length, len(batch_messages)), dtype=torch.int64)\n",
    "        for batch_num, tokens in enumerate(batch_messages):\n",
    "            token_tensor = torch.tensor(tokens)\n",
    "            # Left pad!\n",
    "            start_idx = max(sequence_length - len(token_tensor), 0)\n",
    "            batch[start_idx:, batch_num] = token_tensor[:sequence_length]\n",
    "        \n",
    "        label_tensor = torch.tensor(labels[ii: ii+len(batch_messages)])\n",
    "        \n",
    "        yield batch, label_tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training and  Validation\n",
    "With our data in nice shape, we'll split it into training and validation sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "824320\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Split data into training and validation datasets. Use an appropriate split size.\n",
    "The features are the `token_ids` and the labels are the `sentiments`.\n",
    "\"\"\"   \n",
    "\n",
    "# TODO Implement \n",
    "\n",
    "l = (len(token_ids))//(20*64)\n",
    "\n",
    "split_train = int(.8*l*(20*64))\n",
    "split_valid = int(.2*l*(20*64))\n",
    "print(split_train)\n",
    "\n",
    "train_features = token_ids[:split_train]\n",
    "valid_features = token_ids[split_train:split_train+split_valid]\n",
    "train_labels = sentiments[:split_train]\n",
    "valid_labels = sentiments[split_train:split_train+split_valid]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# token_ids[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([20, 64])\n"
     ]
    }
   ],
   "source": [
    "text_batch, labels = next(iter(dataloader(train_features, train_labels, sequence_length=20, batch_size=64)))\n",
    "text_batch, labels = text_batch.to(\"cuda\"), labels.to(\"cuda\")\n",
    "print(text_batch.size())\n",
    "#vocab_size, embed_size, lstm_size, output_size, lstm_layers=1, dropout=0.1\n",
    "model = TextClassifier(len(vocab)+1, 200, 128, 5, dropout=0.)\n",
    "model.to(\"cuda\")\n",
    "hidden = model.init_hidden(64)\n",
    "logps, hidden = model.forward(text_batch, hidden)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # dataloader(valid_features, valid_labels, batch_size=batch_size, sequence_length=20, shuffle=True)\n",
    "# text_batch, labels = next(iter(dataloader(valid_features, valid_labels, sequence_length=20, batch_size=64)))\n",
    "# text_batch, labels = text_batch.to(\"cuda\"), labels.to(\"cuda\")\n",
    "# print(text_batch.size())\n",
    "# model = TextClassifier(len(vocab)+1, 200, 128, 5, dropout=0.)\n",
    "# model.to(\"cuda\")\n",
    "# hidden = model.init_hidden(64)\n",
    "# logps, hidden = model.forward(text_batch, hidden)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training\n",
    "It's time to train the neural network!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TextClassifier(\n",
       "  (embedding): Embedding(98507, 1024)\n",
       "  (lstm): LSTM(1024, 512, num_layers=2, dropout=0.2)\n",
       "  (fc): Linear(in_features=512, out_features=5, bias=True)\n",
       "  (drop): Dropout(p=0.2)\n",
       "  (soft): LogSoftmax()\n",
       ")"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "model = TextClassifier(len(vocab)+1, 1024, 512, 5, lstm_layers=2, dropout=0.2)\n",
    "model.embedding.weight.data.uniform_(-1, 1)\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[1, 2, 3, 4, 5],\n",
       " [6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 3, 16, 17, 18, 19, 2],\n",
       " [20, 21, 22, 23, 24, 25, 23, 26, 27, 24, 28, 29],\n",
       " [30, 31],\n",
       " [32, 33, 34, 35, 36, 37, 38, 39],\n",
       " [40, 41, 42, 43, 44, 45],\n",
       " [46, 47, 48, 49, 50, 51, 52, 15, 53, 54, 55],\n",
       " [56, 57, 48, 58, 59, 60, 61],\n",
       " [33, 62, 63, 64, 65, 66, 67, 68, 52, 69, 60, 66, 70, 71, 72, 73, 74],\n",
       " [75, 2]]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_features[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting epoch 1\n",
      "weight gradient of fc is tensor([[ 4.0213e-03,  8.4290e-04,  9.9284e-04,  ...,  4.9341e-03,\n",
      "         -9.3166e-03, -3.7850e-04],\n",
      "        [-2.3949e-03, -2.0587e-03,  5.6994e-04,  ..., -6.2658e-03,\n",
      "          3.1732e-03,  3.1332e-03],\n",
      "        [-2.5663e-03, -3.1609e-03,  1.9551e-04,  ..., -1.8645e-03,\n",
      "          2.5507e-03,  2.2665e-03],\n",
      "        [-1.8275e-03, -1.4696e-03,  1.7441e-03,  ..., -5.8661e-04,\n",
      "          2.8173e-03,  2.5979e-03],\n",
      "        [ 2.7674e-03,  5.8463e-03, -3.5024e-03,  ...,  3.7828e-03,\n",
      "          7.7538e-04, -7.6191e-03]], device='cuda:0'), bais gradient of fc is tensor(1.00000e-02 *\n",
      "       [-9.0625,  2.0123,  1.6804,  3.3173,  2.0525], device='cuda:0')\n",
      "Epoch: 1/1... Step: 100... Loss: 1.458937... Val Loss:1.491462\n",
      "weight gradient of fc is tensor(1.00000e-02 *\n",
      "       [[ 0.1168,  0.6288, -0.8850,  ...,  0.4482,  0.4092, -0.5123],\n",
      "        [-0.0177, -0.4566,  1.5326,  ..., -0.6450, -0.5339,  0.5950],\n",
      "        [ 0.3715, -0.1266,  0.1392,  ...,  0.1101, -0.0511,  0.5637],\n",
      "        [-1.5694, -0.7532, -0.8663,  ..., -2.2580,  1.6867, -0.3275],\n",
      "        [ 1.0988,  0.7076,  0.0795,  ...,  2.3448, -1.5111, -0.3189]], device='cuda:0'), bais gradient of fc is tensor([-0.0164, -0.0130, -0.0105,  0.1158, -0.0759], device='cuda:0')\n",
      "Epoch: 1/1... Step: 200... Loss: 1.240662... Val Loss:1.290164\n",
      "weight gradient of fc is tensor([[-7.2106e-03,  3.3489e-04, -9.0772e-03,  ..., -5.0741e-03,\n",
      "          7.9292e-03, -4.5720e-03],\n",
      "        [-4.6007e-03, -4.2602e-04, -5.2028e-04,  ...,  4.1724e-03,\n",
      "          5.1953e-03, -9.1525e-03],\n",
      "        [ 1.0757e-02, -6.4897e-04,  2.1508e-02,  ..., -1.1619e-03,\n",
      "         -1.1616e-02,  1.2736e-02],\n",
      "        [ 6.4892e-03,  4.1998e-04, -7.5353e-03,  ...,  6.6499e-03,\n",
      "         -1.8553e-03,  6.3718e-03],\n",
      "        [-5.4350e-03,  3.2011e-04, -4.3748e-03,  ..., -4.5862e-03,\n",
      "          3.4672e-04, -5.3834e-03]], device='cuda:0'), bais gradient of fc is tensor(1.00000e-02 *\n",
      "       [ 6.2408,  2.1140, -8.4698, -3.0199,  3.1350], device='cuda:0')\n",
      "Epoch: 1/1... Step: 300... Loss: 1.218941... Val Loss:1.213504\n",
      "weight gradient of fc is tensor([[ 5.5456e-04,  2.1442e-04, -6.7262e-03,  ..., -2.1675e-03,\n",
      "          1.0600e-02, -2.6859e-03],\n",
      "        [-6.3369e-03, -5.0389e-03,  7.1941e-03,  ..., -7.0951e-03,\n",
      "          5.9638e-04,  2.8261e-03],\n",
      "        [ 5.1834e-03,  5.1776e-03,  9.3202e-03,  ...,  3.1933e-03,\n",
      "         -9.8984e-03,  2.9335e-03],\n",
      "        [-3.0265e-04, -2.3547e-04, -3.8674e-03,  ...,  2.4737e-03,\n",
      "         -7.7021e-03, -5.6560e-03],\n",
      "        [ 9.0159e-04, -1.1769e-04, -5.9207e-03,  ...,  3.5956e-03,\n",
      "          6.4039e-03,  2.5822e-03]], device='cuda:0'), bais gradient of fc is tensor(1.00000e-02 *\n",
      "       [ 3.0916,  1.8041, -6.9489, -0.0351,  2.0883], device='cuda:0')\n",
      "Epoch: 1/1... Step: 400... Loss: 1.182975... Val Loss:1.192757\n",
      "weight gradient of fc is tensor(1.00000e-02 *\n",
      "       [[-0.4055, -0.1138, -0.2889,  ..., -0.3744,  0.3763,  0.2761],\n",
      "        [ 0.3470,  0.0843,  0.3170,  ...,  0.2522, -0.8510, -0.1900],\n",
      "        [-0.1262, -0.5181,  0.2299,  ..., -0.7833,  0.3565,  0.6517],\n",
      "        [ 0.4945,  0.3697, -0.4143,  ...,  0.8921, -0.4646, -0.2519],\n",
      "        [-0.3099,  0.1779,  0.1562,  ...,  0.0135,  0.5828, -0.4859]], device='cuda:0'), bais gradient of fc is tensor(1.00000e-02 *\n",
      "       [ 3.2334, -4.9007,  2.3685, -3.1794,  2.4783], device='cuda:0')\n",
      "Epoch: 1/1... Step: 500... Loss: 0.929937... Val Loss:1.162664\n",
      "weight gradient of fc is tensor(1.00000e-02 *\n",
      "       [[-0.5401, -0.2068,  0.3656,  ..., -0.4294, -0.2266,  0.1355],\n",
      "        [ 0.0059, -0.3102,  0.2610,  ...,  0.1881, -0.2696, -0.6099],\n",
      "        [-0.3883,  0.0646, -0.6413,  ..., -0.3393,  0.5032, -0.2095],\n",
      "        [ 0.7302,  0.4790, -0.0549,  ...,  0.3975, -0.5792,  0.1401],\n",
      "        [ 0.1923, -0.0266,  0.0696,  ...,  0.1830,  0.5721,  0.5438]], device='cuda:0'), bais gradient of fc is tensor(1.00000e-02 *\n",
      "       [ 1.0918,  3.0517,  2.6840, -5.4367, -1.3907], device='cuda:0')\n",
      "Epoch: 1/1... Step: 600... Loss: 1.146118... Val Loss:1.128012\n",
      "weight gradient of fc is tensor(1.00000e-02 *\n",
      "       [[-0.0273, -0.2939,  0.1633,  ...,  0.1725,  0.0482,  0.0160],\n",
      "        [-0.9430, -0.0086,  0.0365,  ..., -0.7226,  0.7708, -0.4115],\n",
      "        [ 0.5621,  0.0151, -0.0504,  ..., -0.3889, -0.1685,  0.6926],\n",
      "        [ 0.1203, -0.1476,  0.1984,  ...,  0.3934, -0.2510,  0.3265],\n",
      "        [ 0.2879,  0.4350, -0.3478,  ...,  0.5455, -0.3995, -0.6236]], device='cuda:0'), bais gradient of fc is tensor(1.00000e-02 *\n",
      "       [ 0.9800,  2.7569, -2.6753,  0.1121, -1.1738], device='cuda:0')\n",
      "Epoch: 1/1... Step: 700... Loss: 0.911941... Val Loss:1.118954\n",
      "weight gradient of fc is tensor(1.00000e-02 *\n",
      "       [[-0.5609, -0.8421,  2.3339,  ..., -0.8513, -1.2032,  1.2128],\n",
      "        [-0.9055,  0.0089, -1.2437,  ..., -0.7254,  1.2727, -0.6981],\n",
      "        [ 1.0316,  0.7309, -0.1483,  ...,  0.4579,  0.1426, -0.0809],\n",
      "        [ 0.1868, -0.2076, -0.4521,  ...,  0.8340, -0.6485, -0.0787],\n",
      "        [ 0.2480,  0.3099, -0.4898,  ...,  0.2847,  0.4364, -0.3551]], device='cuda:0'), bais gradient of fc is tensor(1.00000e-02 *\n",
      "       [-4.2037,  8.5731,  0.0624, -1.5955, -2.8363], device='cuda:0')\n",
      "Epoch: 1/1... Step: 800... Loss: 0.908836... Val Loss:1.083746\n",
      "weight gradient of fc is tensor([[ 6.6051e-03,  2.8660e-04,  8.2136e-03,  ..., -3.7328e-03,\n",
      "         -5.6872e-03,  3.2537e-03],\n",
      "        [-5.5454e-03,  1.8760e-04, -6.0780e-03,  ..., -2.4261e-03,\n",
      "          3.2336e-03, -3.9372e-03],\n",
      "        [ 5.2954e-03,  2.9348e-03,  3.5119e-03,  ...,  1.6463e-02,\n",
      "         -4.4323e-03, -6.0885e-03],\n",
      "        [-3.5127e-03, -2.7792e-03, -1.3109e-03,  ..., -4.8303e-03,\n",
      "          4.2901e-03,  5.4100e-03],\n",
      "        [-2.8424e-03, -6.2980e-04, -4.3366e-03,  ..., -5.4742e-03,\n",
      "          2.5958e-03,  1.3619e-03]], device='cuda:0'), bais gradient of fc is tensor(1.00000e-02 *\n",
      "       [-2.6525,  3.4031, -3.6858,  1.6727,  1.2624], device='cuda:0')\n",
      "Epoch: 1/1... Step: 900... Loss: 0.969941... Val Loss:1.074562\n",
      "weight gradient of fc is tensor(1.00000e-02 *\n",
      "       [[-0.7672, -0.3852, -0.8416,  ...,  0.0766, -0.0424, -0.4623],\n",
      "        [ 0.1496,  0.0069, -0.7523,  ..., -0.2714,  1.3405, -0.7652],\n",
      "        [ 1.0185,  0.7012,  1.0587,  ...,  0.3005, -0.7503,  0.1636],\n",
      "        [ 0.9091,  0.6406,  0.8218,  ...,  1.1002, -1.6533,  0.7347],\n",
      "        [-1.3100, -0.9635, -0.2866,  ..., -1.2059,  1.1054,  0.3293]], device='cuda:0'), bais gradient of fc is tensor(1.00000e-02 *\n",
      "       [-0.2285,  7.0521, -7.5424, -6.5081,  7.2269], device='cuda:0')\n",
      "Epoch: 1/1... Step: 1000... Loss: 1.129297... Val Loss:1.052801\n",
      "weight gradient of fc is tensor(1.00000e-02 *\n",
      "       [[ 0.0579,  0.3045, -0.8394,  ...,  0.3993,  0.8058, -0.7318],\n",
      "        [-0.2610, -0.1862,  1.1901,  ..., -0.2248, -0.4538, -0.0602],\n",
      "        [ 0.4171,  0.3768,  0.1644,  ..., -0.7775, -0.1596,  0.7907],\n",
      "        [-0.1301, -0.6774, -0.4600,  ...,  0.0546, -0.0538, -0.0996],\n",
      "        [-0.0838,  0.1823, -0.0551,  ...,  0.5483, -0.1386,  0.1010]], device='cuda:0'), bais gradient of fc is tensor(1.00000e-02 *\n",
      "       [ 3.1001, -0.5709, -1.3388, -0.7191, -0.4713], device='cuda:0')\n",
      "Epoch: 1/1... Step: 1100... Loss: 0.843761... Val Loss:1.039644\n",
      "weight gradient of fc is tensor([[ 7.3985e-04,  3.8647e-03, -5.3556e-03,  ..., -2.8643e-03,\n",
      "          8.4671e-04,  1.3147e-03],\n",
      "        [-6.1078e-03, -2.6413e-03, -1.1822e-02,  ...,  4.9401e-03,\n",
      "          8.6039e-03, -8.4773e-03],\n",
      "        [-1.0502e-02,  1.2078e-03, -1.1352e-03,  ..., -1.2824e-02,\n",
      "          1.9402e-04, -6.1669e-03],\n",
      "        [ 2.4987e-03, -3.9269e-03,  1.5874e-02,  ..., -4.7194e-04,\n",
      "         -4.1907e-03,  1.6794e-02],\n",
      "        [ 1.3371e-02,  1.4958e-03,  2.4391e-03,  ...,  1.1220e-02,\n",
      "         -5.4539e-03, -3.4645e-03]], device='cuda:0'), bais gradient of fc is tensor(1.00000e-02 *\n",
      "       [ 1.0264,  6.5304,  4.0953, -4.9664, -6.6857], device='cuda:0')\n",
      "Epoch: 1/1... Step: 1200... Loss: 1.162049... Val Loss:1.030397\n",
      "weight gradient of fc is tensor(1.00000e-02 *\n",
      "       [[ 0.6511,  0.3772, -0.4982,  ...,  0.0785,  0.5015, -0.6273],\n",
      "        [-1.1295, -0.7393,  0.5793,  ..., -0.6645, -0.7394,  0.5764],\n",
      "        [ 0.9591,  0.2514,  0.0834,  ...,  0.2549,  0.0333,  0.5694],\n",
      "        [-0.1949,  0.3006,  0.1832,  ...,  1.1790, -0.5150, -0.7819],\n",
      "        [-0.2858, -0.1899, -0.3478,  ..., -0.8478,  0.7196,  0.2634]], device='cuda:0'), bais gradient of fc is tensor(1.00000e-02 *\n",
      "       [ 3.1945, -2.4607, -1.1586, -2.9852,  3.4099], device='cuda:0')\n",
      "Epoch: 1/1... Step: 1300... Loss: 0.897044... Val Loss:1.030371\n",
      "weight gradient of fc is tensor([[-1.0646e-03,  3.3965e-04,  8.3496e-04,  ...,  6.5339e-04,\n",
      "          1.6223e-03, -2.7734e-03],\n",
      "        [-6.4734e-03, -9.5347e-03,  1.0245e-02,  ..., -9.6406e-03,\n",
      "         -7.6805e-03,  2.0937e-02],\n",
      "        [-1.3278e-02, -4.6559e-03, -4.6864e-03,  ..., -1.3635e-02,\n",
      "          5.8136e-03, -7.0469e-03],\n",
      "        [ 2.7210e-02,  1.9903e-02, -6.3927e-03,  ...,  3.6314e-02,\n",
      "         -2.7254e-03, -3.0001e-02],\n",
      "        [-6.3943e-03, -6.0516e-03, -9.2689e-07,  ..., -1.3692e-02,\n",
      "          2.9699e-03,  1.8884e-02]], device='cuda:0'), bais gradient of fc is tensor([ 0.0158, -0.0435,  0.0933, -0.1176,  0.0519], device='cuda:0')\n",
      "Epoch: 1/1... Step: 1400... Loss: 0.936851... Val Loss:1.020621\n",
      "weight gradient of fc is tensor([[-1.4620e-03, -2.9163e-03,  1.1540e-02,  ..., -1.2818e-03,\n",
      "         -5.7369e-03,  8.6694e-03],\n",
      "        [ 1.4708e-03,  3.4206e-03, -5.8206e-03,  ...,  4.6850e-03,\n",
      "          2.6469e-03, -1.7703e-03],\n",
      "        [ 9.1311e-03,  5.9361e-03, -6.7825e-04,  ...,  2.7175e-03,\n",
      "         -3.9333e-03,  6.6985e-03],\n",
      "        [-2.1866e-03,  2.7648e-03, -2.6696e-03,  ...,  7.5751e-03,\n",
      "          4.7065e-03, -1.2262e-02],\n",
      "        [-6.9533e-03, -9.2051e-03, -2.3714e-03,  ..., -1.3696e-02,\n",
      "          2.3167e-03, -1.3359e-03]], device='cuda:0'), bais gradient of fc is tensor(1.00000e-02 *\n",
      "       [-4.7738,  1.4700, -5.2709,  3.3568,  5.2179], device='cuda:0')\n",
      "Epoch: 1/1... Step: 1500... Loss: 0.942272... Val Loss:1.011860\n",
      "weight gradient of fc is tensor(1.00000e-02 *\n",
      "       [[ 0.9739, -0.2198,  1.5428,  ..., -1.2249, -1.3495,  1.1013],\n",
      "        [-1.5657, -0.5184, -1.1487,  ...,  1.6354,  0.2235, -1.3194],\n",
      "        [ 1.6729,  0.6806,  0.1930,  ...,  0.1371, -0.3170,  0.4787],\n",
      "        [-0.0014,  1.1015, -0.5082,  ...,  0.7875,  1.1924, -1.3274],\n",
      "        [-1.0797, -1.0439, -0.0789,  ..., -1.3351,  0.2505,  1.0668]], device='cuda:0'), bais gradient of fc is tensor(1.00000e-02 *\n",
      "       [-7.8346,  4.9886, -6.0109,  2.6057,  6.2512], device='cuda:0')\n",
      "Epoch: 1/1... Step: 1600... Loss: 1.038304... Val Loss:1.006031\n",
      "weight gradient of fc is tensor([[-5.9053e-03, -2.3415e-03, -6.9151e-03,  ..., -6.3946e-04,\n",
      "          3.3554e-03, -5.4073e-03],\n",
      "        [ 8.4865e-03,  3.9172e-03, -1.5785e-03,  ..., -8.6980e-04,\n",
      "          3.2277e-03, -4.8978e-03],\n",
      "        [ 1.9496e-02,  4.3944e-03,  7.2221e-03,  ...,  1.0300e-02,\n",
      "         -1.0099e-02,  9.5340e-03],\n",
      "        [-1.7803e-02, -4.1028e-03,  3.1470e-03,  ..., -4.4100e-03,\n",
      "         -2.4754e-03, -3.0574e-03],\n",
      "        [-4.2743e-03, -1.8672e-03, -1.8755e-03,  ..., -4.3812e-03,\n",
      "          5.9911e-03,  3.8284e-03]], device='cuda:0'), bais gradient of fc is tensor(1.00000e-02 *\n",
      "       [ 3.4037,  0.6658, -9.1519,  1.3888,  3.6936], device='cuda:0')\n",
      "Epoch: 1/1... Step: 1700... Loss: 0.828920... Val Loss:1.004089\n",
      "weight gradient of fc is tensor(1.00000e-02 *\n",
      "       [[-0.2592,  0.1061, -1.0412,  ...,  0.4187,  1.1577, -0.5757],\n",
      "        [ 0.9658, -0.1688,  0.4278,  ..., -0.6099,  0.5336, -0.2139],\n",
      "        [ 1.1583,  0.5982, -0.3486,  ...,  0.2059, -0.0793,  1.6541],\n",
      "        [-2.4738, -1.4123,  0.2890,  ..., -1.9302,  0.6016,  0.0552],\n",
      "        [ 0.6088,  0.8767,  0.6730,  ...,  1.9155, -2.2137, -0.9197]], device='cuda:0'), bais gradient of fc is tensor([ 0.0568,  0.0364, -0.0280,  0.0677, -0.1330], device='cuda:0')\n",
      "Epoch: 1/1... Step: 1800... Loss: 0.947151... Val Loss:0.986874\n",
      "weight gradient of fc is tensor(1.00000e-02 *\n",
      "       [[-0.8938, -0.4883, -1.1352,  ..., -0.3761, -0.1163,  0.0482],\n",
      "        [ 1.2410,  0.6245,  1.7767,  ...,  0.8311,  0.0212, -0.0138],\n",
      "        [ 0.1420, -0.4088,  0.8164,  ..., -1.0762, -0.8076,  0.3907],\n",
      "        [-1.2611, -0.6245, -1.2582,  ..., -0.9321,  1.8478,  0.7772],\n",
      "        [ 0.7720,  0.8971, -0.1996,  ...,  1.5533, -0.9450, -1.2024]], device='cuda:0'), bais gradient of fc is tensor(1.00000e-02 *\n",
      "       [-0.7856,  1.3926, -5.9824,  8.9598, -3.5844], device='cuda:0')\n",
      "Epoch: 1/1... Step: 1900... Loss: 1.041187... Val Loss:0.982826\n",
      "weight gradient of fc is tensor([[ 1.4964e-04, -3.6148e-03,  5.4550e-03,  ..., -4.9559e-03,\n",
      "         -7.3640e-03,  7.0799e-03],\n",
      "        [-9.3809e-03, -4.5659e-03, -2.2408e-03,  ..., -2.1462e-03,\n",
      "          5.7690e-03, -3.2262e-03],\n",
      "        [-3.7949e-03, -1.2658e-03, -1.2048e-03,  ..., -4.3255e-03,\n",
      "          1.1841e-03, -1.1367e-02],\n",
      "        [-1.0480e-03,  3.5975e-03, -4.2426e-03,  ...,  1.0134e-04,\n",
      "          5.6768e-03, -1.8058e-03],\n",
      "        [ 1.4074e-02,  5.8490e-03,  2.2333e-03,  ...,  1.1326e-02,\n",
      "         -5.2659e-03,  9.3191e-03]], device='cuda:0'), bais gradient of fc is tensor(1.00000e-02 *\n",
      "       [-3.5090,  5.9804,  2.0654, -0.6891, -3.8477], device='cuda:0')\n",
      "Epoch: 1/1... Step: 2000... Loss: 0.853661... Val Loss:0.993149\n",
      "weight gradient of fc is tensor([[-4.1591e-03, -7.8818e-04, -1.4216e-02,  ...,  1.0649e-03,\n",
      "          8.0481e-03, -1.2138e-02],\n",
      "        [ 1.5397e-03,  2.7491e-05,  1.0641e-02,  ...,  2.6387e-03,\n",
      "         -1.3731e-03,  5.9074e-03],\n",
      "        [-1.4164e-02, -9.1359e-03,  5.7654e-04,  ..., -1.3093e-02,\n",
      "          1.4232e-03,  2.5236e-03],\n",
      "        [ 1.0667e-02,  6.1962e-03, -2.3685e-03,  ...,  1.8740e-02,\n",
      "         -9.0044e-03, -2.7577e-03],\n",
      "        [ 6.1167e-03,  3.7004e-03,  5.3668e-03,  ..., -9.3499e-03,\n",
      "          9.0618e-04,  6.4649e-03]], device='cuda:0'), bais gradient of fc is tensor(1.00000e-02 *\n",
      "       [ 4.2859, -2.7137,  3.1332, -5.6991,  0.9937], device='cuda:0')\n",
      "Epoch: 1/1... Step: 2100... Loss: 1.002107... Val Loss:0.975735\n",
      "weight gradient of fc is tensor(1.00000e-02 *\n",
      "       [[-0.5293, -0.7149,  1.1809,  ..., -0.5940, -0.5520,  0.6155],\n",
      "        [ 0.6046, -0.0281,  0.3133,  ..., -0.2313, -0.4233,  1.1673],\n",
      "        [ 0.0236,  0.3723, -0.7554,  ..., -0.3837,  0.2941, -0.5764],\n",
      "        [-0.4468, -0.2446, -0.6055,  ...,  0.3219,  1.3028, -0.7526],\n",
      "        [ 0.3480,  0.6153, -0.1332,  ...,  0.8871, -0.6217, -0.4539]], device='cuda:0'), bais gradient of fc is tensor(1.00000e-02 *\n",
      "       [-2.9423, -3.1469,  2.3710,  5.5501, -1.8318], device='cuda:0')\n",
      "Epoch: 1/1... Step: 2200... Loss: 0.791678... Val Loss:0.968400\n",
      "weight gradient of fc is tensor(1.00000e-02 *\n",
      "       [[-0.0912,  0.1589,  0.8542,  ..., -0.0217, -0.8817,  0.0694],\n",
      "        [-0.5838, -0.2294, -1.0717,  ..., -0.0817,  1.1916, -0.1719],\n",
      "        [-0.3053,  0.0905, -0.3638,  ..., -0.2611,  0.6482, -0.2823],\n",
      "        [ 0.8899, -0.6158,  0.7743,  ..., -0.3048, -0.6994,  0.6991],\n",
      "        [ 0.0904,  0.5957, -0.1930,  ...,  0.6694, -0.2588, -0.3143]], device='cuda:0'), bais gradient of fc is tensor(1.00000e-02 *\n",
      "       [-4.5055,  6.3682,  4.7314, -1.7914, -4.8028], device='cuda:0')\n",
      "Epoch: 1/1... Step: 2300... Loss: 0.886904... Val Loss:0.966440\n",
      "weight gradient of fc is tensor(1.00000e-02 *\n",
      "       [[ 0.3383, -0.8103,  0.9897,  ..., -1.2319, -0.6282,  0.9235],\n",
      "        [ 0.9014,  1.1335, -0.4876,  ...,  1.6132,  0.5116, -0.9211],\n",
      "        [-0.0667,  0.2799, -0.2936,  ...,  0.6270,  0.1374, -0.2162],\n",
      "        [-0.9053, -0.3291, -0.1822,  ..., -0.4615, -0.1914, -0.0235],\n",
      "        [-0.2678, -0.2740, -0.0264,  ..., -0.5468,  0.1705,  0.2374]], device='cuda:0'), bais gradient of fc is tensor(1.00000e-02 *\n",
      "       [-2.9607,  1.1647,  2.8134, -0.4126, -0.6048], device='cuda:0')\n",
      "Epoch: 1/1... Step: 2400... Loss: 0.961578... Val Loss:0.952129\n",
      "weight gradient of fc is tensor(1.00000e-02 *\n",
      "       [[-0.2401,  1.0998, -0.4333,  ...,  0.6226, -1.0687, -0.1765],\n",
      "        [ 0.6083, -0.0403,  0.4167,  ...,  0.8933,  0.7727, -0.8979],\n",
      "        [ 0.3782,  0.0416,  0.3022,  ..., -0.1251,  0.0245, -0.9863],\n",
      "        [ 0.8493,  1.2450, -0.0071,  ...,  1.6880, -0.9152, -0.3744],\n",
      "        [-1.5956, -2.3460, -0.2785,  ..., -3.0789,  1.1868,  2.4351]], device='cuda:0'), bais gradient of fc is tensor([-0.0390,  0.0024,  0.0026, -0.0927,  0.1268], device='cuda:0')\n",
      "Epoch: 1/1... Step: 2500... Loss: 1.302134... Val Loss:0.956753\n",
      "weight gradient of fc is tensor(1.00000e-02 *\n",
      "       [[-1.3167, -0.3810,  0.3583,  ..., -0.2270, -0.5873,  0.4533],\n",
      "        [-0.6361,  0.8025, -1.0502,  ...,  1.0389,  0.4161, -1.1792],\n",
      "        [-0.7381, -0.3197, -0.6413,  ..., -0.1613,  0.2409, -0.7395],\n",
      "        [ 1.7872, -0.2293,  1.1490,  ..., -1.8819,  0.5844,  2.3306],\n",
      "        [ 0.9038,  0.1275,  0.1842,  ...,  1.2312, -0.6541, -0.8653]], device='cuda:0'), bais gradient of fc is tensor(1.00000e-02 *\n",
      "       [-1.3969, -2.3487,  5.2896,  2.2936, -3.8376], device='cuda:0')\n",
      "Epoch: 1/1... Step: 2600... Loss: 0.940527... Val Loss:0.936401\n",
      "weight gradient of fc is tensor(1.00000e-02 *\n",
      "       [[-0.8482, -0.7261,  0.8479,  ...,  0.1621, -0.2611,  0.2649],\n",
      "        [ 1.7764,  0.8519, -0.9089,  ...,  1.2636,  1.1932, -0.3086],\n",
      "        [ 0.1182,  0.0892,  0.3462,  ..., -0.9390, -0.5213,  1.0015],\n",
      "        [-0.9558, -0.6410, -0.2888,  ..., -0.3584,  0.1368, -0.5868],\n",
      "        [-0.0906,  0.4260,  0.0036,  ..., -0.1283, -0.5477, -0.3710]], device='cuda:0'), bais gradient of fc is tensor(1.00000e-02 *\n",
      "       [-1.3088,  2.1172, -5.9369,  6.7541, -1.6255], device='cuda:0')\n",
      "Epoch: 1/1... Step: 2700... Loss: 0.977531... Val Loss:0.931377\n",
      "weight gradient of fc is tensor(1.00000e-02 *\n",
      "       [[ 0.2572,  1.2181, -2.2014,  ...,  1.0225,  0.4434, -1.4168],\n",
      "        [-0.5618, -0.9746,  1.5414,  ...,  0.3511, -0.6119, -0.0689],\n",
      "        [ 1.2167, -0.0707,  0.2087,  ..., -0.7238,  0.1240,  0.7438],\n",
      "        [-1.0050, -0.4099, -0.0921,  ..., -0.0999, -0.0737, -0.5797],\n",
      "        [ 0.0929,  0.2371,  0.5435,  ..., -0.5499,  0.1182,  1.3216]], device='cuda:0'), bais gradient of fc is tensor(1.00000e-02 *\n",
      "       [ 2.7161, -0.8289, -2.3164,  2.8610, -2.4319], device='cuda:0')\n",
      "Epoch: 1/1... Step: 2800... Loss: 0.954187... Val Loss:0.929726\n",
      "weight gradient of fc is tensor([[ 1.8564e-03, -2.4082e-03,  2.5309e-03,  ...,  1.1565e-04,\n",
      "          2.5420e-03, -1.4705e-04],\n",
      "        [-3.7030e-03,  1.5530e-03, -1.2712e-02,  ...,  3.9247e-03,\n",
      "          9.1447e-03, -5.4565e-03],\n",
      "        [-3.3072e-03, -5.3301e-03,  1.2126e-02,  ..., -7.1335e-03,\n",
      "         -3.9237e-03,  1.4498e-02],\n",
      "        [-1.1579e-02, -6.8577e-03, -2.7106e-03,  ..., -3.2440e-02,\n",
      "          8.7240e-03,  1.1946e-02],\n",
      "        [ 1.6733e-02,  1.3043e-02,  7.6549e-04,  ...,  3.5533e-02,\n",
      "         -1.6487e-02, -2.0841e-02]], device='cuda:0'), bais gradient of fc is tensor([ 0.0155,  0.0564, -0.0093,  0.0652, -0.1277], device='cuda:0')\n",
      "Epoch: 1/1... Step: 2900... Loss: 0.824519... Val Loss:0.929680\n",
      "weight gradient of fc is tensor(1.00000e-02 *\n",
      "       [[ 0.1731,  0.2224, -0.7440,  ...,  0.5190,  0.4199, -0.4151],\n",
      "        [ 0.6500, -0.3795,  0.0453,  ..., -1.1162,  0.3236,  0.9476],\n",
      "        [-1.0136, -0.3865, -0.9245,  ...,  0.1682,  0.7829, -1.0720],\n",
      "        [ 0.5680,  0.7483,  1.7987,  ...,  1.5040, -1.7160, -0.4259],\n",
      "        [-0.3775, -0.2047, -0.1755,  ..., -1.0750,  0.1896,  0.9653]], device='cuda:0'), bais gradient of fc is tensor([ 0.0203,  0.0344,  0.0562, -0.1112,  0.0003], device='cuda:0')\n",
      "Epoch: 1/1... Step: 3000... Loss: 0.853297... Val Loss:0.923322\n",
      "weight gradient of fc is tensor(1.00000e-02 *\n",
      "       [[ 0.1021,  0.2440, -2.3049,  ...,  0.5580,  1.1457, -1.3151],\n",
      "        [-0.5683,  1.6217,  0.5671,  ...,  0.4585, -1.3487, -0.6412],\n",
      "        [ 0.6064,  0.2169, -0.2630,  ..., -0.0299,  0.9023, -0.1818],\n",
      "        [-0.4373, -0.2715,  2.3561,  ...,  0.9064, -1.7497,  0.8609],\n",
      "        [ 0.2971, -1.8110, -0.3552,  ..., -1.8930,  1.0505,  1.2772]], device='cuda:0'), bais gradient of fc is tensor(1.00000e-02 *\n",
      "       [ 3.5513, -6.9893,  2.2603, -6.7591,  7.9368], device='cuda:0')\n",
      "Epoch: 1/1... Step: 3100... Loss: 0.974126... Val Loss:0.928455\n",
      "weight gradient of fc is tensor(1.00000e-02 *\n",
      "       [[ 0.8422, -0.0018,  0.3654,  ..., -0.4230, -0.2151, -0.0285],\n",
      "        [-0.1500, -0.2090, -0.3336,  ...,  0.1620, -0.3073,  0.2839],\n",
      "        [ 0.8916,  0.6375,  0.4525,  ...,  0.2460, -0.0127, -0.0894],\n",
      "        [-2.3533, -1.2827, -0.8259,  ..., -0.4380,  0.0561, -0.5866],\n",
      "        [ 0.7696,  0.8560,  0.3416,  ...,  0.4530,  0.4789,  0.4207]], device='cuda:0'), bais gradient of fc is tensor(1.00000e-02 *\n",
      "       [ 1.3382, -1.7888, -3.2270,  2.1233,  1.5543], device='cuda:0')\n",
      "Epoch: 1/1... Step: 3200... Loss: 0.831477... Val Loss:0.914156\n",
      "weight gradient of fc is tensor(1.00000e-02 *\n",
      "       [[-0.7903, -0.9264,  0.3753,  ..., -0.4864, -0.5308,  0.8353],\n",
      "        [ 1.6657,  0.4776,  1.1426,  ..., -0.9466, -0.2839,  0.1259],\n",
      "        [-1.2448, -0.9916,  0.0799,  ...,  0.0594,  0.3487, -0.7203],\n",
      "        [ 1.5919,  2.2580, -1.2430,  ...,  1.5330, -0.1752,  0.1286],\n",
      "        [-1.2226, -0.8176, -0.3548,  ..., -0.1594,  0.6412, -0.3695]], device='cuda:0'), bais gradient of fc is tensor(1.00000e-02 *\n",
      "       [-1.8940,  0.0926,  5.5029, -6.7158,  3.0143], device='cuda:0')\n",
      "Epoch: 1/1... Step: 3300... Loss: 0.880559... Val Loss:0.915308\n",
      "weight gradient of fc is tensor([[ 1.3590e-02,  1.3354e-02, -1.1223e-02,  ...,  9.8105e-03,\n",
      "          6.3379e-03, -1.2194e-02],\n",
      "        [-1.8178e-02, -1.6266e-02,  2.2581e-03,  ..., -1.1057e-02,\n",
      "          5.8469e-04,  1.9092e-02],\n",
      "        [ 7.0323e-03, -7.7549e-04,  2.7466e-03,  ..., -4.8465e-03,\n",
      "         -3.0838e-03, -1.3141e-02],\n",
      "        [ 1.9852e-03,  1.3453e-02,  8.1209e-03,  ...,  1.6919e-02,\n",
      "         -1.0677e-02, -1.9027e-03],\n",
      "        [-4.4289e-03, -9.7656e-03, -1.9025e-03,  ..., -1.0826e-02,\n",
      "          6.8386e-03,  8.1453e-03]], device='cuda:0'), bais gradient of fc is tensor(1.00000e-02 *\n",
      "       [ 3.9730, -1.1498, -1.1371, -8.1236,  6.4375], device='cuda:0')\n",
      "Epoch: 1/1... Step: 3400... Loss: 0.965339... Val Loss:0.909794\n",
      "weight gradient of fc is tensor([[-3.9835e-03,  2.5425e-03, -8.0322e-03,  ...,  7.4752e-03,\n",
      "          6.0398e-03, -3.3089e-03],\n",
      "        [-4.9777e-03, -7.1902e-06,  7.4152e-03,  ..., -1.0802e-02,\n",
      "         -3.3367e-03, -1.8694e-03],\n",
      "        [ 7.9566e-03,  5.7959e-03, -6.1199e-04,  ..., -5.5035e-04,\n",
      "          1.3704e-03, -1.8925e-03],\n",
      "        [ 2.3266e-03, -6.3427e-03,  3.1499e-03,  ...,  2.1015e-02,\n",
      "         -7.5695e-03, -7.2715e-03],\n",
      "        [-1.3220e-03, -1.9885e-03, -1.9210e-03,  ..., -1.7138e-02,\n",
      "          3.4960e-03,  1.4342e-02]], device='cuda:0'), bais gradient of fc is tensor(1.00000e-02 *\n",
      "       [ 2.4317, -0.6631, -0.9736,  0.0332, -0.8282], device='cuda:0')\n",
      "Epoch: 1/1... Step: 3500... Loss: 0.804858... Val Loss:0.902415\n",
      "weight gradient of fc is tensor(1.00000e-02 *\n",
      "       [[ 0.9499,  1.0603, -1.6621,  ...,  0.2872,  0.0580, -0.7060],\n",
      "        [-0.3858, -1.1230,  1.9928,  ..., -1.1139, -0.2256,  1.5445],\n",
      "        [ 0.2886,  1.3107,  0.5810,  ...,  0.7216, -0.7094, -0.3168],\n",
      "        [-1.2041,  0.1808, -0.9965,  ...,  0.8023,  0.3992, -1.1206],\n",
      "        [ 0.3514, -1.4288,  0.0849,  ..., -0.6973,  0.4777,  0.5989]], device='cuda:0'), bais gradient of fc is tensor(1.00000e-02 *\n",
      "       [-0.5852, -0.0572, -6.8492,  3.3353,  4.1563], device='cuda:0')\n",
      "Epoch: 1/1... Step: 3600... Loss: 0.928521... Val Loss:0.899451\n",
      "weight gradient of fc is tensor(1.00000e-02 *\n",
      "       [[ 0.1255, -0.2445, -0.5995,  ...,  0.1577, -0.1587,  0.2683],\n",
      "        [ 0.0564, -0.8895,  0.5839,  ..., -0.8681,  0.1254,  0.8588],\n",
      "        [-0.4692, -0.1594,  0.4585,  ..., -0.0009, -0.2616, -0.0578],\n",
      "        [ 0.4138,  0.5191, -0.3312,  ..., -0.5392,  0.3450,  0.0433],\n",
      "        [-0.1266,  0.7743, -0.1118,  ...,  1.2505, -0.0502, -1.1127]], device='cuda:0'), bais gradient of fc is tensor(1.00000e-02 *\n",
      "       [-2.4626,  1.0212,  1.5978,  2.9834, -3.1397], device='cuda:0')\n",
      "Epoch: 1/1... Step: 3700... Loss: 0.771086... Val Loss:0.896889\n",
      "weight gradient of fc is tensor(1.00000e-02 *\n",
      "       [[ 0.0725,  0.1228, -0.5967,  ..., -0.2112,  0.3939, -0.3602],\n",
      "        [ 0.6998,  0.4530,  0.0449,  ...,  0.5553, -0.0001, -0.7473],\n",
      "        [ 1.4571,  0.2234,  0.7093,  ...,  0.3291, -0.1451,  1.5061],\n",
      "        [-1.5610, -0.3413,  0.0942,  ..., -0.6294, -0.2021, -0.4660],\n",
      "        [-0.6685, -0.4579, -0.2516,  ..., -0.0438, -0.0466,  0.0674]], device='cuda:0'), bais gradient of fc is tensor(1.00000e-02 *\n",
      "       [ 1.7664,  1.8023, -9.5041,  5.2816,  0.6538], device='cuda:0')\n",
      "Epoch: 1/1... Step: 3800... Loss: 0.804765... Val Loss:0.892418\n",
      "weight gradient of fc is tensor([[ 5.8505e-04,  1.8329e-03,  1.7821e-03,  ..., -6.0861e-03,\n",
      "         -5.2699e-03, -8.3250e-04],\n",
      "        [ 3.0400e-03, -1.2792e-03,  3.2179e-03,  ...,  4.9136e-03,\n",
      "          3.1151e-03,  4.7950e-04],\n",
      "        [-8.6902e-03, -3.3081e-03, -4.1719e-03,  ..., -3.2918e-03,\n",
      "          5.1251e-03, -7.3139e-03],\n",
      "        [ 6.8608e-03, -1.8617e-03,  7.5692e-04,  ..., -1.4869e-02,\n",
      "         -4.6711e-04,  1.9870e-02],\n",
      "        [-1.7956e-03,  4.6161e-03, -1.5850e-03,  ...,  1.9333e-02,\n",
      "         -2.5031e-03, -1.2203e-02]], device='cuda:0'), bais gradient of fc is tensor(1.00000e-02 *\n",
      "       [-0.3940,  2.0188,  5.2343, -1.1278, -5.7314], device='cuda:0')\n",
      "Epoch: 1/1... Step: 3900... Loss: 0.840335... Val Loss:0.891798\n",
      "weight gradient of fc is tensor(1.00000e-02 *\n",
      "       [[ 0.0832,  0.5680, -1.0111,  ...,  1.4854,  0.7660, -0.9323],\n",
      "        [-0.2858, -0.7430,  0.8047,  ..., -0.7621, -0.3761,  1.5353],\n",
      "        [-0.3819, -0.2444, -0.7568,  ..., -0.0131,  0.7619, -0.3072],\n",
      "        [ 0.2935,  1.0554,  0.5922,  ..., -0.4927, -0.7305,  0.3099],\n",
      "        [ 0.2910, -0.6360,  0.3710,  ..., -0.2175, -0.4214, -0.6057]], device='cuda:0'), bais gradient of fc is tensor(1.00000e-02 *\n",
      "       [-0.0439, -2.8232,  4.6447,  1.7551, -3.5327], device='cuda:0')\n",
      "Epoch: 1/1... Step: 4000... Loss: 0.997974... Val Loss:0.897117\n",
      "weight gradient of fc is tensor([[ 2.8245e-03, -2.2511e-03,  1.1763e-02,  ...,  2.9372e-03,\n",
      "         -3.8152e-04,  3.3926e-03],\n",
      "        [ 1.9942e-03, -1.6753e-03,  5.8265e-03,  ...,  1.2528e-03,\n",
      "          1.0181e-03,  8.5662e-03],\n",
      "        [ 1.0480e-02,  1.1743e-03, -4.8975e-03,  ...,  2.9202e-03,\n",
      "         -2.0260e-03, -6.5474e-03],\n",
      "        [-2.6413e-02,  5.6369e-03, -1.2945e-02,  ...,  7.9827e-03,\n",
      "          2.2602e-03, -1.3109e-02],\n",
      "        [ 1.1114e-02, -2.8848e-03,  2.5336e-04,  ..., -1.5093e-02,\n",
      "         -8.7082e-04,  7.6972e-03]], device='cuda:0'), bais gradient of fc is tensor(1.00000e-02 *\n",
      "       [-0.0876, -1.2432, -2.4561, -0.6657,  4.4525], device='cuda:0')\n",
      "Epoch: 1/1... Step: 4100... Loss: 0.954527... Val Loss:0.883348\n",
      "weight gradient of fc is tensor(1.00000e-02 *\n",
      "       [[-0.3739, -0.2329,  1.6203,  ..., -0.2577, -0.1066,  0.9468],\n",
      "        [ 0.0746, -0.8877,  0.3427,  ..., -1.2069, -0.7738,  0.4810],\n",
      "        [-0.2297, -0.0364, -0.6621,  ...,  0.1895,  0.3242, -0.0438],\n",
      "        [ 1.5115,  0.3800, -0.9580,  ..., -0.2406,  0.9665,  0.7688],\n",
      "        [-0.9824,  0.7769, -0.3429,  ...,  1.5156, -0.4103, -2.1528]], device='cuda:0'), bais gradient of fc is tensor([ 0.0075, -0.0323, -0.0144,  0.1020, -0.0629], device='cuda:0')\n",
      "Epoch: 1/1... Step: 4200... Loss: 0.657358... Val Loss:0.885568\n",
      "weight gradient of fc is tensor(1.00000e-02 *\n",
      "       [[-0.8144, -1.2395,  0.3536,  ..., -0.1193,  0.1560,  0.3783],\n",
      "        [ 1.4368,  0.4551,  0.7120,  ..., -1.3121, -0.5377,  0.6849],\n",
      "        [ 0.4193,  0.5699, -0.6628,  ...,  0.8410,  0.4365,  0.0015],\n",
      "        [-0.5883,  0.0084, -0.3415,  ...,  0.6478, -0.4960, -0.1676],\n",
      "        [-0.4534,  0.2061, -0.0614,  ..., -0.0574,  0.4412, -0.8971]], device='cuda:0'), bais gradient of fc is tensor(1.00000e-02 *\n",
      "       [ 2.7545,  0.2961, -0.8234, -2.9992,  0.7720], device='cuda:0')\n",
      "Epoch: 1/1... Step: 4300... Loss: 0.843640... Val Loss:0.887282\n",
      "weight gradient of fc is tensor([[ 2.2761e-03,  1.3947e-04, -9.8560e-03,  ...,  5.3663e-03,\n",
      "          5.4118e-03, -2.4630e-03],\n",
      "        [ 3.0362e-04, -4.7629e-03, -1.6375e-02,  ...,  1.1419e-02,\n",
      "          1.0042e-02, -1.1356e-02],\n",
      "        [ 1.5376e-03,  2.3287e-03,  1.5212e-02,  ..., -1.7956e-02,\n",
      "         -6.0075e-03,  7.5935e-03],\n",
      "        [-1.2925e-02, -4.4484e-03,  1.2386e-02,  ..., -1.2910e-02,\n",
      "         -1.8223e-03,  1.1752e-02],\n",
      "        [ 8.8080e-03,  6.7431e-03, -1.3672e-03,  ...,  1.4081e-02,\n",
      "         -7.6237e-03, -5.5264e-03]], device='cuda:0'), bais gradient of fc is tensor(1.00000e-02 *\n",
      "       [-0.7015,  8.0148, -1.7551, -4.4478, -1.1104], device='cuda:0')\n",
      "Epoch: 1/1... Step: 4400... Loss: 0.867286... Val Loss:0.872954\n",
      "weight gradient of fc is tensor([[ 3.9115e-03,  1.2302e-03, -4.7975e-03,  ...,  5.4080e-03,\n",
      "          3.9503e-03, -8.4211e-03],\n",
      "        [-1.9859e-02, -2.0352e-03,  1.1607e-02,  ..., -7.9838e-03,\n",
      "         -4.2138e-03,  1.5809e-02],\n",
      "        [-6.5463e-03, -1.1893e-02,  2.8012e-03,  ..., -3.0283e-03,\n",
      "          2.7647e-03, -6.1648e-03],\n",
      "        [ 9.1811e-03, -1.6052e-04, -8.0494e-03,  ...,  1.5064e-03,\n",
      "         -2.6852e-03,  1.7742e-03],\n",
      "        [ 1.3312e-02,  1.2859e-02, -1.5609e-03,  ...,  4.0976e-03,\n",
      "          1.8391e-04, -2.9969e-03]], device='cuda:0'), bais gradient of fc is tensor(1.00000e-02 *\n",
      "       [ 2.8161, -1.6958, -0.3336,  2.4797, -3.2663], device='cuda:0')\n",
      "Epoch: 1/1... Step: 4500... Loss: 0.890473... Val Loss:0.878127\n",
      "weight gradient of fc is tensor(1.00000e-02 *\n",
      "       [[-1.1041, -0.4487, -0.8126,  ...,  0.1526,  0.3557, -0.9275],\n",
      "        [ 2.4654,  0.9348, -0.2952,  ...,  1.8191,  0.0847, -0.4517],\n",
      "        [ 0.1394, -0.6403,  1.5316,  ..., -1.5334, -0.6572,  0.7365],\n",
      "        [-1.1023, -0.3855, -0.0587,  ..., -0.2987,  0.3719,  0.5637],\n",
      "        [-0.3983,  0.5398, -0.3651,  ..., -0.1396, -0.1551,  0.0790]], device='cuda:0'), bais gradient of fc is tensor(1.00000e-02 *\n",
      "       [ 2.6966, -1.2049, -2.4659,  3.9023, -2.9280], device='cuda:0')\n",
      "Epoch: 1/1... Step: 4600... Loss: 0.840239... Val Loss:0.867309\n",
      "weight gradient of fc is tensor(1.00000e-02 *\n",
      "       [[ 0.3738,  0.0928,  1.3680,  ...,  0.1116, -0.1425,  0.0108],\n",
      "        [-0.2211,  1.1386,  0.3958,  ...,  0.1362, -0.3808, -0.3033],\n",
      "        [-0.2056, -1.0654, -0.1795,  ..., -0.1180, -0.0642,  0.0283],\n",
      "        [ 0.3525, -0.5923, -1.5577,  ..., -0.5543,  0.4148,  0.6559],\n",
      "        [-0.2996,  0.4263, -0.0264,  ...,  0.4245,  0.1727, -0.3917]], device='cuda:0'), bais gradient of fc is tensor(1.00000e-02 *\n",
      "       [ 1.9791, -3.8704,  4.2146, -2.8320,  0.5088], device='cuda:0')\n",
      "Epoch: 1/1... Step: 4700... Loss: 0.942752... Val Loss:0.864938\n",
      "weight gradient of fc is tensor(1.00000e-02 *\n",
      "       [[-0.1424, -0.2405,  0.7911,  ...,  0.0857, -0.1942,  0.5682],\n",
      "        [-1.2804, -0.8506, -0.6612,  ..., -0.8601,  0.0550, -1.4302],\n",
      "        [ 1.2648,  0.7355, -0.1403,  ...,  0.2279, -0.2507,  0.0293],\n",
      "        [-2.2266,  1.3191, -0.2544,  ...,  0.7097, -0.1525, -1.3532],\n",
      "        [ 2.3845, -0.9634,  0.2648,  ..., -0.1632,  0.5424,  2.1860]], device='cuda:0'), bais gradient of fc is tensor(1.00000e-02 *\n",
      "       [-0.0911,  0.3006, -2.6711,  0.9835,  1.4780], device='cuda:0')\n",
      "Epoch: 1/1... Step: 4800... Loss: 0.866715... Val Loss:0.864424\n",
      "weight gradient of fc is tensor(1.00000e-02 *\n",
      "       [[-0.3338,  0.1058,  0.4979,  ...,  0.6031, -0.0606, -0.0106],\n",
      "        [ 1.5455,  0.5574, -0.3837,  ..., -0.7105, -0.5281,  0.8030],\n",
      "        [-2.2790, -0.7904,  1.2654,  ..., -0.4137,  0.4114,  0.2087],\n",
      "        [ 2.3876,  1.9511, -1.0073,  ...,  1.5341, -0.3315, -1.1300],\n",
      "        [-1.3203, -1.8239, -0.3724,  ..., -1.0130,  0.5088,  0.1289]], device='cuda:0'), bais gradient of fc is tensor(1.00000e-02 *\n",
      "       [ 0.5626, -5.1966,  1.4887, -2.8892,  6.0345], device='cuda:0')\n",
      "Epoch: 1/1... Step: 4900... Loss: 0.879318... Val Loss:0.868074\n",
      "weight gradient of fc is tensor(1.00000e-02 *\n",
      "       [[ 0.1366,  0.4632, -0.6159,  ...,  1.1743,  0.0394,  0.8324],\n",
      "        [-0.5013, -0.2347,  0.4221,  ..., -1.3244, -0.1338, -0.3136],\n",
      "        [ 0.4623,  1.4200,  0.3603,  ..., -0.1947, -0.1469, -1.1654],\n",
      "        [-0.2813, -0.9732, -0.1929,  ...,  1.0479, -0.4187, -0.5623],\n",
      "        [ 0.1837, -0.6753,  0.0263,  ..., -0.7031,  0.6599,  1.2090]], device='cuda:0'), bais gradient of fc is tensor(1.00000e-02 *\n",
      "       [-3.2604,  2.7156,  2.4382, -7.2549,  5.3615], device='cuda:0')\n",
      "Epoch: 1/1... Step: 5000... Loss: 0.781852... Val Loss:0.860917\n",
      "weight gradient of fc is tensor(1.00000e-02 *\n",
      "       [[-0.1368, -0.3768, -1.0137,  ...,  0.4258,  0.0572, -0.4245],\n",
      "        [-0.9522, -0.6210,  0.4977,  ..., -0.6395, -0.0514,  0.7733],\n",
      "        [ 0.9125,  0.1308, -0.0801,  ...,  0.8011, -0.0340, -1.1463],\n",
      "        [ 0.2040,  1.1795,  0.3451,  ...,  1.2422,  0.1007, -0.7759],\n",
      "        [-0.0275, -0.3125,  0.2510,  ..., -1.8295, -0.0725,  1.5735]], device='cuda:0'), bais gradient of fc is tensor(1.00000e-02 *\n",
      "       [ 2.6599,  0.5599, -2.5453, -1.6889,  1.0145], device='cuda:0')\n",
      "Epoch: 1/1... Step: 5100... Loss: 0.827506... Val Loss:0.858925\n",
      "weight gradient of fc is tensor([[-7.1664e-03, -3.2044e-03, -2.6370e-03,  ..., -1.2058e-02,\n",
      "         -3.7496e-03,  3.4873e-03],\n",
      "        [ 1.3255e-04,  1.1683e-02,  9.4933e-03,  ...,  1.7832e-02,\n",
      "         -1.2004e-03, -7.3849e-03],\n",
      "        [-2.8334e-03, -1.0069e-02, -5.9439e-03,  ...,  2.6061e-03,\n",
      "          2.1253e-03,  8.6825e-03],\n",
      "        [-1.1434e-03,  1.9483e-02, -1.4624e-03,  ...,  5.4503e-03,\n",
      "         -2.5234e-03, -1.4973e-02],\n",
      "        [ 1.1011e-02, -1.7893e-02,  5.5002e-04,  ..., -1.3831e-02,\n",
      "          5.3481e-03,  1.0188e-02]], device='cuda:0'), bais gradient of fc is tensor(1.00000e-02 *\n",
      "       [-0.3936, -0.8525,  0.8264, -3.2008,  3.6206], device='cuda:0')\n",
      "Epoch: 1/1... Step: 5200... Loss: 0.871196... Val Loss:0.861425\n",
      "weight gradient of fc is tensor(1.00000e-02 *\n",
      "       [[ 1.0284,  0.6540, -1.2452,  ...,  1.0816,  1.1842, -1.3147],\n",
      "        [ 0.2527, -0.1022,  0.9701,  ..., -1.3799, -0.0955,  1.4075],\n",
      "        [-0.7499, -0.4759,  1.6871,  ..., -1.1720, -0.3768,  0.0292],\n",
      "        [ 0.0727,  2.1807, -1.1943,  ...,  3.0744, -1.0573, -0.0651],\n",
      "        [-0.6040, -2.2566, -0.2176,  ..., -1.6042,  0.3454, -0.0569]], device='cuda:0'), bais gradient of fc is tensor(1.00000e-02 *\n",
      "       [ 2.4104,  0.4062, -2.0461, -8.2198,  7.4494], device='cuda:0')\n",
      "Epoch: 1/1... Step: 5300... Loss: 0.810095... Val Loss:0.853396\n",
      "weight gradient of fc is tensor(1.00000e-02 *\n",
      "       [[ 0.8236,  0.2726, -0.3139,  ..., -0.5579, -0.1725,  0.2445],\n",
      "        [ 0.4874, -0.2953, -0.5118,  ...,  1.0505,  0.8363, -1.5737],\n",
      "        [-0.5736,  0.1083, -0.4768,  ...,  0.8724, -0.1357, -0.0634],\n",
      "        [-1.6884, -1.9636,  1.2307,  ..., -3.1842,  0.0665,  2.6683],\n",
      "        [ 0.9510,  1.8780,  0.0717,  ...,  1.8192, -0.5946, -1.2756]], device='cuda:0'), bais gradient of fc is tensor(1.00000e-02 *\n",
      "       [ 1.2732,  8.2413, -0.5910, -1.2071, -7.7164], device='cuda:0')\n",
      "Epoch: 1/1... Step: 5400... Loss: 0.779755... Val Loss:0.854307\n",
      "weight gradient of fc is tensor(1.00000e-02 *\n",
      "       [[ 0.3304,  0.9054,  0.3468,  ..., -0.6492, -0.4672,  0.4088],\n",
      "        [ 0.0235, -0.3186,  0.0644,  ...,  0.0579,  0.2029,  0.2394],\n",
      "        [ 1.0040,  1.0664, -0.1322,  ...,  0.5203, -0.1286, -0.4873],\n",
      "        [ 0.0373, -0.7787, -0.1413,  ..., -1.4707,  0.5624,  1.1688],\n",
      "        [-1.3952, -0.8745, -0.1377,  ...,  1.5417, -0.1695, -1.3297]], device='cuda:0'), bais gradient of fc is tensor(1.00000e-02 *\n",
      "       [-1.6012, -1.3481, -0.1930,  5.4035, -2.2612], device='cuda:0')\n",
      "Epoch: 1/1... Step: 5500... Loss: 0.844127... Val Loss:0.850111\n",
      "weight gradient of fc is tensor([[-9.5817e-03, -2.8134e-03,  1.9947e-02,  ..., -1.5615e-02,\n",
      "         -1.3744e-02,  1.1325e-02],\n",
      "        [-6.0876e-03,  3.1549e-03, -1.2945e-02,  ...,  3.2939e-03,\n",
      "          6.8156e-04, -2.2548e-02],\n",
      "        [ 2.9036e-03,  5.7589e-03,  6.2554e-03,  ..., -5.1999e-03,\n",
      "          1.0256e-03,  1.4434e-02],\n",
      "        [ 1.2240e-02,  7.3612e-03, -1.2734e-02,  ...,  2.3290e-02,\n",
      "          4.4375e-03, -7.6612e-03],\n",
      "        [ 5.2600e-04, -1.3462e-02, -5.2337e-04,  ..., -5.7686e-03,\n",
      "          7.5991e-03,  4.4499e-03]], device='cuda:0'), bais gradient of fc is tensor(1.00000e-02 *\n",
      "       [-6.0969,  2.7722, -5.9073,  8.2560,  0.9760], device='cuda:0')\n",
      "Epoch: 1/1... Step: 5600... Loss: 0.897216... Val Loss:0.847371\n",
      "weight gradient of fc is tensor([[ 1.7830e-03,  5.0573e-03, -4.5596e-03,  ...,  9.9622e-04,\n",
      "         -1.9123e-03,  6.2156e-04],\n",
      "        [ 8.0605e-03, -1.7854e-02,  9.9728e-03,  ..., -6.5727e-03,\n",
      "          4.8606e-03,  5.3168e-03],\n",
      "        [-2.3462e-02,  5.4368e-03, -6.5128e-03,  ...,  1.7787e-03,\n",
      "          2.8868e-03, -1.1719e-02],\n",
      "        [ 1.1080e-02,  1.8482e-02, -1.6754e-03,  ...,  2.4957e-02,\n",
      "         -5.4928e-03, -3.7653e-03],\n",
      "        [ 2.5377e-03, -1.1122e-02,  2.7750e-03,  ..., -2.1159e-02,\n",
      "         -3.4246e-04,  9.5456e-03]], device='cuda:0'), bais gradient of fc is tensor(1.00000e-02 *\n",
      "       [ 0.4920,  3.5629, -0.7766, -7.7322,  4.4540], device='cuda:0')\n",
      "Epoch: 1/1... Step: 5700... Loss: 0.874555... Val Loss:0.854868\n",
      "weight gradient of fc is tensor(1.00000e-02 *\n",
      "       [[ 1.1806,  0.5391, -0.9155,  ...,  0.6748, -0.0299, -0.7419],\n",
      "        [-1.3602, -1.1319,  1.5391,  ..., -2.1237, -0.1554,  1.4660],\n",
      "        [-0.9349, -0.5053, -1.6138,  ...,  1.0537, -0.7911,  0.7442],\n",
      "        [ 1.2111,  1.1961,  0.9746,  ..., -0.2025,  0.4714,  0.6150],\n",
      "        [-0.0967, -0.0980,  0.0157,  ...,  0.5977,  0.5050, -2.0832]], device='cuda:0'), bais gradient of fc is tensor(1.00000e-02 *\n",
      "       [ 0.9813,  0.6051, -5.8694,  5.6863, -1.4033], device='cuda:0')\n",
      "Epoch: 1/1... Step: 5800... Loss: 1.063607... Val Loss:0.843450\n",
      "weight gradient of fc is tensor(1.00000e-02 *\n",
      "       [[-0.0757, -0.5257,  0.1861,  ..., -0.0231,  0.4096, -0.2360],\n",
      "        [ 0.0837,  0.2300, -0.4228,  ..., -0.8529, -0.2600,  0.0626],\n",
      "        [-0.2466,  0.0256, -0.3078,  ...,  0.1678, -0.1807, -0.7738],\n",
      "        [ 0.3285,  0.6969,  0.7865,  ...,  0.3318,  0.3412,  1.1860],\n",
      "        [-0.0900, -0.4268, -0.2420,  ...,  0.3763, -0.3102, -0.2388]], device='cuda:0'), bais gradient of fc is tensor(1.00000e-02 *\n",
      "       [ 2.2210, -0.4770, -1.8618,  4.1006, -3.9828], device='cuda:0')\n",
      "Epoch: 1/1... Step: 5900... Loss: 0.727732... Val Loss:0.848091\n",
      "weight gradient of fc is tensor(1.00000e-02 *\n",
      "       [[-0.0482, -0.2164,  0.7001,  ...,  0.4489,  0.3016,  0.3871],\n",
      "        [-0.7987,  0.6062, -0.6854,  ..., -0.4366,  0.0216,  0.0405],\n",
      "        [ 1.6661,  1.8012,  0.4781,  ..., -0.7300, -0.7366,  0.3176],\n",
      "        [ 1.4831,  3.1241, -0.4534,  ...,  1.7100, -0.1584, -2.5971],\n",
      "        [-2.3023, -5.3151, -0.0394,  ..., -0.9923,  0.5717,  1.8519]], device='cuda:0'), bais gradient of fc is tensor(1.00000e-02 *\n",
      "       [-0.7800, -0.1075, -5.8716, -2.5124,  9.2715], device='cuda:0')\n",
      "Epoch: 1/1... Step: 6000... Loss: 0.903294... Val Loss:0.840592\n",
      "weight gradient of fc is tensor(1.00000e-02 *\n",
      "       [[-0.6322, -1.0902,  0.1777,  ...,  0.4127,  0.4305, -0.1197],\n",
      "        [ 1.1582,  1.7302, -0.8017,  ..., -0.7065, -1.0503, -0.6831],\n",
      "        [-1.4438, -1.5852,  0.4667,  ..., -0.4728, -0.2889,  1.2715],\n",
      "        [ 2.1384,  1.2352,  0.3324,  ..., -0.2141,  0.7859,  0.3316],\n",
      "        [-1.2205, -0.2901, -0.1751,  ...,  0.9807,  0.1228, -0.8003]], device='cuda:0'), bais gradient of fc is tensor(1.00000e-02 *\n",
      "       [ 4.0005, -8.5536, -1.8016,  7.6222, -1.2676], device='cuda:0')\n",
      "Epoch: 1/1... Step: 6100... Loss: 0.813253... Val Loss:0.844318\n",
      "weight gradient of fc is tensor([[ 1.1714e-02,  6.5003e-03,  1.6405e-02,  ..., -3.1780e-03,\n",
      "         -4.3085e-04,  4.8950e-03],\n",
      "        [-2.9218e-03, -2.1859e-02, -4.0119e-03,  ...,  8.9927e-03,\n",
      "          9.5788e-03, -3.4379e-04],\n",
      "        [-6.3013e-03,  1.7167e-03, -3.0683e-03,  ...,  2.0153e-03,\n",
      "         -1.1229e-03, -7.9261e-03],\n",
      "        [ 8.8482e-03,  3.3063e-03, -8.6715e-03,  ..., -2.4265e-02,\n",
      "         -1.0371e-02,  1.3491e-02],\n",
      "        [-1.1339e-02,  1.0336e-02, -6.5348e-04,  ...,  1.6435e-02,\n",
      "          2.3457e-03, -1.0116e-02]], device='cuda:0'), bais gradient of fc is tensor(1.00000e-02 *\n",
      "       [-2.5440,  5.5554,  2.8180, -4.8549, -0.9745], device='cuda:0')\n",
      "Epoch: 1/1... Step: 6200... Loss: 0.644917... Val Loss:0.837577\n",
      "weight gradient of fc is tensor(1.00000e-02 *\n",
      "       [[ 0.6792,  0.2597,  0.4632,  ..., -0.0874, -0.0462, -0.0242],\n",
      "        [ 0.8617,  0.5946,  0.1029,  ..., -0.1361, -0.0614,  0.1609],\n",
      "        [ 1.1563,  1.2868,  0.1312,  ..., -0.0296, -0.1156, -0.5469],\n",
      "        [-1.8472, -1.1051, -0.3864,  ...,  0.2376, -0.9564,  1.6426],\n",
      "        [-0.8499, -1.0360, -0.3108,  ...,  0.0155,  1.1796, -1.2324]], device='cuda:0'), bais gradient of fc is tensor(1.00000e-02 *\n",
      "       [ 0.4638,  1.7403,  0.2664, -1.1525, -1.3180], device='cuda:0')\n",
      "Epoch: 1/1... Step: 6300... Loss: 0.703028... Val Loss:0.839382\n",
      "weight gradient of fc is tensor(1.00000e-02 *\n",
      "       [[ 1.9553,  1.6103,  0.7625,  ..., -1.5622, -0.6661,  0.7078],\n",
      "        [-0.6504, -1.0209, -0.6561,  ...,  0.7282,  0.2047,  0.6552],\n",
      "        [-0.1889,  0.7587, -0.5357,  ...,  0.7636,  0.1909, -1.4262],\n",
      "        [-1.7757, -2.5179,  0.1445,  ..., -1.0335,  0.8962, -0.0249],\n",
      "        [ 0.6597,  1.1698,  0.2847,  ...,  1.1039, -0.6257,  0.0881]], device='cuda:0'), bais gradient of fc is tensor(1.00000e-02 *\n",
      "       [-1.5922,  0.8671, -3.1539,  7.7591, -3.8801], device='cuda:0')\n",
      "Epoch: 1/1... Step: 6400... Loss: 0.838172... Val Loss:0.834960\n",
      "weight gradient of fc is tensor(1.00000e-02 *\n",
      "       [[-0.7392, -0.1386, -0.1670,  ...,  0.3201, -0.1126, -0.4007],\n",
      "        [ 0.6819, -0.5877,  0.5880,  ...,  0.7004,  0.0677, -2.5511],\n",
      "        [ 0.5356, -0.0388, -0.1160,  ..., -0.5242,  0.1323,  0.5588],\n",
      "        [-0.5717,  0.5163, -0.5454,  ..., -1.2855,  0.1016,  2.4291],\n",
      "        [ 0.0934,  0.2487,  0.2404,  ...,  0.7892, -0.1890, -0.0361]], device='cuda:0'), bais gradient of fc is tensor(1.00000e-02 *\n",
      "       [-0.6664,  1.5693, -3.0482, -0.7384,  2.8836], device='cuda:0')\n",
      "Epoch: 1/1... Step: 6500... Loss: 0.880851... Val Loss:0.832160\n",
      "weight gradient of fc is tensor(1.00000e-02 *\n",
      "       [[-0.7201, -0.0595, -0.6039,  ..., -1.0544, -0.4672,  0.1391],\n",
      "        [-1.4775,  1.3981, -0.1222,  ...,  2.0194, -0.2227, -0.5686],\n",
      "        [ 1.5995,  1.4423,  1.7656,  ..., -0.9082, -0.7183,  0.7050],\n",
      "        [-0.1775, -3.9380, -1.0137,  ..., -0.0382,  1.7193, -0.7393],\n",
      "        [ 0.7756,  1.1570, -0.0258,  ..., -0.0186, -0.3111,  0.4638]], device='cuda:0'), bais gradient of fc is tensor(1.00000e-02 *\n",
      "       [-5.8849, -0.4375, -2.3998,  9.7511, -1.0289], device='cuda:0')\n",
      "Epoch: 1/1... Step: 6600... Loss: 1.065567... Val Loss:0.838860\n",
      "weight gradient of fc is tensor([[ 7.2565e-03,  2.0883e-03, -1.0533e-02,  ...,  1.3285e-03,\n",
      "          2.3166e-03, -6.1164e-03],\n",
      "        [-5.2828e-03,  4.2988e-03,  4.4077e-03,  ..., -3.7271e-04,\n",
      "         -2.8433e-03,  1.0148e-02],\n",
      "        [ 2.1168e-02,  2.4175e-02,  1.1420e-02,  ..., -3.4552e-03,\n",
      "         -7.8178e-03,  3.1663e-03],\n",
      "        [-3.1119e-02, -2.1320e-02, -8.8521e-03,  ...,  7.4244e-04,\n",
      "          7.2154e-03, -1.6917e-02],\n",
      "        [ 7.9775e-03, -9.2418e-03,  3.5573e-03,  ...,  1.7570e-03,\n",
      "          1.1290e-03,  9.7191e-03]], device='cuda:0'), bais gradient of fc is tensor(1.00000e-02 *\n",
      "       [ 0.4955, -7.4928, -0.0280,  1.0633,  5.9621], device='cuda:0')\n",
      "Epoch: 1/1... Step: 6700... Loss: 0.855239... Val Loss:0.827314\n",
      "weight gradient of fc is tensor(1.00000e-02 *\n",
      "       [[ 1.8861,  1.3272,  0.1810,  ...,  0.8562, -0.2460, -0.6503],\n",
      "        [ 0.5205,  0.2829, -0.4994,  ..., -1.4620,  0.1010,  0.4847],\n",
      "        [ 0.5572,  1.2337, -0.3960,  ...,  1.5585,  0.1361, -1.1530],\n",
      "        [-1.4484, -1.0746,  0.6510,  ...,  0.1493, -0.4736,  0.6858],\n",
      "        [-1.5154, -1.7692,  0.0633,  ..., -1.1020,  0.4825,  0.6329]], device='cuda:0'), bais gradient of fc is tensor(1.00000e-02 *\n",
      "       [-1.3016,  0.7777, -1.2367, -4.5977,  6.3583], device='cuda:0')\n",
      "Epoch: 1/1... Step: 6800... Loss: 0.710431... Val Loss:0.831668\n",
      "weight gradient of fc is tensor([[ 9.9674e-04,  6.2689e-03, -1.8387e-02,  ...,  1.7420e-02,\n",
      "          9.8501e-03, -2.1079e-02],\n",
      "        [-5.7751e-03, -4.1616e-03, -7.9960e-03,  ..., -8.2241e-03,\n",
      "         -1.1727e-02,  3.6300e-03],\n",
      "        [-2.0158e-02, -1.7866e-02,  4.8437e-04,  ...,  6.8561e-03,\n",
      "          5.2156e-03,  1.7474e-02],\n",
      "        [ 1.8428e-02,  7.9918e-03,  2.6285e-02,  ..., -1.6459e-02,\n",
      "         -2.0396e-03,  4.3469e-04],\n",
      "        [ 6.5086e-03,  7.7667e-03, -3.8629e-04,  ...,  4.0680e-04,\n",
      "         -1.2988e-03, -4.5886e-04]], device='cuda:0'), bais gradient of fc is tensor(1.00000e-02 *\n",
      "       [ 4.6819, -7.6180,  4.9545, -2.5575,  0.5392], device='cuda:0')\n",
      "Epoch: 1/1... Step: 6900... Loss: 0.810303... Val Loss:0.842692\n",
      "weight gradient of fc is tensor(1.00000e-02 *\n",
      "       [[ 0.8953, -0.2193,  1.7970,  ...,  0.2013,  0.0277,  0.2133],\n",
      "        [ 0.1450,  0.8412, -0.8236,  ..., -1.9654, -0.8018,  1.5069],\n",
      "        [-0.2933, -0.2615, -0.1060,  ...,  0.0955,  0.0518, -0.7122],\n",
      "        [-0.2886,  2.4288, -0.4768,  ...,  1.4156,  0.8956, -0.7973],\n",
      "        [-0.4585, -2.7892, -0.3906,  ...,  0.2530, -0.1733, -0.2108]], device='cuda:0'), bais gradient of fc is tensor(1.00000e-02 *\n",
      "       [ 0.7787, -6.6575, -0.1573,  5.3481,  0.6880], device='cuda:0')\n",
      "Epoch: 1/1... Step: 7000... Loss: 0.948364... Val Loss:0.825300\n",
      "weight gradient of fc is tensor(1.00000e-02 *\n",
      "       [[-0.3195,  0.3810,  0.1333,  ..., -1.0146, -0.5402,  1.3587],\n",
      "        [-0.3447, -1.8694, -0.3635,  ..., -0.9705,  0.4212, -0.7008],\n",
      "        [ 0.7146, -0.0176, -0.0026,  ...,  0.6090,  0.1914,  0.0231],\n",
      "        [-0.7805,  1.6626,  0.2454,  ...,  2.2589,  0.1535, -1.0850],\n",
      "        [ 0.7301, -0.1566, -0.0126,  ..., -0.8828, -0.2259,  0.4039]], device='cuda:0'), bais gradient of fc is tensor(1.00000e-02 *\n",
      "       [-3.0546,  3.7502,  0.2985, -1.6621,  0.6680], device='cuda:0')\n",
      "Epoch: 1/1... Step: 7100... Loss: 0.685723... Val Loss:0.828883\n",
      "weight gradient of fc is tensor([[ 8.9323e-03, -9.1998e-03, -5.1669e-03,  ..., -2.2735e-03,\n",
      "          3.5254e-03,  3.0862e-03],\n",
      "        [-5.0223e-03,  1.1770e-03, -6.2021e-03,  ..., -1.3308e-03,\n",
      "          1.1620e-03,  4.5726e-03],\n",
      "        [ 5.5334e-03, -7.6603e-03,  7.4730e-03,  ..., -4.6226e-03,\n",
      "         -2.0934e-03,  1.8933e-04],\n",
      "        [-2.0724e-02,  1.5388e-02,  8.4744e-04,  ...,  2.2262e-03,\n",
      "         -5.0747e-03, -6.2678e-03],\n",
      "        [ 1.1281e-02,  2.9481e-04,  3.0485e-03,  ...,  6.0007e-03,\n",
      "          2.4808e-03, -1.5803e-03]], device='cuda:0'), bais gradient of fc is tensor(1.00000e-02 *\n",
      "       [-1.2529, -0.9996,  3.2155, -4.8860,  3.9231], device='cuda:0')\n",
      "Epoch: 1/1... Step: 7200... Loss: 0.826223... Val Loss:0.822709\n",
      "weight gradient of fc is tensor(1.00000e-02 *\n",
      "       [[-0.6171,  0.7071, -1.1176,  ..., -0.2047, -0.1839, -0.7066],\n",
      "        [ 0.5882, -0.0447, -0.2957,  ..., -0.1976,  0.1324,  1.1341],\n",
      "        [ 1.0837,  0.7548,  1.8368,  ..., -0.8770, -0.6403,  0.9420],\n",
      "        [-3.0070,  0.3612, -0.7565,  ...,  2.3470, -0.6435, -3.1254],\n",
      "        [ 1.9522, -1.7784,  0.3330,  ..., -1.0677,  1.3354,  1.7559]], device='cuda:0'), bais gradient of fc is tensor(1.00000e-02 *\n",
      "       [-2.2896, -0.9146,  0.7664, -3.4505,  5.8883], device='cuda:0')\n",
      "Epoch: 1/1... Step: 7300... Loss: 0.720725... Val Loss:0.832289\n",
      "weight gradient of fc is tensor(1.00000e-02 *\n",
      "       [[ 0.6592,  1.0057,  1.3863,  ...,  0.3387, -0.6066, -0.3656],\n",
      "        [ 1.8426,  0.5905, -0.6857,  ...,  0.1201, -0.1572, -0.2030],\n",
      "        [-0.7184, -0.0980,  0.7705,  ...,  0.3876,  0.1856, -0.0760],\n",
      "        [-3.2517, -3.2927, -1.5982,  ..., -0.8981,  0.9822,  0.3539],\n",
      "        [ 1.4684,  1.7944,  0.1271,  ...,  0.0516, -0.4040,  0.2908]], device='cuda:0'), bais gradient of fc is tensor(1.00000e-02 *\n",
      "       [-1.9220, -0.8171,  1.6587,  6.1145, -5.0341], device='cuda:0')\n",
      "Epoch: 1/1... Step: 7400... Loss: 0.754873... Val Loss:0.820194\n",
      "weight gradient of fc is tensor([[ 1.1618e-02,  9.3692e-03,  6.5448e-03,  ..., -8.2060e-03,\n",
      "         -3.6898e-03, -2.0180e-03],\n",
      "        [ 2.2662e-03,  1.1907e-02,  2.5678e-03,  ...,  6.1864e-03,\n",
      "          3.6924e-04, -1.7421e-02],\n",
      "        [-1.7376e-02, -2.3344e-02,  5.3884e-03,  ..., -6.5241e-03,\n",
      "         -6.6562e-04,  1.0223e-02],\n",
      "        [ 1.0580e-02,  2.2477e-02, -1.3924e-02,  ...,  1.0383e-02,\n",
      "         -3.1643e-04,  1.8394e-02],\n",
      "        [-7.0878e-03, -2.0409e-02, -5.7709e-04,  ..., -1.8391e-03,\n",
      "          4.3026e-03, -9.1787e-03]], device='cuda:0'), bais gradient of fc is tensor(1.00000e-02 *\n",
      "       [-0.3416,  1.5252,  4.5935, -6.7628,  0.9858], device='cuda:0')\n",
      "Epoch: 1/1... Step: 7500... Loss: 0.783143... Val Loss:0.821015\n",
      "weight gradient of fc is tensor([[-1.4892e-02, -5.6257e-03,  8.5879e-04,  ..., -1.4756e-03,\n",
      "          8.7912e-04,  1.1449e-02],\n",
      "        [ 2.0503e-02,  4.3794e-04,  3.8170e-03,  ...,  4.3513e-03,\n",
      "         -2.8850e-03, -3.1996e-03],\n",
      "        [-1.7086e-03, -6.2016e-03, -2.9615e-03,  ...,  3.0760e-03,\n",
      "          5.3992e-03,  1.1920e-03],\n",
      "        [ 6.7620e-03,  2.2378e-02,  1.0986e-03,  ..., -6.3860e-04,\n",
      "          2.0438e-03, -1.7234e-02],\n",
      "        [-1.0664e-02, -1.0989e-02, -2.8128e-03,  ..., -5.3130e-03,\n",
      "         -5.4372e-03,  7.7920e-03]], device='cuda:0'), bais gradient of fc is tensor(1.00000e-02 *\n",
      "       [-1.4314, -1.3519,  4.0875, -1.9352,  0.6310], device='cuda:0')\n",
      "Epoch: 1/1... Step: 7600... Loss: 0.750029... Val Loss:0.817432\n",
      "weight gradient of fc is tensor([[ 8.4061e-03,  6.4610e-03, -2.9933e-03,  ..., -4.6954e-04,\n",
      "         -2.1195e-03,  2.9954e-04],\n",
      "        [-9.1636e-03, -6.1443e-03,  6.0389e-03,  ..., -1.2214e-02,\n",
      "          6.4910e-04, -9.2588e-03],\n",
      "        [-2.9753e-02, -7.0322e-03,  2.6851e-03,  ...,  3.1399e-03,\n",
      "         -3.9101e-03, -1.2302e-03],\n",
      "        [ 1.8876e-02, -3.9938e-03, -9.5194e-03,  ..., -4.9132e-04,\n",
      "         -4.0562e-03,  6.9332e-03],\n",
      "        [ 1.1635e-02,  1.0709e-02,  3.7887e-03,  ...,  1.0035e-02,\n",
      "          9.4367e-03,  3.2563e-03]], device='cuda:0'), bais gradient of fc is tensor(1.00000e-02 *\n",
      "       [ 0.6734,  3.3696,  3.6182, -4.0034, -3.6577], device='cuda:0')\n",
      "Epoch: 1/1... Step: 7700... Loss: 0.839976... Val Loss:0.814708\n",
      "weight gradient of fc is tensor(1.00000e-02 *\n",
      "       [[-0.6229, -1.2430, -0.6137,  ...,  0.6731,  0.5804, -0.7362],\n",
      "        [-0.9086,  0.3505, -0.5661,  ..., -1.2521, -0.2588,  1.1599],\n",
      "        [-1.0146, -1.8815, -0.9128,  ...,  0.5108,  0.4166,  1.1014],\n",
      "        [ 1.9828,  3.3644,  1.6473,  ...,  0.6294, -1.3689, -2.2308],\n",
      "        [ 0.5633, -0.5905,  0.4453,  ..., -0.5612,  0.6307,  0.7058]], device='cuda:0'), bais gradient of fc is tensor(1.00000e-02 *\n",
      "       [ 4.2997, -1.7589,  2.6293, -5.3131,  0.1429], device='cuda:0')\n",
      "Epoch: 1/1... Step: 7800... Loss: 0.618313... Val Loss:0.816734\n",
      "weight gradient of fc is tensor(1.00000e-02 *\n",
      "       [[ 0.8173,  0.7688,  1.1569,  ..., -1.0686, -0.5772,  1.0084],\n",
      "        [-1.9010, -0.7320, -0.7035,  ...,  0.6459, -0.0228, -1.1794],\n",
      "        [ 2.4714,  2.5329,  0.3869,  ..., -0.4184,  0.1457,  0.1279],\n",
      "        [-2.5616, -3.5780, -0.8346,  ...,  0.9299,  0.2117, -0.5879],\n",
      "        [ 1.1740,  1.0083, -0.0058,  ..., -0.0888,  0.2426,  0.6310]], device='cuda:0'), bais gradient of fc is tensor(1.00000e-02 *\n",
      "       [-2.3646,  2.3068, -3.9628,  4.7683, -0.7476], device='cuda:0')\n",
      "Epoch: 1/1... Step: 7900... Loss: 0.694522... Val Loss:0.811560\n",
      "weight gradient of fc is tensor([[-1.2209e-02, -7.4629e-03, -3.8404e-03,  ..., -5.0286e-03,\n",
      "          1.9040e-03,  1.1215e-02],\n",
      "        [ 2.8707e-02,  4.5764e-02,  4.1852e-03,  ...,  2.3540e-02,\n",
      "         -1.3838e-03, -1.2817e-02],\n",
      "        [-3.0435e-03, -9.8322e-03, -7.5266e-03,  ..., -6.1064e-04,\n",
      "         -1.0449e-03, -6.8337e-03],\n",
      "        [-2.1467e-02, -2.1509e-02,  7.1153e-03,  ..., -1.8446e-02,\n",
      "         -6.0324e-03,  9.8727e-03],\n",
      "        [ 8.0121e-03, -6.9602e-03,  6.6474e-05,  ...,  5.4522e-04,\n",
      "          6.5570e-03, -1.4375e-03]], device='cuda:0'), bais gradient of fc is tensor(1.00000e-02 *\n",
      "       [-1.1364, -2.7782,  4.8060, -0.7735, -0.1178], device='cuda:0')\n",
      "Epoch: 1/1... Step: 8000... Loss: 0.810482... Val Loss:0.814474\n",
      "weight gradient of fc is tensor(1.00000e-02 *\n",
      "       [[ 0.0245, -0.8024,  0.3054,  ..., -0.0524,  0.3327,  0.1880],\n",
      "        [ 1.1915,  0.8379, -0.4308,  ..., -0.1071,  0.1024, -0.3192],\n",
      "        [ 0.7745,  0.4821, -0.0800,  ..., -0.5228, -0.1765,  0.7285],\n",
      "        [-2.3307, -2.3634,  0.5167,  ..., -1.7316, -0.2309,  1.0398],\n",
      "        [ 0.3402,  1.8458, -0.3113,  ...,  2.4139, -0.0277, -1.6370]], device='cuda:0'), bais gradient of fc is tensor(1.00000e-02 *\n",
      "       [ 0.0206,  2.2304, -2.2726,  2.4027, -2.3810], device='cuda:0')\n",
      "Epoch: 1/1... Step: 8100... Loss: 0.652647... Val Loss:0.810923\n",
      "weight gradient of fc is tensor(1.00000e-02 *\n",
      "       [[-0.4080, -0.8719,  0.7580,  ..., -1.1898, -0.3392,  0.7852],\n",
      "        [-0.6730,  1.8007,  0.0950,  ...,  2.0280,  0.1805, -1.7802],\n",
      "        [-0.9717, -2.8803,  0.1630,  ..., -0.3287,  0.7657, -0.4155],\n",
      "        [ 0.1303,  0.7848, -1.1058,  ..., -0.4226, -0.5121,  0.5885],\n",
      "        [ 1.9224,  1.1668,  0.0899,  ..., -0.0870, -0.0949,  0.8220]], device='cuda:0'), bais gradient of fc is tensor(1.00000e-02 *\n",
      "       [ 1.2603,  0.3364,  5.5432, -3.6317, -3.5081], device='cuda:0')\n",
      "Epoch: 1/1... Step: 8200... Loss: 0.792968... Val Loss:0.811111\n",
      "weight gradient of fc is tensor(1.00000e-02 *\n",
      "       [[ 1.5331,  2.5602,  0.9879,  ...,  0.1020,  0.4292,  0.3261],\n",
      "        [ 2.4058,  2.7137, -0.0559,  ...,  1.7880,  0.1279, -1.6621],\n",
      "        [-0.0863, -0.5529, -0.1725,  ...,  1.1352, -0.0421,  0.8213],\n",
      "        [-2.1623, -3.0391, -0.7114,  ..., -2.2238,  0.2503, -0.5961],\n",
      "        [-1.6904, -1.6820, -0.0481,  ..., -0.8015, -0.7654,  1.1108]], device='cuda:0'), bais gradient of fc is tensor(1.00000e-02 *\n",
      "       [-4.9677, -3.5312,  2.2386,  1.3757,  4.8846], device='cuda:0')\n",
      "Epoch: 1/1... Step: 8300... Loss: 0.904311... Val Loss:0.810368\n",
      "weight gradient of fc is tensor(1.00000e-02 *\n",
      "       [[ 1.1024,  0.5334, -0.5404,  ...,  0.2547, -0.1535, -1.7342],\n",
      "        [-1.4044, -2.4217, -0.4874,  ..., -0.6371,  0.8946, -0.0006],\n",
      "        [-0.7408, -1.8236,  0.1907,  ...,  0.9194,  0.6283, -0.1575],\n",
      "        [ 0.6396,  4.4735,  0.3666,  ...,  0.8130, -1.2527,  1.2908],\n",
      "        [ 0.4031, -0.7616,  0.4705,  ..., -1.3500, -0.1167,  0.6015]], device='cuda:0'), bais gradient of fc is tensor(1.00000e-02 *\n",
      "       [ 0.7706,  1.6156,  4.4895, -9.5965,  2.7208], device='cuda:0')\n",
      "Epoch: 1/1... Step: 8400... Loss: 0.757642... Val Loss:0.814532\n",
      "weight gradient of fc is tensor(1.00000e-02 *\n",
      "       [[-0.1599,  0.1331,  0.2936,  ...,  0.1651,  0.3126, -0.5272],\n",
      "        [-0.0513, -3.0612,  0.0917,  ...,  0.2993,  0.5215, -0.2069],\n",
      "        [-0.0472, -0.3707,  0.0788,  ..., -0.3043, -0.1352,  0.2884],\n",
      "        [ 0.2688,  2.6941, -0.2009,  ...,  0.0715, -0.9836,  1.4973],\n",
      "        [-0.0104,  0.6046, -0.2631,  ..., -0.2316,  0.2847, -1.0516]], device='cuda:0'), bais gradient of fc is tensor(1.00000e-02 *\n",
      "       [ 2.9452,  5.6116, -0.7794, -3.2650, -4.5125], device='cuda:0')\n",
      "Epoch: 1/1... Step: 8500... Loss: 0.698227... Val Loss:0.808499\n",
      "weight gradient of fc is tensor(1.00000e-02 *\n",
      "       [[-0.5546, -0.1679,  1.0334,  ...,  0.0481, -0.1285,  0.6895],\n",
      "        [-1.1160, -0.6438,  0.5796,  ...,  0.2372,  0.3541,  1.7343],\n",
      "        [-2.3099, -2.1446, -0.2329,  ..., -0.2016,  0.5443, -0.7385],\n",
      "        [ 2.5115,  0.2325, -1.2641,  ..., -2.4925, -0.0234, -3.1390],\n",
      "        [ 1.4690,  2.7238, -0.1159,  ...,  2.4087, -0.7465,  1.4537]], device='cuda:0'), bais gradient of fc is tensor(1.00000e-02 *\n",
      "       [-0.0120,  3.1173,  3.9138, -2.6594, -4.3597], device='cuda:0')\n",
      "Epoch: 1/1... Step: 8600... Loss: 0.748319... Val Loss:0.807747\n",
      "weight gradient of fc is tensor(1.00000e-02 *\n",
      "       [[-0.6708,  0.8503,  0.4393,  ...,  0.7552, -0.0610, -0.5910],\n",
      "        [-0.3178, -0.1322, -0.7856,  ..., -0.8797, -0.6787,  1.0239],\n",
      "        [ 0.8267, -0.4238,  0.0473,  ..., -0.4949, -0.5285,  0.2985],\n",
      "        [-1.1517,  0.6620, -0.1944,  ...,  0.8660,  0.9951, -3.1219],\n",
      "        [ 1.3136, -0.9562,  0.4935,  ..., -0.2466,  0.2731,  2.3906]], device='cuda:0'), bais gradient of fc is tensor(1.00000e-02 *\n",
      "       [ 0.6654, -4.8804, -1.3435,  3.5831,  1.9753], device='cuda:0')\n",
      "Epoch: 1/1... Step: 8700... Loss: 0.777302... Val Loss:0.806637\n",
      "weight gradient of fc is tensor(1.00000e-02 *\n",
      "       [[-0.2484, -0.1694, -0.3062,  ...,  1.6656,  0.8653, -1.2933],\n",
      "        [ 1.0645,  1.4002,  0.6476,  ...,  0.2996,  0.0365,  0.8890],\n",
      "        [-0.1072, -0.4515,  1.2502,  ..., -1.3654,  0.1126,  1.6709],\n",
      "        [-0.6108, -3.3250, -1.2355,  ..., -1.8056,  0.0150, -0.2933],\n",
      "        [-0.0980,  2.5458, -0.3562,  ...,  1.2057, -1.0294, -0.9732]], device='cuda:0'), bais gradient of fc is tensor(1.00000e-02 *\n",
      "       [ 3.0809, -4.2737,  0.3573,  4.7266, -3.8911], device='cuda:0')\n",
      "Epoch: 1/1... Step: 8800... Loss: 0.814617... Val Loss:0.800323\n",
      "weight gradient of fc is tensor([[ 3.4592e-03, -3.5533e-03, -1.1099e-03,  ..., -1.5392e-03,\n",
      "          3.9628e-03, -2.9128e-03],\n",
      "        [-8.9174e-03,  3.7962e-03, -1.0055e-02,  ..., -5.8890e-03,\n",
      "         -4.3571e-05,  3.0538e-03],\n",
      "        [-6.5499e-03, -1.5340e-02,  1.0933e-02,  ..., -6.2947e-03,\n",
      "         -2.2283e-03,  1.3422e-02],\n",
      "        [ 9.3382e-03,  7.2621e-03,  7.5415e-03,  ...,  1.3740e-02,\n",
      "          4.6018e-03, -1.1065e-02],\n",
      "        [ 2.6700e-03,  7.8347e-03, -7.3103e-03,  ..., -1.7015e-05,\n",
      "         -6.2927e-03, -2.4984e-03]], device='cuda:0'), bais gradient of fc is tensor(1.00000e-02 *\n",
      "       [ 0.7702, -2.1987,  3.5825,  2.1629, -4.3168], device='cuda:0')\n",
      "Epoch: 1/1... Step: 8900... Loss: 0.778093... Val Loss:0.803937\n",
      "weight gradient of fc is tensor(1.00000e-02 *\n",
      "       [[ 1.1771,  0.0793,  0.7823,  ..., -0.7946, -0.6908,  1.0044],\n",
      "        [-1.0094, -0.1326,  0.3047,  ..., -0.4535,  0.8497, -0.9031],\n",
      "        [-0.9237,  0.1452, -0.1341,  ...,  0.2101, -0.1259, -0.7005],\n",
      "        [-0.3134, -1.5366, -0.8879,  ...,  0.1266,  0.4339,  0.0902],\n",
      "        [ 1.0693,  1.4446, -0.0650,  ...,  0.9114, -0.4668,  0.5089]], device='cuda:0'), bais gradient of fc is tensor(1.00000e-02 *\n",
      "       [-4.7878,  1.3640, -1.0161,  3.7306,  0.7093], device='cuda:0')\n",
      "Epoch: 1/1... Step: 9000... Loss: 0.863866... Val Loss:0.801424\n",
      "weight gradient of fc is tensor(1.00000e-02 *\n",
      "       [[ 0.4239,  0.3425,  0.8545,  ..., -0.6087,  0.0598,  0.1680],\n",
      "        [-0.9555, -0.2603, -0.7046,  ...,  1.8691,  0.4380, -0.6802],\n",
      "        [ 0.9711,  0.3794,  0.1397,  ...,  0.1204,  0.4962, -0.4159],\n",
      "        [-2.2174, -1.3121, -0.2382,  ..., -1.6109, -0.8461,  1.7309],\n",
      "        [ 1.7779,  0.8506, -0.0514,  ...,  0.2301, -0.1479, -0.8027]], device='cuda:0'), bais gradient of fc is tensor(1.00000e-02 *\n",
      "       [ 1.8239, -1.4647,  2.9607,  0.0667, -3.3866], device='cuda:0')\n",
      "Epoch: 1/1... Step: 9100... Loss: 0.724610... Val Loss:0.799134\n",
      "weight gradient of fc is tensor(1.00000e-02 *\n",
      "       [[-0.6262, -0.4903,  0.2843,  ...,  0.6281,  0.2901,  0.3201],\n",
      "        [ 0.2534,  2.3531, -0.5445,  ..., -0.9409, -0.1384,  1.0386],\n",
      "        [ 0.1536, -0.0716,  0.0362,  ...,  0.1631,  0.4575, -0.1037],\n",
      "        [ 2.5487,  1.6739,  0.0662,  ...,  1.3616, -0.8170, -1.5068],\n",
      "        [-2.3295, -3.4651,  0.1578,  ..., -1.2120,  0.2078,  0.2518]], device='cuda:0'), bais gradient of fc is tensor(1.00000e-02 *\n",
      "       [-1.0082, -4.2525,  2.5122, -4.3296,  7.0781], device='cuda:0')\n",
      "Epoch: 1/1... Step: 9200... Loss: 0.656563... Val Loss:0.795702\n",
      "weight gradient of fc is tensor(1.00000e-02 *\n",
      "       [[ 0.7899,  0.8209,  0.8094,  ...,  0.4145,  0.4172,  0.4245],\n",
      "        [ 0.0712,  0.9607, -0.5384,  ..., -0.2706, -0.1396, -0.6205],\n",
      "        [-1.8973, -2.4219, -0.8374,  ...,  1.2962, -0.3887, -0.1130],\n",
      "        [ 0.3603,  1.7762,  0.1747,  ...,  0.9674, -0.0305, -1.1597],\n",
      "        [ 0.6758, -1.1358,  0.3917,  ..., -2.4075,  0.1415,  1.4686]], device='cuda:0'), bais gradient of fc is tensor(1.00000e-02 *\n",
      "       [-3.7729,  0.7516,  4.5144, -6.0757,  4.5825], device='cuda:0')\n",
      "Epoch: 1/1... Step: 9300... Loss: 0.906622... Val Loss:0.800314\n",
      "weight gradient of fc is tensor([[ 7.4734e-03,  1.1070e-02, -1.1301e-02,  ..., -6.4415e-04,\n",
      "         -7.5431e-04, -1.3745e-02],\n",
      "        [ 1.4067e-02,  9.7703e-04, -6.6909e-03,  ..., -7.2872e-03,\n",
      "          1.7896e-03,  5.9320e-03],\n",
      "        [ 8.8510e-03, -6.9617e-03,  4.2660e-04,  ..., -3.6820e-03,\n",
      "          2.9808e-03, -1.2071e-02],\n",
      "        [-2.9892e-02,  7.1710e-03,  2.1884e-02,  ...,  1.7100e-02,\n",
      "         -5.6402e-03,  1.9730e-02],\n",
      "        [-4.9899e-04, -1.2256e-02, -4.3180e-03,  ..., -5.4864e-03,\n",
      "          1.6240e-03,  1.5467e-04]], device='cuda:0'), bais gradient of fc is tensor(1.00000e-02 *\n",
      "       [-1.3993,  0.5591,  4.8723, -5.2188,  1.1867], device='cuda:0')\n",
      "Epoch: 1/1... Step: 9400... Loss: 0.658305... Val Loss:0.797350\n",
      "weight gradient of fc is tensor([[ 5.2779e-03,  5.1579e-03, -7.0372e-03,  ...,  4.3199e-04,\n",
      "          8.4701e-04, -5.1801e-03],\n",
      "        [-6.4502e-03, -1.3098e-02,  6.3959e-03,  ..., -1.4372e-02,\n",
      "         -1.5290e-03,  8.9422e-03],\n",
      "        [ 2.0557e-02,  3.0994e-02,  1.1985e-02,  ..., -1.7062e-02,\n",
      "         -5.7473e-03,  3.2624e-02],\n",
      "        [-3.1932e-02, -2.1489e-02, -1.1940e-02,  ...,  3.1089e-02,\n",
      "          1.0996e-02, -4.4617e-02],\n",
      "        [ 1.2547e-02, -1.5651e-03,  5.9617e-04,  ..., -8.5909e-05,\n",
      "         -4.5662e-03,  8.2308e-03]], device='cuda:0'), bais gradient of fc is tensor(1.00000e-02 *\n",
      "       [-1.3697,  0.5260, -5.5082,  5.4512,  0.9008], device='cuda:0')\n",
      "Epoch: 1/1... Step: 9500... Loss: 0.866891... Val Loss:0.798109\n",
      "weight gradient of fc is tensor([[-4.4613e-03, -6.0150e-03,  8.0200e-03,  ..., -2.1116e-03,\n",
      "          4.9692e-04,  6.5640e-03],\n",
      "        [-2.6623e-03, -2.0149e-02,  2.5876e-03,  ..., -7.1281e-03,\n",
      "          6.3147e-03,  6.8972e-03],\n",
      "        [ 2.3028e-02,  1.3313e-02, -1.9861e-03,  ..., -3.4730e-03,\n",
      "         -4.0734e-03, -9.0259e-03],\n",
      "        [-2.7149e-02,  2.2476e-03, -8.0521e-03,  ...,  4.0169e-03,\n",
      "         -1.2787e-03, -2.6642e-03],\n",
      "        [ 1.1244e-02,  1.0603e-02, -5.6947e-04,  ...,  8.6957e-03,\n",
      "         -1.4596e-03, -1.7711e-03]], device='cuda:0'), bais gradient of fc is tensor(1.00000e-02 *\n",
      "       [ 0.6235,  5.2832, -3.5988, -0.9672, -1.3407], device='cuda:0')\n",
      "Epoch: 1/1... Step: 9600... Loss: 0.610883... Val Loss:0.794691\n",
      "weight gradient of fc is tensor([[ 2.6320e-02,  1.7234e-02, -1.1591e-03,  ...,  1.0590e-02,\n",
      "         -3.0683e-03, -6.1006e-03],\n",
      "        [ 1.9050e-03, -2.8774e-04,  1.4381e-02,  ..., -1.6370e-02,\n",
      "         -7.8589e-05,  5.5125e-03],\n",
      "        [-3.7188e-03,  3.0888e-03, -2.6312e-03,  ...,  6.3570e-03,\n",
      "         -1.2594e-03, -1.2147e-02],\n",
      "        [-2.4822e-02, -3.2309e-03, -1.5145e-02,  ...,  2.4866e-03,\n",
      "          5.2144e-03, -3.7718e-03],\n",
      "        [ 3.1676e-04, -1.6805e-02,  4.5546e-03,  ..., -3.0634e-03,\n",
      "         -8.0824e-04,  1.6507e-02]], device='cuda:0'), bais gradient of fc is tensor(1.00000e-02 *\n",
      "       [-2.7977, -1.7426, -0.1197,  0.5894,  4.0706], device='cuda:0')\n",
      "Epoch: 1/1... Step: 9700... Loss: 0.865095... Val Loss:0.791363\n",
      "weight gradient of fc is tensor([[-1.7951e-03, -8.0748e-03,  2.0400e-03,  ...,  4.5052e-03,\n",
      "          4.9304e-03, -5.5882e-03],\n",
      "        [-3.8566e-03, -2.8711e-02,  4.1396e-03,  ..., -6.1669e-05,\n",
      "          5.7437e-03, -4.0916e-03],\n",
      "        [-6.3012e-03, -4.1253e-03,  9.6938e-04,  ..., -9.8966e-04,\n",
      "          6.3221e-05,  2.2430e-03],\n",
      "        [ 2.2105e-03,  4.1975e-02, -5.2299e-03,  ...,  2.0812e-03,\n",
      "         -1.3479e-02, -1.1462e-04],\n",
      "        [ 9.7424e-03, -1.0635e-03, -1.9191e-03,  ..., -5.5350e-03,\n",
      "          2.7417e-03,  7.5515e-03]], device='cuda:0'), bais gradient of fc is tensor(1.00000e-02 *\n",
      "       [ 2.6862,  3.2360,  0.9435, -7.9205,  1.0548], device='cuda:0')\n",
      "Epoch: 1/1... Step: 9800... Loss: 0.682852... Val Loss:0.792835\n",
      "weight gradient of fc is tensor([[-3.9435e-04, -8.6699e-03, -3.2962e-03,  ..., -7.5391e-03,\n",
      "         -4.9448e-03, -9.5803e-03],\n",
      "        [-1.6365e-02,  1.1482e-02, -1.0932e-02,  ..., -1.3992e-02,\n",
      "         -2.1239e-03,  4.0706e-03],\n",
      "        [ 8.3750e-03,  1.3262e-02, -1.9129e-02,  ...,  1.1187e-03,\n",
      "          1.0286e-03, -1.8167e-02],\n",
      "        [ 2.6222e-03, -1.2261e-02,  3.4064e-02,  ...,  2.0863e-02,\n",
      "          2.7257e-03,  2.4793e-02],\n",
      "        [ 5.7618e-03, -3.8131e-03, -7.0639e-04,  ..., -4.5028e-04,\n",
      "          3.3144e-03, -1.1156e-03]], device='cuda:0'), bais gradient of fc is tensor(1.00000e-02 *\n",
      "       [-0.0909, -2.1088, -7.5775,  7.4519,  2.3253], device='cuda:0')\n",
      "Epoch: 1/1... Step: 9900... Loss: 0.741811... Val Loss:0.789439\n",
      "weight gradient of fc is tensor(1.00000e-02 *\n",
      "       [[ 0.9361,  2.3217, -0.6673,  ..., -1.9555, -1.4252,  2.2757],\n",
      "        [-1.9953, -2.8995,  0.4389,  ...,  0.3368,  0.7126,  0.8193],\n",
      "        [ 1.4471,  1.2506, -0.1656,  ..., -0.8726, -0.8384, -0.8658],\n",
      "        [ 1.7765,  1.1404,  0.6753,  ...,  2.8823,  0.4052, -2.1515],\n",
      "        [-2.1643, -1.8133, -0.2814,  ..., -0.3909,  1.1458, -0.0777]], device='cuda:0'), bais gradient of fc is tensor(1.00000e-02 *\n",
      "       [-5.6747,  2.0217, -0.6845,  1.6557,  2.6817], device='cuda:0')\n",
      "Epoch: 1/1... Step: 10000... Loss: 0.717529... Val Loss:0.790824\n",
      "weight gradient of fc is tensor(1.00000e-02 *\n",
      "       [[ 1.1664,  0.8473,  1.0046,  ..., -0.5867, -0.1793,  1.1781],\n",
      "        [-0.1446, -0.4553,  0.5670,  ...,  0.2841, -0.1676, -0.3932],\n",
      "        [ 0.8604,  1.6033, -1.0280,  ...,  0.5179, -0.4481,  0.1992],\n",
      "        [-2.2403, -1.9422, -0.2231,  ..., -0.8357,  0.6424, -0.9731],\n",
      "        [ 0.3581, -0.0530, -0.3205,  ...,  0.6204,  0.1526, -0.0110]], device='cuda:0'), bais gradient of fc is tensor(1.00000e-02 *\n",
      "       [-0.0040,  1.2472, -4.7115,  4.9201, -1.4519], device='cuda:0')\n",
      "Epoch: 1/1... Step: 10100... Loss: 0.740676... Val Loss:0.790404\n",
      "weight gradient of fc is tensor(1.00000e-02 *\n",
      "       [[ 0.2768,  0.5035,  0.6832,  ...,  0.1291,  0.1268,  0.4046],\n",
      "        [ 2.0504, -0.4299,  1.2200,  ..., -0.0570,  0.3697,  0.1157],\n",
      "        [-1.3820,  0.5873, -1.1052,  ..., -0.2507, -0.1024,  0.3344],\n",
      "        [-1.1615, -3.0532, -0.0347,  ..., -1.1125,  0.7812,  2.1979],\n",
      "        [ 0.2163,  2.3923, -0.7633,  ...,  1.2911, -1.1753, -3.0526]], device='cuda:0'), bais gradient of fc is tensor(1.00000e-02 *\n",
      "       [-2.7566,  3.1467, -2.9624,  7.6259, -5.0536], device='cuda:0')\n",
      "Epoch: 1/1... Step: 10200... Loss: 0.787796... Val Loss:0.784299\n",
      "weight gradient of fc is tensor(1.00000e-02 *\n",
      "       [[ 0.2003,  0.3483,  2.7402,  ..., -1.3659, -0.1328,  1.6202],\n",
      "        [ 0.0648, -0.8609, -0.0395,  ...,  1.6969,  0.7579, -1.1811],\n",
      "        [-1.7458, -1.6635, -0.4765,  ...,  0.4893,  0.5806,  0.7932],\n",
      "        [ 0.2048,  0.5619, -1.2484,  ..., -0.4847, -0.6767,  0.0227],\n",
      "        [ 1.2759,  1.6143, -0.9759,  ..., -0.3355, -0.5290, -1.2550]], device='cuda:0'), bais gradient of fc is tensor(1.00000e-02 *\n",
      "       [-0.5650,  5.7204,  2.3953, -2.9945, -4.5563], device='cuda:0')\n",
      "Epoch: 1/1... Step: 10300... Loss: 0.882794... Val Loss:0.788035\n",
      "weight gradient of fc is tensor(1.00000e-02 *\n",
      "       [[ 0.7902,  1.3208,  0.0357,  ...,  0.3813, -0.3693,  0.4554],\n",
      "        [-0.1378, -0.0171,  1.0406,  ...,  0.1661,  0.3510, -0.2854],\n",
      "        [-1.3108, -2.1659, -0.1417,  ..., -0.3076,  0.4866,  1.1266],\n",
      "        [ 0.0382, -1.3409, -0.4307,  ..., -0.2748,  0.1477, -0.3106],\n",
      "        [ 0.6201,  2.2032, -0.5039,  ...,  0.0350, -0.6159, -0.9860]], device='cuda:0'), bais gradient of fc is tensor(1.00000e-02 *\n",
      "       [-2.4402, -1.9326,  4.8074,  2.2743, -2.7089], device='cuda:0')\n",
      "Epoch: 1/1... Step: 10400... Loss: 0.760944... Val Loss:0.788642\n",
      "weight gradient of fc is tensor([[ 6.7352e-03,  2.9320e-03, -2.3412e-04,  ..., -9.4471e-04,\n",
      "          4.3538e-03, -5.4561e-03],\n",
      "        [ 1.3699e-02,  2.2530e-02, -4.2781e-03,  ...,  4.5653e-03,\n",
      "         -8.9080e-03,  8.7806e-03],\n",
      "        [-1.3680e-02, -1.4370e-02, -4.0222e-03,  ...,  1.5014e-03,\n",
      "         -4.6482e-03,  7.9556e-03],\n",
      "        [ 2.7577e-03, -4.0528e-03,  1.3877e-03,  ..., -2.3499e-03,\n",
      "          4.1752e-03, -1.0598e-02],\n",
      "        [-9.5115e-03, -7.0387e-03,  7.1467e-03,  ..., -2.7721e-03,\n",
      "          5.0273e-03, -6.8201e-04]], device='cuda:0'), bais gradient of fc is tensor(1.00000e-02 *\n",
      "       [ 1.1983, -5.5744,  5.3285, -2.9448,  1.9923], device='cuda:0')\n",
      "Epoch: 1/1... Step: 10500... Loss: 0.727041... Val Loss:0.787177\n",
      "weight gradient of fc is tensor([[-1.2375e-02, -2.7694e-03,  8.4766e-03,  ..., -5.3061e-03,\n",
      "          1.1119e-04,  7.5494e-03],\n",
      "        [ 3.8169e-03,  1.4461e-02,  1.2481e-02,  ...,  4.6581e-03,\n",
      "         -2.7564e-03, -7.7263e-03],\n",
      "        [ 9.0828e-03,  1.5414e-02, -8.1348e-03,  ...,  4.0214e-03,\n",
      "          1.4869e-03, -1.2991e-02],\n",
      "        [-1.3754e-02, -2.0639e-02, -1.6083e-02,  ...,  8.4428e-03,\n",
      "          3.2951e-03, -1.6849e-03],\n",
      "        [ 1.3230e-02, -6.4671e-03,  3.2607e-03,  ..., -1.1816e-02,\n",
      "         -2.1368e-03,  1.4853e-02]], device='cuda:0'), bais gradient of fc is tensor(1.00000e-02 *\n",
      "       [ 0.1479, -0.0169, -2.4817,  2.4692, -0.1185], device='cuda:0')\n",
      "Epoch: 1/1... Step: 10600... Loss: 0.780453... Val Loss:0.790829\n",
      "weight gradient of fc is tensor(1.00000e-02 *\n",
      "       [[ 0.6370, -0.0517, -0.0490,  ...,  0.1166,  0.0204, -0.5930],\n",
      "        [ 0.1828,  1.1523, -0.3083,  ...,  1.4034, -0.3214,  0.4617],\n",
      "        [-1.7590,  1.3633, -1.1617,  ..., -0.0950, -1.0784, -0.8309],\n",
      "        [ 1.8143,  0.3154,  1.4478,  ..., -0.1914, -0.2793,  0.7645],\n",
      "        [-0.8751, -2.7793,  0.0713,  ..., -1.2337,  1.6587,  0.1976]], device='cuda:0'), bais gradient of fc is tensor(1.00000e-02 *\n",
      "       [ 0.4692, -3.2577, -3.5999,  1.2331,  5.1553], device='cuda:0')\n",
      "Epoch: 1/1... Step: 10700... Loss: 0.866688... Val Loss:0.785292\n",
      "weight gradient of fc is tensor(1.00000e-02 *\n",
      "       [[-0.6656, -0.3847, -0.0728,  ..., -0.0289, -0.2897,  0.7766],\n",
      "        [ 1.1438,  0.3427,  0.2754,  ..., -0.4529, -0.6046,  0.5014],\n",
      "        [ 1.6663,  1.0041,  0.2553,  ..., -0.6692,  0.2749, -0.1574],\n",
      "        [-0.5523,  0.1764,  0.4588,  ...,  1.8812, -0.0041, -0.7004],\n",
      "        [-1.5923, -1.1385, -0.9168,  ..., -0.7302,  0.6234, -0.4202]], device='cuda:0'), bais gradient of fc is tensor(1.00000e-02 *\n",
      "       [ 0.1687, -0.3703, -6.3260,  2.3952,  4.1325], device='cuda:0')\n",
      "Epoch: 1/1... Step: 10800... Loss: 0.578419... Val Loss:0.784846\n",
      "weight gradient of fc is tensor([[ 4.5193e-03, -2.6717e-03,  3.7063e-03,  ...,  6.8533e-03,\n",
      "          1.0431e-02, -5.6986e-03],\n",
      "        [ 3.0140e-02,  1.7754e-02,  5.6413e-03,  ..., -1.0797e-02,\n",
      "         -3.6166e-03, -1.1914e-02],\n",
      "        [-2.3313e-02, -3.5769e-02,  2.8814e-03,  ...,  9.6061e-04,\n",
      "          1.3535e-03, -3.8327e-03],\n",
      "        [ 4.0641e-04,  1.6005e-02, -1.0887e-03,  ..., -1.6991e-03,\n",
      "         -3.8978e-03,  3.4055e-02],\n",
      "        [-1.1752e-02,  4.6809e-03, -1.1140e-02,  ...,  4.6825e-03,\n",
      "         -4.2701e-03, -1.2610e-02]], device='cuda:0'), bais gradient of fc is tensor(1.00000e-02 *\n",
      "       [ 2.6151, -0.4862,  8.5787, -6.8718, -3.8359], device='cuda:0')\n",
      "Epoch: 1/1... Step: 10900... Loss: 0.863886... Val Loss:0.782516\n",
      "weight gradient of fc is tensor(1.00000e-02 *\n",
      "       [[ 0.0096, -0.7996, -0.5190,  ...,  0.0786, -0.0580, -0.4764],\n",
      "        [-0.6966,  1.3442, -1.3305,  ..., -0.4844, -0.1005, -1.9498],\n",
      "        [ 0.5582,  0.2977,  1.7134,  ..., -0.3062, -0.8219,  0.6166],\n",
      "        [-1.8256,  2.4868, -1.4759,  ...,  2.2053,  0.4542, -0.9453],\n",
      "        [ 1.9543, -3.3291,  1.6121,  ..., -1.4934,  0.5262,  2.7549]], device='cuda:0'), bais gradient of fc is tensor(1.00000e-02 *\n",
      "       [ 0.0960,  1.4447, -2.2449, -5.0572,  5.7614], device='cuda:0')\n",
      "Epoch: 1/1... Step: 11000... Loss: 0.863813... Val Loss:0.782526\n",
      "weight gradient of fc is tensor(1.00000e-02 *\n",
      "       [[-1.9268, -0.4556, -0.7967,  ..., -1.9588, -0.3466,  1.9794],\n",
      "        [ 1.4829,  0.1825,  0.7498,  ...,  1.0944,  0.6913, -0.8651],\n",
      "        [ 0.3500, -1.0611,  0.8526,  ..., -0.3432,  0.2718, -0.0742],\n",
      "        [ 0.1375, -0.1085, -0.1052,  ..., -0.5284,  0.0652,  0.9799],\n",
      "        [-0.0436,  1.4428, -0.7005,  ...,  1.7360, -0.6816, -2.0200]], device='cuda:0'), bais gradient of fc is tensor(1.00000e-02 *\n",
      "       [-4.3104,  2.3218,  2.0549,  2.2807, -2.3471], device='cuda:0')\n",
      "Epoch: 1/1... Step: 11100... Loss: 0.773477... Val Loss:0.792317\n",
      "weight gradient of fc is tensor([[-6.2927e-03, -3.6913e-04,  2.6402e-03,  ..., -1.8701e-03,\n",
      "         -3.4195e-03,  1.1037e-02],\n",
      "        [ 3.5294e-03, -2.2869e-03,  4.3768e-03,  ..., -1.2828e-02,\n",
      "         -6.5075e-04,  1.0389e-02],\n",
      "        [ 1.0144e-03,  1.7684e-02,  1.0829e-03,  ...,  1.0873e-02,\n",
      "          2.4872e-03, -4.2718e-03],\n",
      "        [-7.9980e-03, -1.6134e-02, -6.8214e-03,  ...,  3.5929e-03,\n",
      "         -3.7246e-03, -2.7840e-02],\n",
      "        [ 9.7469e-03,  1.1063e-03, -1.2785e-03,  ...,  2.3220e-04,\n",
      "          5.3077e-03,  1.0686e-02]], device='cuda:0'), bais gradient of fc is tensor(1.00000e-02 *\n",
      "       [-1.1794,  1.4666, -3.9175,  5.1917, -1.5614], device='cuda:0')\n",
      "Epoch: 1/1... Step: 11200... Loss: 0.621729... Val Loss:0.779899\n",
      "weight gradient of fc is tensor(1.00000e-02 *\n",
      "       [[ 0.4041, -0.1080,  0.2010,  ..., -0.1909,  0.2071,  0.0971],\n",
      "        [ 1.7542, -0.6602,  0.0272,  ..., -0.2815, -0.1312, -0.1175],\n",
      "        [-0.8785, -2.5495,  0.1584,  ...,  0.2812,  0.6492,  0.0609],\n",
      "        [-2.7206, -1.0556,  0.1677,  ..., -0.6680,  0.3606,  1.2179],\n",
      "        [ 1.4408,  4.3732, -0.5543,  ...,  0.8591, -1.0857, -1.2584]], device='cuda:0'), bais gradient of fc is tensor(1.00000e-02 *\n",
      "       [ 2.0929,  0.2498,  4.3880,  0.8004, -7.5311], device='cuda:0')\n",
      "Epoch: 1/1... Step: 11300... Loss: 0.647050... Val Loss:0.778399\n",
      "weight gradient of fc is tensor(1.00000e-02 *\n",
      "       [[-0.3054, -0.2616,  0.4284,  ..., -0.1921,  0.0126,  0.8282],\n",
      "        [-1.6933, -1.6037, -1.0337,  ..., -0.3582, -0.0613, -1.2010],\n",
      "        [-0.3529, -0.6264,  0.2398,  ..., -0.4513,  0.2494,  0.7280],\n",
      "        [ 2.2593,  3.3246,  1.5446,  ...,  2.7447, -0.5904,  0.1485],\n",
      "        [ 0.0922, -0.8329, -1.1791,  ..., -1.7431,  0.3896, -0.5037]], device='cuda:0'), bais gradient of fc is tensor(1.00000e-02 *\n",
      "       [-0.9753,  0.6245,  0.1708, -0.8213,  1.0014], device='cuda:0')\n",
      "Epoch: 1/1... Step: 11400... Loss: 0.536599... Val Loss:0.778779\n",
      "weight gradient of fc is tensor(1.00000e-02 *\n",
      "       [[-0.5586, -0.4820,  0.6341,  ..., -0.4873,  0.0276,  0.5074],\n",
      "        [-1.5630,  0.5012, -0.3669,  ...,  0.0862,  0.1366,  0.1878],\n",
      "        [-0.3258, -1.7114, -0.7887,  ...,  0.2995, -0.0217,  1.2663],\n",
      "        [ 1.3715,  1.5517,  0.3379,  ...,  1.0713,  0.4790, -2.4074],\n",
      "        [ 1.0760,  0.1404,  0.1836,  ..., -0.9697, -0.6215,  0.4459]], device='cuda:0'), bais gradient of fc is tensor(1.00000e-02 *\n",
      "       [ 0.0380, -0.6000,  0.2144, -0.8094,  1.1571], device='cuda:0')\n",
      "Epoch: 1/1... Step: 11500... Loss: 0.809643... Val Loss:0.775937\n",
      "weight gradient of fc is tensor(1.00000e-02 *\n",
      "       [[ 1.7303,  0.6813, -0.1743,  ...,  0.7041,  0.1547, -0.3588],\n",
      "        [-1.8247, -1.1051,  0.2900,  ..., -0.7231,  0.8950,  0.4848],\n",
      "        [-0.3984, -0.0851,  0.6826,  ..., -0.4141, -0.6481,  0.2526],\n",
      "        [ 2.7158,  0.2048,  0.3272,  ..., -0.0330,  0.2064,  1.0030],\n",
      "        [-2.2229,  0.3041, -1.1255,  ...,  0.4660, -0.6080, -1.3815]], device='cuda:0'), bais gradient of fc is tensor(1.00000e-02 *\n",
      "       [-0.7017, -0.7238, -0.7455,  4.3266, -2.1557], device='cuda:0')\n",
      "Epoch: 1/1... Step: 11600... Loss: 0.743811... Val Loss:0.778006\n",
      "weight gradient of fc is tensor(1.00000e-02 *\n",
      "       [[-3.2918, -2.2033, -0.0999,  ...,  0.4150, -0.2726,  0.6355],\n",
      "        [ 2.8366,  3.0659,  0.8790,  ..., -0.5638, -1.0507, -2.0273],\n",
      "        [ 2.0966,  1.5473,  1.1879,  ...,  0.9306,  0.0641,  0.9296],\n",
      "        [-1.1549, -0.6531, -2.9876,  ..., -1.5125,  0.5255, -0.6348],\n",
      "        [-0.4865, -1.7569,  1.0206,  ...,  0.7307,  0.7337,  1.0970]], device='cuda:0'), bais gradient of fc is tensor(1.00000e-02 *\n",
      "       [-2.3353, -0.8751, -2.8852,  0.1475,  5.9481], device='cuda:0')\n",
      "Epoch: 1/1... Step: 11700... Loss: 0.826346... Val Loss:0.780042\n",
      "weight gradient of fc is tensor(1.00000e-02 *\n",
      "       [[-0.4130, -0.5933, -0.2767,  ..., -1.2520, -0.2233,  1.6715],\n",
      "        [-1.4189, -2.3007,  0.4314,  ...,  0.4411,  0.9888,  0.1911],\n",
      "        [ 3.0792,  2.2916,  1.2992,  ...,  0.1281, -0.7496,  0.2051],\n",
      "        [-0.2324,  2.3695, -1.5388,  ...,  1.1117, -0.0518, -3.2665],\n",
      "        [-1.0149, -1.7670,  0.0849,  ..., -0.4290,  0.0360,  1.1987]], device='cuda:0'), bais gradient of fc is tensor(1.00000e-02 *\n",
      "       [-0.6998,  8.7350, -3.4729, -5.4743,  0.9119], device='cuda:0')\n",
      "Epoch: 1/1... Step: 11800... Loss: 0.932102... Val Loss:0.773399\n",
      "weight gradient of fc is tensor([[-7.9286e-03, -1.4730e-02, -1.9865e-02,  ...,  1.3089e-02,\n",
      "          3.0321e-03, -1.2495e-02],\n",
      "        [ 4.3376e-03, -1.4608e-03,  3.9508e-03,  ..., -4.1790e-03,\n",
      "         -1.4296e-03, -1.4735e-03],\n",
      "        [ 3.1695e-03, -4.6264e-03,  2.3712e-03,  ...,  4.1746e-03,\n",
      "         -2.1196e-03, -7.2659e-03],\n",
      "        [ 7.4271e-03,  2.0055e-02,  1.1984e-02,  ..., -2.4929e-02,\n",
      "         -3.9082e-03,  3.7375e-02],\n",
      "        [-7.0056e-03,  7.6181e-04,  1.5588e-03,  ...,  1.1844e-02,\n",
      "          4.4254e-03, -1.6140e-02]], device='cuda:0'), bais gradient of fc is tensor(1.00000e-02 *\n",
      "       [ 0.0856,  2.5736,  0.7296, -2.5947, -0.7941], device='cuda:0')\n",
      "Epoch: 1/1... Step: 11900... Loss: 0.720687... Val Loss:0.780720\n",
      "weight gradient of fc is tensor([[-7.7619e-03, -7.6687e-03, -2.3489e-03,  ...,  3.8004e-03,\n",
      "          2.0426e-04, -8.6722e-03],\n",
      "        [ 5.6137e-03, -1.5258e-02,  7.7253e-03,  ...,  7.1883e-03,\n",
      "          7.0100e-03, -7.0980e-03],\n",
      "        [-8.3812e-03, -1.9428e-02,  8.3114e-03,  ..., -1.6929e-04,\n",
      "          2.1052e-03,  5.4089e-03],\n",
      "        [ 4.0046e-02,  4.1949e-02, -8.6205e-03,  ..., -3.2272e-03,\n",
      "         -4.7829e-03,  1.6332e-02],\n",
      "        [-2.9517e-02,  4.0573e-04, -5.0673e-03,  ..., -7.5922e-03,\n",
      "         -4.5366e-03, -5.9704e-03]], device='cuda:0'), bais gradient of fc is tensor(1.00000e-02 *\n",
      "       [ 2.7808,  7.4515, -0.9771, -6.8665, -2.3886], device='cuda:0')\n",
      "Epoch: 1/1... Step: 12000... Loss: 0.759895... Val Loss:0.777887\n",
      "weight gradient of fc is tensor(1.00000e-02 *\n",
      "       [[ 1.4608, -0.3774,  1.4413,  ...,  0.7156,  0.9800,  1.4443],\n",
      "        [-1.2033,  1.4444, -2.6211,  ..., -0.6049, -1.2332, -2.9675],\n",
      "        [ 2.2968,  2.3587, -0.1179,  ..., -0.0613, -0.3250, -0.0938],\n",
      "        [-1.9323, -0.1068,  0.7951,  ...,  2.8169,  0.1127, -0.4993],\n",
      "        [-0.6221, -3.3189,  0.5026,  ..., -2.8662,  0.4655,  2.1163]], device='cuda:0'), bais gradient of fc is tensor(1.00000e-02 *\n",
      "       [ 3.6882, -9.0075, -2.4395,  1.0215,  6.7374], device='cuda:0')\n",
      "Epoch: 1/1... Step: 12100... Loss: 1.006344... Val Loss:0.777246\n",
      "weight gradient of fc is tensor(1.00000e-02 *\n",
      "       [[ 1.1234,  0.3880,  0.9182,  ...,  0.4308,  0.2226, -0.7624],\n",
      "        [-0.4736, -1.6280, -0.9055,  ..., -1.3755,  0.4398,  0.9780],\n",
      "        [-2.8893, -0.0566,  0.0607,  ...,  0.2930, -0.0740,  0.7668],\n",
      "        [ 1.7853,  1.6726, -0.5331,  ...,  0.9050, -0.8385, -3.5602],\n",
      "        [ 0.4542, -0.3760,  0.4597,  ..., -0.2533,  0.2501,  2.5779]], device='cuda:0'), bais gradient of fc is tensor(1.00000e-02 *\n",
      "       [ 0.0682, -1.2981,  4.4043, -4.9361,  1.7616], device='cuda:0')\n",
      "Epoch: 1/1... Step: 12200... Loss: 0.718085... Val Loss:0.771840\n",
      "weight gradient of fc is tensor(1.00000e-02 *\n",
      "       [[-0.2411,  0.0868, -0.4345,  ...,  0.1208,  0.0518, -0.8116],\n",
      "        [-1.5887, -1.8877,  0.6543,  ..., -0.3629,  0.2606,  0.4440],\n",
      "        [ 1.9717,  0.8047,  0.0854,  ..., -0.6941, -0.0846,  1.4000],\n",
      "        [-0.7468,  0.5639, -0.6500,  ..., -0.3880,  0.3049, -1.0602],\n",
      "        [ 0.6049,  0.4323,  0.3448,  ...,  1.3241, -0.5328,  0.0278]], device='cuda:0'), bais gradient of fc is tensor(1.00000e-02 *\n",
      "       [ 2.7242,  2.8587, -1.8934, -5.7528,  2.0633], device='cuda:0')\n",
      "Epoch: 1/1... Step: 12300... Loss: 0.712558... Val Loss:0.770391\n",
      "weight gradient of fc is tensor(1.00000e-02 *\n",
      "       [[ 1.3052,  0.3725,  1.8052,  ..., -0.0850,  0.2845,  0.5868],\n",
      "        [-1.3146, -1.3880,  0.2131,  ..., -1.4811,  0.2297,  1.1372],\n",
      "        [-0.5349, -1.3806, -0.9160,  ...,  0.4188,  0.6209, -1.1386],\n",
      "        [ 2.3287,  2.7287, -1.0005,  ...,  0.1371, -1.4316, -0.5226],\n",
      "        [-1.7844, -0.3326, -0.1018,  ...,  1.0102,  0.2965, -0.0629]], device='cuda:0'), bais gradient of fc is tensor(1.00000e-02 *\n",
      "       [ 0.6910,  1.3622,  3.9697, -4.9740, -1.0491], device='cuda:0')\n",
      "Epoch: 1/1... Step: 12400... Loss: 0.682144... Val Loss:0.768556\n",
      "weight gradient of fc is tensor([[-2.1532e-02, -9.6126e-03, -7.4133e-03,  ..., -5.5612e-03,\n",
      "          1.3134e-03,  1.6393e-02],\n",
      "        [ 2.1442e-02,  5.5590e-03,  2.3161e-04,  ...,  3.4523e-04,\n",
      "         -7.7949e-03, -4.0931e-03],\n",
      "        [ 4.7800e-03,  1.3931e-02,  1.0638e-03,  ..., -8.4337e-03,\n",
      "         -4.1424e-04,  3.2987e-03],\n",
      "        [-5.0030e-03, -1.9056e-02, -3.1607e-03,  ...,  1.3815e-02,\n",
      "          7.3683e-03, -1.1644e-02],\n",
      "        [ 3.1268e-04,  9.1790e-03,  9.2786e-03,  ..., -1.6540e-04,\n",
      "         -4.7265e-04, -3.9536e-03]], device='cuda:0'), bais gradient of fc is tensor(1.00000e-02 *\n",
      "       [ 0.3732, -1.8406, -1.8517,  4.0023, -0.6832], device='cuda:0')\n",
      "Epoch: 1/1... Step: 12500... Loss: 0.578645... Val Loss:0.772456\n",
      "weight gradient of fc is tensor([[ 1.1947e-02,  6.2726e-04, -1.1176e-04,  ...,  1.0563e-02,\n",
      "          3.8120e-03, -1.4859e-02],\n",
      "        [-3.9326e-02, -1.6301e-02, -8.1535e-03,  ..., -1.6688e-02,\n",
      "         -3.0121e-03, -9.0343e-03],\n",
      "        [ 6.1224e-04, -8.1574e-03, -3.6051e-04,  ..., -2.6393e-03,\n",
      "          7.0057e-03,  4.7990e-03],\n",
      "        [ 1.5282e-02,  1.3262e-02,  3.3199e-03,  ...,  2.9773e-03,\n",
      "         -4.7656e-03,  1.6841e-02],\n",
      "        [ 1.1484e-02,  1.0569e-02,  5.3059e-03,  ...,  5.7863e-03,\n",
      "         -3.0400e-03,  2.2535e-03]], device='cuda:0'), bais gradient of fc is tensor(1.00000e-02 *\n",
      "       [ 4.5836, -1.0619,  2.4442, -5.3215, -0.6444], device='cuda:0')\n",
      "Epoch: 1/1... Step: 12600... Loss: 0.668805... Val Loss:0.772838\n",
      "weight gradient of fc is tensor(1.00000e-02 *\n",
      "       [[ 1.1262,  0.8686,  1.9909,  ..., -0.7704, -0.1902,  2.6730],\n",
      "        [-1.2338, -1.0022, -0.6263,  ...,  0.2423, -0.0571, -0.1942],\n",
      "        [ 3.1097,  2.7321, -0.0177,  ...,  0.3214, -0.0700, -0.5725],\n",
      "        [-2.9889, -3.2513, -1.1569,  ..., -0.2549, -0.1108, -0.9141],\n",
      "        [-0.0132,  0.6528, -0.1900,  ...,  0.4616,  0.4280, -0.9922]], device='cuda:0'), bais gradient of fc is tensor(1.00000e-02 *\n",
      "       [-1.6895,  3.6071, -6.1070,  4.8886, -0.6993], device='cuda:0')\n",
      "Epoch: 1/1... Step: 12700... Loss: 0.521819... Val Loss:0.772197\n",
      "weight gradient of fc is tensor(1.00000e-02 *\n",
      "       [[-0.6058, -0.9842, -0.0317,  ...,  0.1241,  0.4248, -0.0902],\n",
      "        [-0.4435, -1.7644,  0.1177,  ..., -0.7640,  1.0000, -1.1419],\n",
      "        [ 2.5052,  3.5150,  0.1920,  ...,  1.0224, -1.0069, -1.0213],\n",
      "        [-3.2981, -1.5944, -0.7465,  ..., -0.1139, -0.2543,  1.1099],\n",
      "        [ 1.8423,  0.8280,  0.4685,  ..., -0.2686, -0.1636,  1.1436]], device='cuda:0'), bais gradient of fc is tensor(1.00000e-02 *\n",
      "       [ 2.8050,  5.7548, -8.9335,  0.6832, -0.3095], device='cuda:0')\n",
      "Epoch: 1/1... Step: 12800... Loss: 0.734648... Val Loss:0.772941\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Train your model with dropout. Make sure to clip your gradients.\n",
    "Print the training loss, validation loss, and validation accuracy for every 100 steps.\n",
    "\"\"\"\n",
    "\n",
    "epochs = 1\n",
    "batch_size = 64\n",
    "learning_rate = 0.0001\n",
    "clip=5\n",
    "\n",
    "print_every = 100\n",
    "criterion = nn.NLLLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "model.train()\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    print('Starting epoch {}'.format(epoch + 1))\n",
    "    \n",
    "    hidden = model.init_hidden(batch_size)\n",
    "    steps = 0\n",
    "    for text_batch, labels in dataloader(\n",
    "            train_features, train_labels, batch_size=batch_size, sequence_length=20, shuffle=True):\n",
    "        steps += 1\n",
    "        \n",
    "        # Set Device\n",
    "        text_batch, labels = text_batch.to(device), labels.to(device)\n",
    "        for each in hidden:\n",
    "            each.to(device)\n",
    "        \n",
    "        # TODO Implement: Train Model\n",
    "        hidden = tuple([each.data for each in hidden])\n",
    "        \n",
    "        #zero gradient\n",
    "        model.zero_grad()\n",
    "        \n",
    "        \n",
    "        #forward\n",
    "        output,hidden = model(text_batch,hidden)\n",
    "        \n",
    "        #loss\n",
    "        loss = criterion(output.squeeze(),labels.long())\n",
    "        \n",
    "        #backward, calc gradient\n",
    "        loss.backward()\n",
    "        \n",
    "        #clip gradient\n",
    "        nn.utils.clip_grad_norm_(model.parameters(),clip)\n",
    "        \n",
    "     \n",
    "        #update weight\n",
    "        optimizer.step()\n",
    "        \n",
    "        if steps % print_every == 0:\n",
    "            # eval model\n",
    "            model.eval()\n",
    "            \n",
    "            #check fc gradient test\n",
    "            weight_grad = model.fc.weight.grad\n",
    "            bias_grad = model.fc.bias.grad\n",
    "            print(f\"weight gradient of fc is {weight_grad}, bais gradient of fc is {bias_grad}\")\n",
    "\n",
    "            \n",
    "            # TODO Implement: Print metrics\n",
    "            val_h = model.init_hidden(batch_size)\n",
    "            val_losses = []\n",
    "            \n",
    "            for val_text_batch, val_labels in dataloader(\n",
    "                valid_features, valid_labels, batch_size=batch_size, sequence_length=20, shuffle=True):\n",
    "                \n",
    "                \n",
    "                # detach hidden from history\n",
    "                val_h = tuple([each.data for each in val_h])\n",
    "                \n",
    "#                 print(val_text_batch.size())\n",
    "                \n",
    "                # Set Device\n",
    "                val_text_batch, val_labels = val_text_batch.to(device), val_labels.to(device)\n",
    "                for each in val_h:\n",
    "                    each.to(device)\n",
    "                    \n",
    "                val_out,val_h = model(val_text_batch,val_h)\n",
    "                val_loss = criterion(val_out.squeeze(),val_labels.long())\n",
    "                \n",
    "                val_losses.append(val_loss.item())\n",
    "                \n",
    "            model.train()\n",
    "            \n",
    "            print(f\"Epoch: {epoch+1}/{epochs}...\",\n",
    "                 f\"Step: {steps}...\",\n",
    "                 \"Loss: {:.6f}...\".format(loss.item()),\n",
    "                 \"Val Loss:{:.6f}\".format(np.mean(val_losses)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Making Predictions\n",
    "### Prediction \n",
    "Okay, now that you have a trained model, try it on some new twits and see if it works appropriately. Remember that for any new text, you'll need to preprocess it first before passing it to the network. Implement the `predict` function to generate the prediction vector from a message."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(text, model, vocab):\n",
    "    \"\"\" \n",
    "    Make a prediction on a single sentence.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "        text : The string to make a prediction on.\n",
    "        model : The model to use for making the prediction.\n",
    "        vocab : Dictionary for word to word ids. The key is the word and the value is the word id.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "        pred : Prediction vector\n",
    "    \"\"\"    \n",
    "    \n",
    "    # TODO Implement\n",
    "    \n",
    "    tokens = preprocess(text)\n",
    "    \n",
    "    # Filter non-vocab words\n",
    "    tokens = [t for t in tokens if t in vocab.keys()]\n",
    "    # Convert words to ids\n",
    "    tokens = [vocab[t] for t in tokens]\n",
    "        \n",
    "    # Adding a batch dimension\n",
    "    text_input = torch.from_numpy(np.asarray(tokens)).view(-1,1)\n",
    "    \n",
    "    text_input = text_input.to(\"cuda\")\n",
    "    # Get the NN output\n",
    "    hidden = model.init_hidden(1)\n",
    "    logps, _ = model.forward(text_input,hidden)\n",
    "    # Take the exponent of the NN output to get a range of 0 to 1 for each label.\n",
    "    pred = logps.exp()\n",
    "    \n",
    "    return pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.0062,  0.0857,  0.0269,  0.4101,  0.4710]], device='cuda:0')"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = \"Google is working on self driving cars, I'm bullish on $goog\"\n",
    "model.eval()\n",
    "model.to(\"cuda\")\n",
    "predict(text, model, vocab)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Questions: What is the prediction of the model? What is the uncertainty of the prediction?\n",
    "** TODO: Answer Question**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we have a trained model and we can make predictions. We can use this model to track the sentiments of various stocks by predicting the sentiments of twits as they are coming in. Now we have a stream of twits. For each of those twits, pull out the stocks mentioned in them and keep track of the sentiments. Remember that in the twits, ticker symbols are encoded with a dollar sign as the first character, all caps, and 2-4 letters, like $AAPL. Ideally, you'd want to track the sentiments of the stocks in your universe and use this as a signal in your larger model(s).\n",
    "\n",
    "## Testing\n",
    "### Load the Data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.path.join('..', '..', 'data', 'project_6_stocktwits', 'test_twits.json'), 'r') as f:\n",
    "    test_data = json.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Twit Stream"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'message_body': '$JWN has moved -1.69% on 10-31. Check out the movement and peers at  https://dividendbot.com?s=JWN',\n",
       " 'timestamp': '2018-11-01T00:00:05Z'}"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def twit_stream():\n",
    "    for twit in test_data['data']:\n",
    "        yield twit\n",
    "\n",
    "next(twit_stream())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the `prediction` function, let's apply it to a stream of twits."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def score_twits(stream, model, vocab, universe):\n",
    "    \"\"\" \n",
    "    Given a stream of twits and a universe of tickers, return sentiment scores for tickers in the universe.\n",
    "    \"\"\"\n",
    "    for twit in stream:\n",
    "\n",
    "        # Get the message text\n",
    "        text = twit['message_body']\n",
    "        symbols = re.findall('\\$[A-Z]{2,4}', text)\n",
    "        score = predict(text, model, vocab)\n",
    "\n",
    "        for symbol in symbols:\n",
    "            if symbol in universe:\n",
    "                yield {'symbol': symbol, 'score': score, 'timestamp': twit['timestamp']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'symbol': '$AAPL',\n",
       " 'score': tensor([[ 0.1123,  0.1684,  0.1974,  0.2688,  0.2531]], device='cuda:0'),\n",
       " 'timestamp': '2018-11-01T00:00:18Z'}"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "universe = {'$BBRY', '$AAPL', '$AMZN', '$BABA', '$YHOO', '$LQMT', '$FB', '$GOOG', '$BBBY', '$JNUG', '$SBUX', '$MU'}\n",
    "score_stream = score_twits(twit_stream(), model, vocab, universe)\n",
    "\n",
    "next(score_stream)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That's it. You have successfully built a model for sentiment analysis! "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Submission\n",
    "Now that you're done with the project, it's time to submit it. Click the submit button in the bottom right. One of our reviewers will give you feedback on your project with a pass or not passed grade. You can continue to the next section while you wait for feedback."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
